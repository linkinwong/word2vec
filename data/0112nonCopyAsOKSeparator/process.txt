CRFSuite 0.12  Copyright (c) 2007-2011 Naoaki Okazaki

Start time of the training: 2015-01-13T04:51:30Z

Reading the data set(s)
[1] tr.crf.txt
0....1....2....3....4....5....6....7....8....9....10
Number of instances: 10003
Seconds required: 2.410
[2] te.crf.txt
0....1....2....3....4....5....6....7....8....9....10
Number of instances: 1317
Seconds required: 0.270

Statistics the data set(s)
Number of data sets (groups): 2
Number of instances: 11318
Number of items: 153844
Number of attributes: 116857
Number of labels: 36

Holdout group: 2

Feature generation
type: CRF1d
feature.minfreq: 0.000000
feature.possible_states: 0
feature.possible_transitions: 0
0....1....2....3....4....5....6....7....8....9....10
Number of features: 158563
Seconds required: 0.700

L-BFGS optimization
c1: 0.000000
c2: 1.000000
num_memories: 6
max_iterations: 2147483647
epsilon: 0.000010
stop: 10
delta: 0.000010
linesearch: MoreThuente
linesearch.max_iterations: 20

***** Iteration #1 *****
Loss: 328328.527090
Feature norm: 1.000000
Error norm: 133811.570765
Active features: 158563
Line search trials: 1
Line search step: 0.000006
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (12101, 17262, 12101) (0.7010, 1.0000, 0.8242)
    repeat: (0, 0, 1447) (0.0000, 0.0000, 0.0000)
    filler: (0, 0, 1423) (0.0000, 0.0000, 0.0000)
    false_start: (0, 0, 2244) (0.0000, 0.0000, 0.0000)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.019473, 0.027778, 0.022895)
Item accuracy: 12101 / 17262 (0.7010)
Instance accuracy: 181 / 1316 (0.1375)

***** Iteration #2 *****
Loss: 323212.352908
Feature norm: 5.164597
Error norm: 120585.674154
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (12101, 17262, 12101) (0.7010, 1.0000, 0.8242)
    repeat: (0, 0, 1447) (0.0000, 0.0000, 0.0000)
    filler: (0, 0, 1423) (0.0000, 0.0000, 0.0000)
    false_start: (0, 0, 2244) (0.0000, 0.0000, 0.0000)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.019473, 0.027778, 0.022895)
Item accuracy: 12101 / 17262 (0.7010)
Instance accuracy: 181 / 1316 (0.1375)

***** Iteration #3 *****
Loss: 194817.925680
Feature norm: 4.623051
Error norm: 107229.492914
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (12081, 17242, 12101) (0.7007, 0.9983, 0.8234)
    repeat: (0, 0, 1447) (0.0000, 0.0000, 0.0000)
    filler: (0, 16, 1423) (0.0000, 0.0000, 0.0000)
    false_start: (0, 4, 2244) (0.0000, 0.0000, 0.0000)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.019463, 0.027732, 0.022873)
Item accuracy: 12081 / 17262 (0.6999)
Instance accuracy: 161 / 1316 (0.1223)

***** Iteration #4 *****
Loss: 136362.441431
Feature norm: 4.556147
Error norm: 68027.184272
Active features: 158563
Line search trials: 3
Line search step: 0.060868
Seconds required for this iteration: 2.130
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (12027, 17004, 12101) (0.7073, 0.9939, 0.8265)
    repeat: (0, 0, 1447) (0.0000, 0.0000, 0.0000)
    filler: (0, 16, 1423) (0.0000, 0.0000, 0.0000)
    false_start: (119, 242, 2244) (0.4917, 0.0530, 0.0957)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.033307, 0.029081, 0.025616)
Item accuracy: 12146 / 17262 (0.7036)
Instance accuracy: 153 / 1316 (0.1163)

***** Iteration #5 *****
Loss: 121833.495904
Feature norm: 4.647327
Error norm: 34270.059047
Active features: 158563
Line search trials: 2
Line search step: 0.220642
Seconds required for this iteration: 1.440
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 15558, 12101) (0.7481, 0.9618, 0.8416)
    repeat: (0, 0, 1447) (0.0000, 0.0000, 0.0000)
    filler: (12, 28, 1423) (0.4286, 0.0084, 0.0165)
    false_start: (505, 1676, 2244) (0.3013, 0.2250, 0.2577)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.041055, 0.033203, 0.030994)
Item accuracy: 12156 / 17262 (0.7042)
Instance accuracy: 142 / 1316 (0.1079)

***** Iteration #6 *****
Loss: 115025.060258
Feature norm: 4.870169
Error norm: 38564.565165
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11656, 15520, 12101) (0.7510, 0.9632, 0.8440)
    repeat: (12, 12, 1447) (1.0000, 0.0083, 0.0164)
    filler: (331, 441, 1423) (0.7506, 0.2326, 0.3552)
    false_start: (477, 1289, 2244) (0.3701, 0.2126, 0.2700)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.079768, 0.039353, 0.041267)
Item accuracy: 12476 / 17262 (0.7227)
Instance accuracy: 180 / 1316 (0.1368)

***** Iteration #7 *****
Loss: 107631.158038
Feature norm: 5.347201
Error norm: 32205.402333
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11762, 15637, 12101) (0.7522, 0.9720, 0.8481)
    repeat: (142, 166, 1447) (0.8554, 0.0981, 0.1761)
    filler: (699, 1251, 1423) (0.5588, 0.4912, 0.5228)
    false_start: (141, 208, 2244) (0.6779, 0.0628, 0.1150)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.079007, 0.045116, 0.046166)
Item accuracy: 12744 / 17262 (0.7383)
Instance accuracy: 202 / 1316 (0.1535)

***** Iteration #8 *****
Loss: 100700.006290
Feature norm: 5.886539
Error norm: 22026.450656
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11854, 15741, 12101) (0.7531, 0.9796, 0.8515)
    repeat: (232, 301, 1447) (0.7708, 0.1603, 0.2654)
    filler: (668, 1009, 1423) (0.6620, 0.4694, 0.5493)
    false_start: (123, 211, 2244) (0.5829, 0.0548, 0.1002)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.076911, 0.046227, 0.049070)
Item accuracy: 12877 / 17262 (0.7460)
Instance accuracy: 213 / 1316 (0.1619)

***** Iteration #9 *****
Loss: 90088.681543
Feature norm: 7.051988
Error norm: 23857.954407
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11799, 15425, 12101) (0.7649, 0.9750, 0.8573)
    repeat: (293, 447, 1447) (0.6555, 0.2025, 0.3094)
    filler: (743, 1042, 1423) (0.7131, 0.5221, 0.6028)
    false_start: (191, 348, 2244) (0.5489, 0.0851, 0.1474)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.074509, 0.049577, 0.053248)
Item accuracy: 13026 / 17262 (0.7546)
Instance accuracy: 205 / 1316 (0.1558)

***** Iteration #10 *****
Loss: 77662.272887
Feature norm: 8.931914
Error norm: 16790.219584
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11572, 14435, 12101) (0.8017, 0.9563, 0.8722)
    repeat: (393, 555, 1447) (0.7081, 0.2716, 0.3926)
    filler: (914, 1274, 1423) (0.7174, 0.6423, 0.6778)
    false_start: (509, 998, 2244) (0.5100, 0.2268, 0.3140)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.076034, 0.058250, 0.062683)
Item accuracy: 13388 / 17262 (0.7756)
Instance accuracy: 239 / 1316 (0.1816)

***** Iteration #11 *****
Loss: 73796.939705
Feature norm: 10.912846
Error norm: 43508.461950
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (9662, 10747, 12101) (0.8990, 0.7984, 0.8458)
    repeat: (650, 961, 1447) (0.6764, 0.4492, 0.5399)
    filler: (893, 1073, 1423) (0.8322, 0.6275, 0.7155)
    false_start: (1387, 4481, 2244) (0.3095, 0.6181, 0.4125)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.075478, 0.069258, 0.069824)
Item accuracy: 12592 / 17262 (0.7295)
Instance accuracy: 257 / 1316 (0.1953)

***** Iteration #12 *****
Loss: 69697.506060
Feature norm: 11.160107
Error norm: 9845.741443
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11308, 13252, 12101) (0.8533, 0.9345, 0.8920)
    repeat: (589, 806, 1447) (0.7308, 0.4070, 0.5229)
    filler: (1016, 1242, 1423) (0.8180, 0.7140, 0.7625)
    false_start: (892, 1962, 2244) (0.4546, 0.3975, 0.4242)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.079354, 0.068139, 0.072265)
Item accuracy: 13805 / 17262 (0.7997)
Instance accuracy: 304 / 1316 (0.2310)

***** Iteration #13 *****
Loss: 68989.692000
Feature norm: 11.287840
Error norm: 9076.883560
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11408, 13408, 12101) (0.8508, 0.9427, 0.8944)
    repeat: (584, 779, 1447) (0.7497, 0.4036, 0.5247)
    filler: (1078, 1329, 1423) (0.8111, 0.7576, 0.7834)
    false_start: (827, 1746, 2244) (0.4737, 0.3685, 0.4145)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.080147, 0.068678, 0.072697)
Item accuracy: 13897 / 17262 (0.8051)
Instance accuracy: 308 / 1316 (0.2340)

***** Iteration #14 *****
Loss: 67421.505924
Feature norm: 11.417011
Error norm: 9347.126904
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11503, 13521, 12101) (0.8508, 0.9506, 0.8979)
    repeat: (538, 679, 1447) (0.7923, 0.3718, 0.5061)
    filler: (1165, 1454, 1423) (0.8012, 0.8187, 0.8099)
    false_start: (783, 1608, 2244) (0.4869, 0.3489, 0.4065)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.081424, 0.069167, 0.072790)
Item accuracy: 13989 / 17262 (0.8104)
Instance accuracy: 327 / 1316 (0.2485)

***** Iteration #15 *****
Loss: 65803.608487
Feature norm: 11.552178
Error norm: 8641.096230
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11551, 13561, 12101) (0.8518, 0.9545, 0.9002)
    repeat: (534, 656, 1447) (0.8140, 0.3690, 0.5078)
    filler: (1244, 1557, 1423) (0.7990, 0.8742, 0.8349)
    false_start: (746, 1488, 2244) (0.5013, 0.3324, 0.3998)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.082392, 0.070284, 0.073410)
Item accuracy: 14075 / 17262 (0.8154)
Instance accuracy: 353 / 1316 (0.2682)

***** Iteration #16 *****
Loss: 63862.627615
Feature norm: 12.962385
Error norm: 12510.239811
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11659, 13740, 12101) (0.8485, 0.9635, 0.9024)
    repeat: (633, 770, 1447) (0.8221, 0.4375, 0.5710)
    filler: (1262, 1537, 1423) (0.8211, 0.8869, 0.8527)
    false_start: (618, 1215, 2244) (0.5086, 0.2754, 0.3573)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.083343, 0.071200, 0.074540)
Item accuracy: 14172 / 17262 (0.8210)
Instance accuracy: 383 / 1316 (0.2910)

***** Iteration #17 *****
Loss: 62723.981551
Feature norm: 12.986540
Error norm: 7856.462428
Active features: 158563
Line search trials: 2
Line search step: 0.129327
Seconds required for this iteration: 1.450
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11645, 13727, 12101) (0.8483, 0.9623, 0.9017)
    repeat: (553, 657, 1447) (0.8417, 0.3822, 0.5257)
    filler: (1273, 1549, 1423) (0.8218, 0.8946, 0.8567)
    false_start: (674, 1329, 2244) (0.5071, 0.3004, 0.3773)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.083861, 0.070540, 0.073926)
Item accuracy: 14145 / 17262 (0.8194)
Instance accuracy: 367 / 1316 (0.2789)

***** Iteration #18 *****
Loss: 61768.864450
Feature norm: 12.776865
Error norm: 5728.741252
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11695, 13842, 12101) (0.8449, 0.9664, 0.9016)
    repeat: (653, 802, 1447) (0.8142, 0.4513, 0.5807)
    filler: (1272, 1545, 1423) (0.8233, 0.8939, 0.8571)
    false_start: (582, 1073, 2244) (0.5424, 0.2594, 0.3509)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.084023, 0.071416, 0.074732)
Item accuracy: 14202 / 17262 (0.8227)
Instance accuracy: 382 / 1316 (0.2903)

***** Iteration #19 *****
Loss: 61394.255844
Feature norm: 12.778136
Error norm: 11785.709599
Active features: 158563
Line search trials: 2
Line search step: 0.504215
Seconds required for this iteration: 1.450
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11553, 13422, 12101) (0.8608, 0.9547, 0.9053)
    repeat: (695, 850, 1447) (0.8176, 0.4803, 0.6051)
    filler: (1265, 1540, 1423) (0.8214, 0.8890, 0.8539)
    false_start: (783, 1450, 2244) (0.5400, 0.3489, 0.4239)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.084440, 0.074248, 0.077451)
Item accuracy: 14296 / 17262 (0.8282)
Instance accuracy: 392 / 1316 (0.2979)

***** Iteration #20 *****
Loss: 60901.169453
Feature norm: 12.829444
Error norm: 9468.297186
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11571, 13436, 12101) (0.8612, 0.9562, 0.9062)
    repeat: (708, 865, 1447) (0.8185, 0.4893, 0.6125)
    filler: (1257, 1528, 1423) (0.8226, 0.8833, 0.8519)
    false_start: (792, 1433, 2244) (0.5527, 0.3529, 0.4308)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.084862, 0.074494, 0.077816)
Item accuracy: 14328 / 17262 (0.8300)
Instance accuracy: 397 / 1316 (0.3017)

***** Iteration #21 *****
Loss: 59563.687051
Feature norm: 13.358739
Error norm: 5332.264223
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 13540, 12101) (0.8589, 0.9610, 0.9071)
    repeat: (742, 912, 1447) (0.8136, 0.5128, 0.6291)
    filler: (1254, 1521, 1423) (0.8245, 0.8812, 0.8519)
    false_start: (740, 1289, 2244) (0.5741, 0.3298, 0.4189)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.085306, 0.074577, 0.077971)
Item accuracy: 14365 / 17262 (0.8322)
Instance accuracy: 408 / 1316 (0.3100)

***** Iteration #22 *****
Loss: 58395.080201
Feature norm: 14.209987
Error norm: 4444.368903
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 13458, 12101) (0.8649, 0.9619, 0.9108)
    repeat: (804, 1016, 1447) (0.7913, 0.5556, 0.6529)
    filler: (1278, 1559, 1423) (0.8198, 0.8981, 0.8571)
    false_start: (776, 1229, 2244) (0.6314, 0.3458, 0.4469)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.086317, 0.076707, 0.079659)
Item accuracy: 14498 / 17262 (0.8399)
Instance accuracy: 421 / 1316 (0.3199)

***** Iteration #23 *****
Loss: 57242.857620
Feature norm: 15.188520
Error norm: 5872.938337
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11688, 13518, 12101) (0.8646, 0.9659, 0.9124)
    repeat: (816, 1026, 1447) (0.7953, 0.5639, 0.6599)
    filler: (1295, 1574, 1423) (0.8227, 0.9100, 0.8642)
    false_start: (737, 1144, 2244) (0.6442, 0.3284, 0.4351)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.086859, 0.076897, 0.079768)
Item accuracy: 14536 / 17262 (0.8421)
Instance accuracy: 427 / 1316 (0.3245)

***** Iteration #24 *****
Loss: 56159.206619
Feature norm: 16.531880
Error norm: 7493.162475
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11668, 13428, 12101) (0.8689, 0.9642, 0.9141)
    repeat: (942, 1249, 1447) (0.7542, 0.6510, 0.6988)
    filler: (1299, 1576, 1423) (0.8242, 0.9129, 0.8663)
    false_start: (677, 1009, 2244) (0.6710, 0.3017, 0.4162)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.086620, 0.078605, 0.080429)
Item accuracy: 14586 / 17262 (0.8450)
Instance accuracy: 451 / 1316 (0.3427)

***** Iteration #25 *****
Loss: 55391.791277
Feature norm: 17.271770
Error norm: 4363.706981
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 13329, 12101) (0.8728, 0.9614, 0.9150)
    repeat: (884, 1109, 1447) (0.7971, 0.6109, 0.6917)
    filler: (1295, 1556, 1423) (0.8323, 0.9100, 0.8694)
    false_start: (793, 1268, 2244) (0.6254, 0.3534, 0.4516)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.086878, 0.078771, 0.081325)
Item accuracy: 14606 / 17262 (0.8461)
Instance accuracy: 455 / 1316 (0.3457)

***** Iteration #26 *****
Loss: 55004.168740
Feature norm: 17.155573
Error norm: 7143.623911
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11682, 13463, 12101) (0.8677, 0.9654, 0.9139)
    repeat: (869, 1069, 1447) (0.8129, 0.6006, 0.6908)
    filler: (1298, 1559, 1423) (0.8326, 0.9122, 0.8706)
    false_start: (727, 1171, 2244) (0.6208, 0.3240, 0.4258)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.087057, 0.077835, 0.080585)
Item accuracy: 14576 / 17262 (0.8444)
Instance accuracy: 451 / 1316 (0.3427)

***** Iteration #27 *****
Loss: 54372.468461
Feature norm: 17.076660
Error norm: 6971.174767
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11519, 13090, 12101) (0.8800, 0.9519, 0.9145)
    repeat: (882, 1087, 1447) (0.8114, 0.6095, 0.6961)
    filler: (1297, 1549, 1423) (0.8373, 0.9115, 0.8728)
    false_start: (878, 1536, 2244) (0.5716, 0.3913, 0.4646)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.086120, 0.079560, 0.081890)
Item accuracy: 14576 / 17262 (0.8444)
Instance accuracy: 443 / 1316 (0.3366)

***** Iteration #28 *****
Loss: 54020.691055
Feature norm: 17.109656
Error norm: 4081.825808
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11560, 13159, 12101) (0.8785, 0.9553, 0.9153)
    repeat: (910, 1138, 1447) (0.7996, 0.6289, 0.7041)
    filler: (1299, 1554, 1423) (0.8359, 0.9129, 0.8727)
    false_start: (837, 1411, 2244) (0.5932, 0.3730, 0.4580)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.086312, 0.079723, 0.081945)
Item accuracy: 14606 / 17262 (0.8461)
Instance accuracy: 447 / 1316 (0.3397)

***** Iteration #29 *****
Loss: 53513.093370
Feature norm: 17.687178
Error norm: 3402.364227
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11569, 13206, 12101) (0.8760, 0.9560, 0.9143)
    repeat: (947, 1211, 1447) (0.7820, 0.6545, 0.7126)
    filler: (1301, 1550, 1423) (0.8394, 0.9143, 0.8752)
    false_start: (776, 1295, 2244) (0.5992, 0.3458, 0.4385)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.086017, 0.079738, 0.081684)
Item accuracy: 14593 / 17262 (0.8454)
Instance accuracy: 454 / 1316 (0.3450)

***** Iteration #30 *****
Loss: 52947.487568
Feature norm: 18.448049
Error norm: 3460.740343
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11612, 13249, 12101) (0.8764, 0.9596, 0.9161)
    repeat: (954, 1211, 1447) (0.7878, 0.6593, 0.7178)
    filler: (1295, 1529, 1423) (0.8470, 0.9100, 0.8774)
    false_start: (784, 1273, 2244) (0.6159, 0.3494, 0.4458)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.086862, 0.079953, 0.082144)
Item accuracy: 14645 / 17262 (0.8484)
Instance accuracy: 465 / 1316 (0.3533)

***** Iteration #31 *****
Loss: 52083.811841
Feature norm: 19.351595
Error norm: 3904.548910
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11669, 13272, 12101) (0.8792, 0.9643, 0.9198)
    repeat: (986, 1265, 1447) (0.7794, 0.6814, 0.7271)
    filler: (1292, 1531, 1423) (0.8439, 0.9079, 0.8747)
    false_start: (787, 1194, 2244) (0.6591, 0.3507, 0.4578)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.087825, 0.080677, 0.082764)
Item accuracy: 14734 / 17262 (0.8536)
Instance accuracy: 478 / 1316 (0.3632)

***** Iteration #32 *****
Loss: 51628.755148
Feature norm: 19.617190
Error norm: 4506.471074
Active features: 158563
Line search trials: 2
Line search step: 0.406804
Seconds required for this iteration: 1.440
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11714, 13349, 12101) (0.8775, 0.9680, 0.9206)
    repeat: (929, 1142, 1447) (0.8135, 0.6420, 0.7177)
    filler: (1280, 1498, 1423) (0.8545, 0.8995, 0.8764)
    false_start: (847, 1273, 2244) (0.6654, 0.3775, 0.4817)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.089190, 0.080194, 0.083230)
Item accuracy: 14770 / 17262 (0.8556)
Instance accuracy: 475 / 1316 (0.3609)

***** Iteration #33 *****
Loss: 51096.762411
Feature norm: 19.887649
Error norm: 3262.551795
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11732, 13392, 12101) (0.8760, 0.9695, 0.9204)
    repeat: (964, 1193, 1447) (0.8080, 0.6662, 0.7303)
    filler: (1283, 1504, 1423) (0.8531, 0.9016, 0.8767)
    false_start: (785, 1173, 2244) (0.6692, 0.3498, 0.4595)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.089066, 0.080199, 0.082968)
Item accuracy: 14764 / 17262 (0.8553)
Instance accuracy: 487 / 1316 (0.3701)

***** Iteration #34 *****
Loss: 50916.029205
Feature norm: 19.876680
Error norm: 8124.113578
Active features: 158563
Line search trials: 2
Line search step: 0.359762
Seconds required for this iteration: 1.440
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11653, 13166, 12101) (0.8851, 0.9630, 0.9224)
    repeat: (983, 1225, 1447) (0.8024, 0.6793, 0.7358)
    filler: (1287, 1513, 1423) (0.8506, 0.9044, 0.8767)
    false_start: (882, 1358, 2244) (0.6495, 0.3930, 0.4897)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.088546, 0.081661, 0.084017)
Item accuracy: 14805 / 17262 (0.8577)
Instance accuracy: 487 / 1316 (0.3701)

***** Iteration #35 *****
Loss: 50530.622854
Feature norm: 19.495689
Error norm: 4276.340727
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11713, 13334, 12101) (0.8784, 0.9679, 0.9210)
    repeat: (992, 1250, 1447) (0.7936, 0.6856, 0.7356)
    filler: (1296, 1526, 1423) (0.8493, 0.9108, 0.8789)
    false_start: (773, 1152, 2244) (0.6710, 0.3445, 0.4552)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.088675, 0.080798, 0.083079)
Item accuracy: 14774 / 17262 (0.8559)
Instance accuracy: 493 / 1316 (0.3746)

***** Iteration #36 *****
Loss: 50273.378936
Feature norm: 19.240217
Error norm: 2959.547555
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11749, 13445, 12101) (0.8739, 0.9709, 0.9198)
    repeat: (988, 1240, 1447) (0.7968, 0.6828, 0.7354)
    filler: (1293, 1527, 1423) (0.8468, 0.9086, 0.8766)
    false_start: (720, 1050, 2244) (0.6857, 0.3209, 0.4372)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.088975, 0.080089, 0.082472)
Item accuracy: 14750 / 17262 (0.8545)
Instance accuracy: 499 / 1316 (0.3792)

***** Iteration #37 *****
Loss: 49773.420138
Feature norm: 18.976576
Error norm: 3033.680252
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11785, 13571, 12101) (0.8684, 0.9739, 0.9181)
    repeat: (983, 1222, 1447) (0.8044, 0.6793, 0.7366)
    filler: (1295, 1526, 1423) (0.8486, 0.9100, 0.8783)
    false_start: (654, 943, 2244) (0.6935, 0.2914, 0.4104)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.089305, 0.079298, 0.081761)
Item accuracy: 14717 / 17262 (0.8526)
Instance accuracy: 499 / 1316 (0.3792)

***** Iteration #38 *****
Loss: 49245.515662
Feature norm: 18.916115
Error norm: 3297.920360
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11785, 13584, 12101) (0.8676, 0.9739, 0.9177)
    repeat: (971, 1200, 1447) (0.8092, 0.6710, 0.7337)
    filler: (1298, 1522, 1423) (0.8528, 0.9122, 0.8815)
    false_start: (651, 956, 2244) (0.6810, 0.2901, 0.4069)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.089181, 0.079089, 0.081658)
Item accuracy: 14705 / 17262 (0.8519)
Instance accuracy: 510 / 1316 (0.3875)

***** Iteration #39 *****
Loss: 48598.230701
Feature norm: 19.754528
Error norm: 8437.302906
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11706, 13480, 12101) (0.8684, 0.9674, 0.9152)
    repeat: (1021, 1299, 1447) (0.7860, 0.7056, 0.7436)
    filler: (1290, 1514, 1423) (0.8520, 0.9065, 0.8784)
    false_start: (627, 969, 2244) (0.6471, 0.2794, 0.3903)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 0, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.087597, 0.079414, 0.081322)
Item accuracy: 14644 / 17262 (0.8483)
Instance accuracy: 486 / 1316 (0.3693)

***** Iteration #40 *****
Loss: 48091.794950
Feature norm: 19.851694
Error norm: 5862.262421
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11600, 13226, 12101) (0.8771, 0.9586, 0.9160)
    repeat: (933, 1102, 1447) (0.8466, 0.6448, 0.7321)
    filler: (1262, 1464, 1423) (0.8620, 0.8869, 0.8743)
    false_start: (859, 1464, 2244) (0.5867, 0.3828, 0.4633)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (3, 6, 26) (0.5000, 0.1154, 0.1875)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.102013, 0.083012, 0.088143)
Item accuracy: 14657 / 17262 (0.8491)
Instance accuracy: 478 / 1316 (0.3632)

***** Iteration #41 *****
Loss: 47713.710249
Feature norm: 19.933344
Error norm: 4103.799983
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11668, 13348, 12101) (0.8741, 0.9642, 0.9170)
    repeat: (960, 1160, 1447) (0.8276, 0.6634, 0.7365)
    filler: (1269, 1485, 1423) (0.8545, 0.8918, 0.8728)
    false_start: (775, 1268, 2244) (0.6112, 0.3454, 0.4413)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 1, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.087985, 0.079578, 0.082432)
Item accuracy: 14672 / 17262 (0.8500)
Instance accuracy: 484 / 1316 (0.3678)

***** Iteration #42 *****
Loss: 47597.719973
Feature norm: 20.002496
Error norm: 4755.943683
Active features: 158563
Line search trials: 2
Line search step: 0.324171
Seconds required for this iteration: 1.440
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 13169, 12101) (0.8837, 0.9617, 0.9211)
    repeat: (993, 1216, 1447) (0.8166, 0.6862, 0.7458)
    filler: (1290, 1507, 1423) (0.8560, 0.9065, 0.8805)
    false_start: (858, 1369, 2244) (0.6267, 0.3824, 0.4750)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 1, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.088419, 0.081580, 0.083955)
Item accuracy: 14779 / 17262 (0.8562)
Instance accuracy: 495 / 1316 (0.3761)

***** Iteration #43 *****
Loss: 47445.123303
Feature norm: 20.260380
Error norm: 3067.348136
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 13204, 12101) (0.8816, 0.9620, 0.9201)
    repeat: (1007, 1252, 1447) (0.8043, 0.6959, 0.7462)
    filler: (1282, 1498, 1423) (0.8558, 0.9009, 0.8778)
    false_start: (822, 1307, 2244) (0.6289, 0.3663, 0.4630)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (0, 1, 26) (0.0000, 0.0000, 0.0000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.088074, 0.081254, 0.083528)
Item accuracy: 14752 / 17262 (0.8546)
Instance accuracy: 498 / 1316 (0.3784)

***** Iteration #44 *****
Loss: 47215.373214
Feature norm: 20.461008
Error norm: 2724.041875
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11660, 13224, 12101) (0.8817, 0.9636, 0.9208)
    repeat: (1012, 1266, 1447) (0.7994, 0.6994, 0.7460)
    filler: (1292, 1515, 1423) (0.8528, 0.9079, 0.8795)
    false_start: (801, 1251, 2244) (0.6403, 0.3570, 0.4584)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (3, 6, 26) (0.5000, 0.1154, 0.1875)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.102061, 0.084534, 0.088673)
Item accuracy: 14768 / 17262 (0.8555)
Instance accuracy: 500 / 1316 (0.3799)

***** Iteration #45 *****
Loss: 46803.200800
Feature norm: 20.783194
Error norm: 3531.132143
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11677, 13327, 12101) (0.8762, 0.9650, 0.9184)
    repeat: (1022, 1291, 1447) (0.7916, 0.7063, 0.7465)
    filler: (1291, 1509, 1423) (0.8555, 0.9072, 0.8806)
    false_start: (717, 1128, 2244) (0.6356, 0.3195, 0.4253)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (3, 7, 26) (0.4286, 0.1154, 0.1818)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.099655, 0.083705, 0.087574)
Item accuracy: 14710 / 17262 (0.8522)
Instance accuracy: 487 / 1316 (0.3701)

***** Iteration #46 *****
Loss: 46497.021092
Feature norm: 21.116138
Error norm: 2960.252670
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11725, 13394, 12101) (0.8754, 0.9689, 0.9198)
    repeat: (1020, 1287, 1447) (0.7925, 0.7049, 0.7462)
    filler: (1293, 1500, 1423) (0.8620, 0.9086, 0.8847)
    false_start: (719, 1074, 2244) (0.6695, 0.3204, 0.4334)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (3, 7, 26) (0.4286, 0.1154, 0.1818)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.100777, 0.083841, 0.087941)
Item accuracy: 14760 / 17262 (0.8551)
Instance accuracy: 505 / 1316 (0.3837)

***** Iteration #47 *****
Loss: 46299.345982
Feature norm: 21.296454
Error norm: 6537.684788
Active features: 158563
Line search trials: 2
Line search step: 0.489532
Seconds required for this iteration: 1.440
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11758, 13486, 12101) (0.8719, 0.9717, 0.9191)
    repeat: (1037, 1319, 1447) (0.7862, 0.7167, 0.7498)
    filler: (1301, 1513, 1423) (0.8599, 0.9143, 0.8862)
    false_start: (649, 932, 2244) (0.6964, 0.2892, 0.4087)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (7, 12, 26) (0.5833, 0.2692, 0.3684)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.105490, 0.087806, 0.092562)
Item accuracy: 14752 / 17262 (0.8546)
Instance accuracy: 506 / 1316 (0.3845)

***** Iteration #48 *****
Loss: 45953.897566
Feature norm: 21.906668
Error norm: 2401.888404
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11740, 13419, 12101) (0.8749, 0.9702, 0.9201)
    repeat: (1018, 1266, 1447) (0.8041, 0.7035, 0.7505)
    filler: (1291, 1492, 1423) (0.8653, 0.9072, 0.8858)
    false_start: (724, 1071, 2244) (0.6760, 0.3226, 0.4368)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (9, 14, 26) (0.6429, 0.3462, 0.4500)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107309, 0.090270, 0.095641)
Item accuracy: 14782 / 17262 (0.8563)
Instance accuracy: 507 / 1316 (0.3853)

***** Iteration #49 *****
Loss: 45829.111107
Feature norm: 21.888267
Error norm: 3096.733179
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11739, 13415, 12101) (0.8751, 0.9701, 0.9201)
    repeat: (1004, 1234, 1447) (0.8136, 0.6938, 0.7490)
    filler: (1291, 1491, 1423) (0.8659, 0.9072, 0.8861)
    false_start: (741, 1108, 2244) (0.6688, 0.3302, 0.4421)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (9, 14, 26) (0.6429, 0.3462, 0.4500)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107394, 0.090209, 0.095758)
Item accuracy: 14784 / 17262 (0.8564)
Instance accuracy: 509 / 1316 (0.3868)

***** Iteration #50 *****
Loss: 45755.495576
Feature norm: 21.905845
Error norm: 4920.852720
Active features: 158563
Line search trials: 2
Line search step: 0.175856
Seconds required for this iteration: 1.440
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11669, 13214, 12101) (0.8831, 0.9643, 0.9219)
    repeat: (1022, 1261, 1447) (0.8105, 0.7063, 0.7548)
    filler: (1293, 1497, 1423) (0.8637, 0.9086, 0.8856)
    false_start: (827, 1276, 2244) (0.6481, 0.3685, 0.4699)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (9, 14, 26) (0.6429, 0.3462, 0.4500)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.106896, 0.091498, 0.096728)
Item accuracy: 14820 / 17262 (0.8585)
Instance accuracy: 513 / 1316 (0.3898)

***** Iteration #51 *****
Loss: 45662.235630
Feature norm: 21.904613
Error norm: 4089.156913
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11701, 13285, 12101) (0.8808, 0.9669, 0.9218)
    repeat: (1021, 1260, 1447) (0.8103, 0.7056, 0.7543)
    filler: (1296, 1506, 1423) (0.8606, 0.9108, 0.8849)
    false_start: (790, 1197, 2244) (0.6600, 0.3520, 0.4592)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (9, 14, 26) (0.6429, 0.3462, 0.4500)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107069, 0.091153, 0.096397)
Item accuracy: 14817 / 17262 (0.8584)
Instance accuracy: 514 / 1316 (0.3906)

***** Iteration #52 *****
Loss: 45256.221824
Feature norm: 22.471244
Error norm: 2038.878023
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11725, 13279, 12101) (0.8830, 0.9689, 0.9240)
    repeat: (1024, 1267, 1447) (0.8082, 0.7077, 0.7546)
    filler: (1298, 1529, 1423) (0.8489, 0.9122, 0.8794)
    false_start: (796, 1175, 2244) (0.6774, 0.3547, 0.4656)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (7, 12, 26) (0.5833, 0.2692, 0.3684)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.105580, 0.089242, 0.094223)
Item accuracy: 14850 / 17262 (0.8603)
Instance accuracy: 511 / 1316 (0.3883)

***** Iteration #53 *****
Loss: 45013.993079
Feature norm: 22.900690
Error norm: 1893.795186
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11703, 13226, 12101) (0.8848, 0.9671, 0.9242)
    repeat: (1037, 1292, 1447) (0.8026, 0.7167, 0.7572)
    filler: (1302, 1535, 1423) (0.8482, 0.9150, 0.8803)
    false_start: (815, 1197, 2244) (0.6809, 0.3632, 0.4737)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (7, 12, 26) (0.5833, 0.2692, 0.3684)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.105553, 0.089754, 0.094550)
Item accuracy: 14864 / 17262 (0.8611)
Instance accuracy: 512 / 1316 (0.3891)

***** Iteration #54 *****
Loss: 44679.392995
Feature norm: 23.592027
Error norm: 1812.959131
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11675, 13173, 12101) (0.8863, 0.9648, 0.9239)
    repeat: (1038, 1300, 1447) (0.7985, 0.7173, 0.7557)
    filler: (1302, 1539, 1423) (0.8460, 0.9150, 0.8791)
    false_start: (830, 1238, 2244) (0.6704, 0.3699, 0.4767)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (7, 12, 26) (0.5833, 0.2692, 0.3684)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.105125, 0.089895, 0.094553)
Item accuracy: 14852 / 17262 (0.8604)
Instance accuracy: 515 / 1316 (0.3913)

***** Iteration #55 *****
Loss: 44135.370263
Feature norm: 24.690700
Error norm: 3509.861135
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11659, 13122, 12101) (0.8885, 0.9635, 0.9245)
    repeat: (1063, 1364, 1447) (0.7793, 0.7346, 0.7563)
    filler: (1314, 1553, 1423) (0.8461, 0.9234, 0.8831)
    false_start: (809, 1207, 2244) (0.6703, 0.3605, 0.4688)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 16, 26) (0.5000, 0.3077, 0.3810)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.102339, 0.091381, 0.094824)
Item accuracy: 14853 / 17262 (0.8604)
Instance accuracy: 512 / 1316 (0.3891)

***** Iteration #56 *****
Loss: 44072.798494
Feature norm: 27.303474
Error norm: 9295.585316
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11533, 12915, 12101) (0.8930, 0.9531, 0.9220)
    repeat: (984, 1151, 1447) (0.8549, 0.6800, 0.7575)
    filler: (1290, 1501, 1423) (0.8594, 0.9065, 0.8824)
    false_start: (995, 1678, 2244) (0.5930, 0.4434, 0.5074)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 17, 26) (0.4706, 0.3077, 0.3721)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.101969, 0.091409, 0.095594)
Item accuracy: 14810 / 17262 (0.8580)
Instance accuracy: 508 / 1316 (0.3860)

***** Iteration #57 *****
Loss: 43411.270843
Feature norm: 26.733359
Error norm: 8793.521732
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11725, 13248, 12101) (0.8850, 0.9689, 0.9251)
    repeat: (1036, 1263, 1447) (0.8203, 0.7160, 0.7646)
    filler: (1303, 1529, 1423) (0.8522, 0.9157, 0.8828)
    false_start: (812, 1205, 2244) (0.6739, 0.3619, 0.4709)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 17, 26) (0.4706, 0.3077, 0.3721)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.102832, 0.090836, 0.094872)
Item accuracy: 14884 / 17262 (0.8622)
Instance accuracy: 515 / 1316 (0.3913)

***** Iteration #58 *****
Loss: 43151.629840
Feature norm: 26.367740
Error norm: 2412.659977
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11626, 13053, 12101) (0.8907, 0.9607, 0.9244)
    repeat: (1068, 1340, 1447) (0.7970, 0.7381, 0.7664)
    filler: (1311, 1542, 1423) (0.8502, 0.9213, 0.8843)
    false_start: (844, 1310, 2244) (0.6443, 0.3761, 0.4750)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 17, 26) (0.4706, 0.3077, 0.3721)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.101465, 0.091776, 0.095060)
Item accuracy: 14857 / 17262 (0.8607)
Instance accuracy: 508 / 1316 (0.3860)

***** Iteration #59 *****
Loss: 43045.226560
Feature norm: 26.451849
Error norm: 2106.201246
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11622, 13045, 12101) (0.8909, 0.9604, 0.9244)
    repeat: (1066, 1319, 1447) (0.8082, 0.7367, 0.7708)
    filler: (1306, 1536, 1423) (0.8503, 0.9178, 0.8827)
    false_start: (857, 1345, 2244) (0.6372, 0.3819, 0.4776)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 17, 26) (0.4706, 0.3077, 0.3721)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.101587, 0.091791, 0.095210)
Item accuracy: 14859 / 17262 (0.8608)
Instance accuracy: 510 / 1316 (0.3875)

***** Iteration #60 *****
Loss: 42834.423326
Feature norm: 26.860573
Error norm: 2472.881651
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11608, 13040, 12101) (0.8902, 0.9593, 0.9234)
    repeat: (1045, 1274, 1447) (0.8203, 0.7222, 0.7681)
    filler: (1308, 1540, 1423) (0.8494, 0.9192, 0.8829)
    false_start: (867, 1391, 2244) (0.6233, 0.3864, 0.4770)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 17, 26) (0.4706, 0.3077, 0.3721)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.101491, 0.091519, 0.095098)
Item accuracy: 14836 / 17262 (0.8595)
Instance accuracy: 512 / 1316 (0.3891)

***** Iteration #61 *****
Loss: 42484.515853
Feature norm: 27.643538
Error norm: 2216.073085
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11600, 13025, 12101) (0.8906, 0.9586, 0.9233)
    repeat: (1044, 1282, 1447) (0.8144, 0.7215, 0.7651)
    filler: (1307, 1547, 1423) (0.8449, 0.9185, 0.8801)
    false_start: (861, 1391, 2244) (0.6190, 0.3837, 0.4737)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 17, 26) (0.4706, 0.3077, 0.3721)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 0, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.101094, 0.091388, 0.094845)
Item accuracy: 14820 / 17262 (0.8585)
Instance accuracy: 513 / 1316 (0.3898)

***** Iteration #62 *****
Loss: 42247.681962
Feature norm: 27.654910
Error norm: 7022.672496
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11576, 13009, 12101) (0.8898, 0.9566, 0.9220)
    repeat: (980, 1180, 1447) (0.8305, 0.6773, 0.7461)
    filler: (1304, 1518, 1423) (0.8590, 0.9164, 0.8868)
    false_start: (923, 1538, 2244) (0.6001, 0.4113, 0.4881)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 16, 26) (0.5000, 0.3077, 0.3810)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 1, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.102209, 0.090813, 0.095110)
Item accuracy: 14791 / 17262 (0.8569)
Instance accuracy: 502 / 1316 (0.3815)

***** Iteration #63 *****
Loss: 41670.970710
Feature norm: 28.586943
Error norm: 2371.319800
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 13076, 12101) (0.8892, 0.9608, 0.9236)
    repeat: (1026, 1249, 1447) (0.8215, 0.7091, 0.7611)
    filler: (1308, 1549, 1423) (0.8444, 0.9192, 0.8802)
    false_start: (856, 1371, 2244) (0.6244, 0.3815, 0.4736)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 15, 26) (0.5333, 0.3077, 0.3902)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.103132, 0.091062, 0.095244)
Item accuracy: 14825 / 17262 (0.8588)
Instance accuracy: 507 / 1316 (0.3853)

***** Iteration #64 *****
Loss: 41535.556346
Feature norm: 28.871420
Error norm: 2004.463834
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11624, 13020, 12101) (0.8928, 0.9606, 0.9254)
    repeat: (1038, 1272, 1447) (0.8160, 0.7173, 0.7635)
    filler: (1307, 1542, 1423) (0.8476, 0.9185, 0.8816)
    false_start: (895, 1411, 2244) (0.6343, 0.3988, 0.4897)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 15, 26) (0.5333, 0.3077, 0.3902)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.103446, 0.091748, 0.095849)
Item accuracy: 14872 / 17262 (0.8615)
Instance accuracy: 512 / 1316 (0.3891)

***** Iteration #65 *****
Loss: 41480.766330
Feature norm: 28.959234
Error norm: 4378.189982
Active features: 158563
Line search trials: 2
Line search step: 0.199864
Seconds required for this iteration: 1.410
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11674, 13143, 12101) (0.8882, 0.9647, 0.9249)
    repeat: (1038, 1271, 1447) (0.8167, 0.7173, 0.7638)
    filler: (1308, 1539, 1423) (0.8499, 0.9192, 0.8832)
    false_start: (834, 1292, 2244) (0.6455, 0.3717, 0.4717)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 15, 26) (0.5333, 0.3077, 0.3902)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.103713, 0.091128, 0.095384)
Item accuracy: 14862 / 17262 (0.8610)
Instance accuracy: 506 / 1316 (0.3845)

***** Iteration #66 *****
Loss: 41382.388280
Feature norm: 29.174645
Error norm: 2838.323873
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11655, 13093, 12101) (0.8902, 0.9631, 0.9252)
    repeat: (1042, 1278, 1447) (0.8153, 0.7201, 0.7648)
    filler: (1313, 1539, 1423) (0.8532, 0.9227, 0.8866)
    false_start: (853, 1335, 2244) (0.6390, 0.3801, 0.4767)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 15, 26) (0.5333, 0.3077, 0.3902)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.103637, 0.091494, 0.095652)
Item accuracy: 14871 / 17262 (0.8615)
Instance accuracy: 517 / 1316 (0.3929)

***** Iteration #67 *****
Loss: 41230.690149
Feature norm: 29.494938
Error norm: 1829.268626
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11654, 13071, 12101) (0.8916, 0.9631, 0.9259)
    repeat: (1053, 1299, 1447) (0.8106, 0.7277, 0.7669)
    filler: (1309, 1536, 1423) (0.8522, 0.9199, 0.8848)
    false_start: (861, 1339, 2244) (0.6430, 0.3837, 0.4806)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 15, 26) (0.5333, 0.3077, 0.3902)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.103633, 0.091723, 0.095791)
Item accuracy: 14885 / 17262 (0.8623)
Instance accuracy: 519 / 1316 (0.3944)

***** Iteration #68 *****
Loss: 41000.397161
Feature norm: 30.048699
Error norm: 2565.727433
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.750
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11622, 13016, 12101) (0.8929, 0.9604, 0.9254)
    repeat: (1055, 1289, 1447) (0.8185, 0.7291, 0.7712)
    filler: (1314, 1538, 1423) (0.8544, 0.9234, 0.8875)
    false_start: (887, 1402, 2244) (0.6327, 0.3953, 0.4866)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 14, 26) (0.5714, 0.3077, 0.4000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (1, 3, 4) (0.3333, 0.2500, 0.2857)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.113976, 0.099052, 0.104346)
Item accuracy: 14887 / 17262 (0.8624)
Instance accuracy: 526 / 1316 (0.3997)

***** Iteration #69 *****
Loss: 40801.902897
Feature norm: 30.621455
Error norm: 2648.798335
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11642, 13020, 12101) (0.8942, 0.9621, 0.9269)
    repeat: (1053, 1288, 1447) (0.8175, 0.7277, 0.7700)
    filler: (1303, 1526, 1423) (0.8539, 0.9157, 0.8837)
    false_start: (908, 1411, 2244) (0.6435, 0.4046, 0.4969)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 13, 26) (0.6154, 0.3077, 0.4103)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.120124, 0.106049, 0.110769)
Item accuracy: 14916 / 17262 (0.8641)
Instance accuracy: 533 / 1316 (0.4050)

***** Iteration #70 *****
Loss: 40442.088173
Feature norm: 32.296634
Error norm: 3340.245090
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12988, 12101) (0.8956, 0.9612, 0.9273)
    repeat: (1081, 1358, 1447) (0.7960, 0.7471, 0.7708)
    filler: (1291, 1512, 1423) (0.8538, 0.9072, 0.8797)
    false_start: (890, 1387, 2244) (0.6417, 0.3966, 0.4902)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 11, 26) (0.7273, 0.3077, 0.4324)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127252, 0.119996, 0.119456)
Item accuracy: 14906 / 17262 (0.8635)
Instance accuracy: 537 / 1316 (0.4081)

***** Iteration #71 *****
Loss: 40373.032793
Feature norm: 34.182465
Error norm: 5629.240161
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11604, 13008, 12101) (0.8921, 0.9589, 0.9243)
    repeat: (1001, 1189, 1447) (0.8419, 0.6918, 0.7595)
    filler: (1281, 1489, 1423) (0.8603, 0.9002, 0.8798)
    false_start: (947, 1559, 2244) (0.6074, 0.4220, 0.4980)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 11, 26) (0.7273, 0.3077, 0.4324)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127657, 0.118906, 0.119279)
Item accuracy: 14845 / 17262 (0.8600)
Instance accuracy: 530 / 1316 (0.4027)

***** Iteration #72 *****
Loss: 40028.617289
Feature norm: 33.849521
Error norm: 1974.956829
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11621, 13004, 12101) (0.8936, 0.9603, 0.9258)
    repeat: (1048, 1272, 1447) (0.8239, 0.7243, 0.7709)
    filler: (1305, 1540, 1423) (0.8474, 0.9171, 0.8809)
    false_start: (900, 1429, 2244) (0.6298, 0.4011, 0.4901)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 11, 26) (0.7273, 0.3077, 0.4324)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127464, 0.119734, 0.119445)
Item accuracy: 14886 / 17262 (0.8624)
Instance accuracy: 523 / 1316 (0.3974)

***** Iteration #73 *****
Loss: 39939.152172
Feature norm: 33.762127
Error norm: 2808.273746
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11575, 12911, 12101) (0.8965, 0.9565, 0.9256)
    repeat: (1061, 1312, 1447) (0.8087, 0.7332, 0.7691)
    filler: (1305, 1533, 1423) (0.8513, 0.9171, 0.8829)
    false_start: (910, 1489, 2244) (0.6111, 0.4055, 0.4875)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 11, 26) (0.7273, 0.3077, 0.4324)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.126710, 0.120002, 0.119378)
Item accuracy: 14863 / 17262 (0.8610)
Instance accuracy: 523 / 1316 (0.3974)

***** Iteration #74 *****
Loss: 39858.020191
Feature norm: 34.035790
Error norm: 3343.246926
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 13028, 12101) (0.8935, 0.9619, 0.9264)
    repeat: (1073, 1345, 1447) (0.7978, 0.7415, 0.7686)
    filler: (1312, 1548, 1423) (0.8475, 0.9220, 0.8832)
    false_start: (849, 1324, 2244) (0.6412, 0.3783, 0.4759)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 11, 26) (0.7273, 0.3077, 0.4324)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127054, 0.119763, 0.119072)
Item accuracy: 14886 / 17262 (0.8624)
Instance accuracy: 522 / 1316 (0.3967)

***** Iteration #75 *****
Loss: 39790.990231
Feature norm: 34.332483
Error norm: 2178.713933
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11618, 12980, 12101) (0.8951, 0.9601, 0.9264)
    repeat: (1068, 1331, 1447) (0.8024, 0.7381, 0.7689)
    filler: (1310, 1541, 1423) (0.8501, 0.9206, 0.8839)
    false_start: (883, 1393, 2244) (0.6339, 0.3935, 0.4856)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 11, 26) (0.7273, 0.3077, 0.4324)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127094, 0.119998, 0.119369)
Item accuracy: 14891 / 17262 (0.8626)
Instance accuracy: 523 / 1316 (0.3974)

***** Iteration #76 *****
Loss: 39686.152332
Feature norm: 35.101127
Error norm: 1535.566561
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11601, 12946, 12101) (0.8961, 0.9587, 0.9263)
    repeat: (1070, 1324, 1447) (0.8082, 0.7395, 0.7723)
    filler: (1299, 1518, 1423) (0.8557, 0.9129, 0.8834)
    false_start: (910, 1457, 2244) (0.6246, 0.4055, 0.4918)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 11, 26) (0.7273, 0.3077, 0.4324)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127181, 0.120117, 0.119616)
Item accuracy: 14892 / 17262 (0.8627)
Instance accuracy: 524 / 1316 (0.3982)

***** Iteration #77 *****
Loss: 39623.510959
Feature norm: 35.422420
Error norm: 1815.916380
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11593, 12921, 12101) (0.8972, 0.9580, 0.9266)
    repeat: (1071, 1324, 1447) (0.8089, 0.7402, 0.7730)
    filler: (1295, 1510, 1423) (0.8576, 0.9100, 0.8831)
    false_start: (931, 1490, 2244) (0.6248, 0.4149, 0.4987)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 11, 26) (0.7273, 0.3077, 0.4324)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127292, 0.120300, 0.119827)
Item accuracy: 14902 / 17262 (0.8633)
Instance accuracy: 522 / 1316 (0.3967)

***** Iteration #78 *****
Loss: 39396.833329
Feature norm: 36.377312
Error norm: 2588.761546
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11595, 12915, 12101) (0.8978, 0.9582, 0.9270)
    repeat: (1080, 1332, 1447) (0.8108, 0.7464, 0.7773)
    filler: (1295, 1511, 1423) (0.8570, 0.9100, 0.8828)
    false_start: (925, 1487, 2244) (0.6221, 0.4122, 0.4958)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (8, 11, 26) (0.7273, 0.3077, 0.4324)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127268, 0.120403, 0.119869)
Item accuracy: 14907 / 17262 (0.8636)
Instance accuracy: 531 / 1316 (0.4035)

***** Iteration #79 *****
Loss: 39080.531836
Feature norm: 37.623609
Error norm: 3052.861555
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11570, 12904, 12101) (0.8966, 0.9561, 0.9254)
    repeat: (1079, 1328, 1447) (0.8125, 0.7457, 0.7777)
    filler: (1289, 1503, 1423) (0.8576, 0.9058, 0.8811)
    false_start: (927, 1509, 2244) (0.6143, 0.4131, 0.4940)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (9, 12, 26) (0.7500, 0.3462, 0.4737)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127714, 0.121302, 0.120884)
Item accuracy: 14878 / 17262 (0.8619)
Instance accuracy: 521 / 1316 (0.3959)

***** Iteration #80 *****
Loss: 38933.814539
Feature norm: 38.566902
Error norm: 6359.796504
Active features: 158563
Line search trials: 2
Line search step: 0.309756
Seconds required for this iteration: 1.420
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11511, 12765, 12101) (0.9018, 0.9512, 0.9258)
    repeat: (1122, 1424, 1447) (0.7879, 0.7754, 0.7816)
    filler: (1299, 1521, 1423) (0.8540, 0.9129, 0.8825)
    false_start: (941, 1532, 2244) (0.6142, 0.4193, 0.4984)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (11, 14, 26) (0.7857, 0.4231, 0.5500)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128065, 0.124498, 0.123287)
Item accuracy: 14888 / 17262 (0.8625)
Instance accuracy: 530 / 1316 (0.4027)

***** Iteration #81 *****
Loss: 38645.623811
Feature norm: 40.652705
Error norm: 3692.568323
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11619, 12947, 12101) (0.8974, 0.9602, 0.9277)
    repeat: (1120, 1403, 1447) (0.7983, 0.7740, 0.7860)
    filler: (1302, 1520, 1423) (0.8566, 0.9150, 0.8848)
    false_start: (892, 1372, 2244) (0.6501, 0.3975, 0.4934)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (11, 14, 26) (0.7857, 0.4231, 0.5500)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.129301, 0.124159, 0.123385)
Item accuracy: 14948 / 17262 (0.8659)
Instance accuracy: 531 / 1316 (0.4035)

***** Iteration #82 *****
Loss: 38491.347834
Feature norm: 40.437101
Error norm: 1787.446683
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11590, 12893, 12101) (0.8989, 0.9578, 0.9274)
    repeat: (1115, 1370, 1447) (0.8139, 0.7706, 0.7916)
    filler: (1311, 1528, 1423) (0.8580, 0.9213, 0.8885)
    false_start: (925, 1451, 2244) (0.6375, 0.4122, 0.5007)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (11, 14, 26) (0.7857, 0.4231, 0.5500)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.129463, 0.124581, 0.123840)
Item accuracy: 14956 / 17262 (0.8664)
Instance accuracy: 530 / 1316 (0.4027)

***** Iteration #83 *****
Loss: 38385.925989
Feature norm: 40.062607
Error norm: 1582.160694
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11554, 12844, 12101) (0.8996, 0.9548, 0.9264)
    repeat: (1109, 1351, 1447) (0.8209, 0.7664, 0.7927)
    filler: (1313, 1532, 1423) (0.8570, 0.9227, 0.8887)
    false_start: (946, 1515, 2244) (0.6244, 0.4216, 0.5033)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (11, 14, 26) (0.7857, 0.4231, 0.5500)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.129286, 0.124682, 0.123918)
Item accuracy: 14937 / 17262 (0.8653)
Instance accuracy: 525 / 1316 (0.3989)

***** Iteration #84 *****
Loss: 38236.854760
Feature norm: 40.766166
Error norm: 2447.611791
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.740
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11544, 12822, 12101) (0.9003, 0.9540, 0.9264)
    repeat: (1096, 1316, 1447) (0.8328, 0.7574, 0.7933)
    filler: (1314, 1526, 1423) (0.8611, 0.9234, 0.8911)
    false_start: (963, 1576, 2244) (0.6110, 0.4291, 0.5042)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 16, 26) (0.8125, 0.5000, 0.6190)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.130123, 0.126776, 0.125947)
Item accuracy: 14934 / 17262 (0.8651)
Instance accuracy: 527 / 1316 (0.4005)

***** Iteration #85 *****
Loss: 38015.020854
Feature norm: 41.127364
Error norm: 1928.393191
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11568, 12874, 12101) (0.8986, 0.9560, 0.9264)
    repeat: (1097, 1318, 1447) (0.8323, 0.7581, 0.7935)
    filler: (1312, 1517, 1423) (0.8649, 0.9220, 0.8925)
    false_start: (941, 1531, 2244) (0.6146, 0.4193, 0.4985)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 16, 26) (0.8125, 0.5000, 0.6190)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.130265, 0.126539, 0.125832)
Item accuracy: 14935 / 17262 (0.8652)
Instance accuracy: 527 / 1316 (0.4005)

***** Iteration #86 *****
Loss: 37745.101565
Feature norm: 42.430115
Error norm: 2137.790716
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11570, 12859, 12101) (0.8998, 0.9561, 0.9271)
    repeat: (1096, 1313, 1447) (0.8347, 0.7574, 0.7942)
    filler: (1300, 1505, 1423) (0.8638, 0.9136, 0.8880)
    false_start: (948, 1561, 2244) (0.6073, 0.4225, 0.4983)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 18, 26) (0.7222, 0.5000, 0.5909)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127624, 0.126377, 0.124957)
Item accuracy: 14931 / 17262 (0.8650)
Instance accuracy: 530 / 1316 (0.4027)

***** Iteration #87 *****
Loss: 37686.280154
Feature norm: 42.114371
Error norm: 7931.940914
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11682, 13083, 12101) (0.8929, 0.9654, 0.9277)
    repeat: (1072, 1263, 1447) (0.8488, 0.7408, 0.7911)
    filler: (1293, 1500, 1423) (0.8620, 0.9086, 0.8847)
    false_start: (885, 1392, 2244) (0.6358, 0.3944, 0.4868)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 18, 26) (0.7222, 0.5000, 0.5909)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128565, 0.125257, 0.124480)
Item accuracy: 14949 / 17262 (0.8660)
Instance accuracy: 534 / 1316 (0.4058)

***** Iteration #88 *****
Loss: 37445.122133
Feature norm: 42.856175
Error norm: 3894.213867
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11533, 12763, 12101) (0.9036, 0.9531, 0.9277)
    repeat: (1098, 1315, 1447) (0.8350, 0.7588, 0.7951)
    filler: (1290, 1504, 1423) (0.8577, 0.9065, 0.8814)
    false_start: (1002, 1656, 2244) (0.6051, 0.4465, 0.5138)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 18, 26) (0.7222, 0.5000, 0.5909)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127508, 0.126804, 0.125249)
Item accuracy: 14940 / 17262 (0.8655)
Instance accuracy: 536 / 1316 (0.4073)

***** Iteration #89 *****
Loss: 37373.260438
Feature norm: 42.881487
Error norm: 1958.254730
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11572, 12849, 12101) (0.9006, 0.9563, 0.9276)
    repeat: (1102, 1315, 1447) (0.8380, 0.7616, 0.7980)
    filler: (1291, 1502, 1423) (0.8595, 0.9072, 0.8827)
    false_start: (960, 1572, 2244) (0.6107, 0.4278, 0.5031)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 18, 26) (0.7222, 0.5000, 0.5909)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127715, 0.126470, 0.125066)
Item accuracy: 14942 / 17262 (0.8656)
Instance accuracy: 536 / 1316 (0.4073)

***** Iteration #90 *****
Loss: 37304.620802
Feature norm: 43.288593
Error norm: 1366.133244
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11596, 12881, 12101) (0.9002, 0.9583, 0.9283)
    repeat: (1100, 1313, 1447) (0.8378, 0.7602, 0.7971)
    filler: (1291, 1502, 1423) (0.8595, 0.9072, 0.8827)
    false_start: (956, 1542, 2244) (0.6200, 0.4260, 0.5050)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 18, 26) (0.7222, 0.5000, 0.5909)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127956, 0.126437, 0.125114)
Item accuracy: 14960 / 17262 (0.8666)
Instance accuracy: 535 / 1316 (0.4065)

***** Iteration #91 *****
Loss: 37135.871904
Feature norm: 44.482994
Error norm: 2458.959524
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11594, 12882, 12101) (0.9000, 0.9581, 0.9282)
    repeat: (1106, 1333, 1447) (0.8297, 0.7643, 0.7957)
    filler: (1301, 1514, 1423) (0.8593, 0.9143, 0.8859)
    false_start: (940, 1508, 2244) (0.6233, 0.4189, 0.5011)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 19, 26) (0.6842, 0.5000, 0.5778)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.126757, 0.126545, 0.124684)
Item accuracy: 14958 / 17262 (0.8665)
Instance accuracy: 532 / 1316 (0.4043)

***** Iteration #92 *****
Loss: 37008.736711
Feature norm: 45.644128
Error norm: 2379.463239
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11598, 12882, 12101) (0.9003, 0.9584, 0.9285)
    repeat: (1105, 1343, 1447) (0.8228, 0.7636, 0.7921)
    filler: (1303, 1512, 1423) (0.8618, 0.9157, 0.8879)
    false_start: (934, 1500, 2244) (0.6227, 0.4162, 0.4989)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 19, 26) (0.6842, 0.5000, 0.5778)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.126623, 0.126499, 0.124589)
Item accuracy: 14957 / 17262 (0.8665)
Instance accuracy: 529 / 1316 (0.4020)

***** Iteration #93 *****
Loss: 36887.882852
Feature norm: 47.105034
Error norm: 3115.457172
Active features: 158563
Line search trials: 2
Line search step: 0.466077
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11599, 12876, 12101) (0.9008, 0.9585, 0.9288)
    repeat: (1119, 1386, 1447) (0.8074, 0.7733, 0.7900)
    filler: (1306, 1522, 1423) (0.8581, 0.9178, 0.8869)
    false_start: (916, 1452, 2244) (0.6309, 0.4082, 0.4957)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 20, 26) (0.6500, 0.5000, 0.5652)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.125383, 0.126606, 0.124071)
Item accuracy: 14957 / 17262 (0.8665)
Instance accuracy: 530 / 1316 (0.4027)

***** Iteration #94 *****
Loss: 36793.146311
Feature norm: 47.902766
Error norm: 1237.068005
Active features: 158563
Line search trials: 2
Line search step: 0.457147
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11599, 12873, 12101) (0.9010, 0.9585, 0.9289)
    repeat: (1104, 1338, 1447) (0.8251, 0.7630, 0.7928)
    filler: (1303, 1512, 1423) (0.8618, 0.9157, 0.8879)
    false_start: (943, 1513, 2244) (0.6233, 0.4202, 0.5020)
    arg1: (0, 1, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 20, 26) (0.6500, 0.5000, 0.5652)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123922, 0.119649, 0.120652)
Item accuracy: 14965 / 17262 (0.8669)
Instance accuracy: 534 / 1316 (0.4058)

***** Iteration #95 *****
Loss: 36755.876885
Feature norm: 48.201655
Error norm: 3258.578761
Active features: 158563
Line search trials: 2
Line search step: 0.365060
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11613, 12919, 12101) (0.8989, 0.9597, 0.9283)
    repeat: (1105, 1336, 1447) (0.8271, 0.7636, 0.7941)
    filler: (1302, 1511, 1423) (0.8617, 0.9150, 0.8875)
    false_start: (919, 1470, 2244) (0.6252, 0.4095, 0.4949)
    arg1: (0, 1, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 20, 26) (0.6500, 0.5000, 0.5652)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123968, 0.119384, 0.120464)
Item accuracy: 14955 / 17262 (0.8664)
Instance accuracy: 533 / 1316 (0.4050)

***** Iteration #96 *****
Loss: 36703.041298
Feature norm: 48.332068
Error norm: 1113.294060
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11602, 12862, 12101) (0.9020, 0.9588, 0.9295)
    repeat: (1104, 1335, 1447) (0.8270, 0.7630, 0.7937)
    filler: (1303, 1509, 1423) (0.8635, 0.9157, 0.8888)
    false_start: (961, 1530, 2244) (0.6281, 0.4283, 0.5093)
    arg1: (0, 1, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 20, 26) (0.6500, 0.5000, 0.5652)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124183, 0.119879, 0.120922)
Item accuracy: 14986 / 17262 (0.8681)
Instance accuracy: 534 / 1316 (0.4058)

***** Iteration #97 *****
Loss: 36685.133922
Feature norm: 48.333697
Error norm: 1278.973818
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11599, 12845, 12101) (0.9030, 0.9585, 0.9299)
    repeat: (1103, 1335, 1447) (0.8262, 0.7623, 0.7930)
    filler: (1303, 1509, 1423) (0.8635, 0.9157, 0.8888)
    false_start: (973, 1547, 2244) (0.6290, 0.4336, 0.5133)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 21, 26) (0.6190, 0.5000, 0.5532)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123353, 0.120002, 0.120691)
Item accuracy: 14994 / 17262 (0.8686)
Instance accuracy: 537 / 1316 (0.4081)

***** Iteration #98 *****
Loss: 36654.169265
Feature norm: 48.390422
Error norm: 2055.762178
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11580, 12825, 12101) (0.9029, 0.9569, 0.9292)
    repeat: (1102, 1333, 1447) (0.8267, 0.7616, 0.7928)
    filler: (1303, 1509, 1423) (0.8635, 0.9157, 0.8888)
    false_start: (971, 1568, 2244) (0.6193, 0.4327, 0.5094)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 22, 26) (0.6364, 0.5385, 0.5833)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123576, 0.120982, 0.121395)
Item accuracy: 14973 / 17262 (0.8674)
Instance accuracy: 537 / 1316 (0.4081)

***** Iteration #99 *****
Loss: 36581.886097
Feature norm: 48.624174
Error norm: 2979.452625
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11568, 12787, 12101) (0.9047, 0.9560, 0.9296)
    repeat: (1104, 1333, 1447) (0.8282, 0.7630, 0.7942)
    filler: (1302, 1511, 1423) (0.8617, 0.9150, 0.8875)
    false_start: (995, 1604, 2244) (0.6203, 0.4434, 0.5172)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 22, 26) (0.6364, 0.5385, 0.5833)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123646, 0.121271, 0.121626)
Item accuracy: 14986 / 17262 (0.8681)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #100 *****
Loss: 36473.971754
Feature norm: 49.116702
Error norm: 2768.974022
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11551, 12788, 12101) (0.9033, 0.9545, 0.9282)
    repeat: (1108, 1344, 1447) (0.8244, 0.7657, 0.7940)
    filler: (1303, 1520, 1423) (0.8572, 0.9157, 0.8855)
    false_start: (966, 1583, 2244) (0.6102, 0.4305, 0.5048)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 23, 26) (0.6087, 0.5385, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.119551, 0.114025, 0.116220)
Item accuracy: 14944 / 17262 (0.8657)
Instance accuracy: 536 / 1316 (0.4073)

***** Iteration #101 *****
Loss: 36237.705956
Feature norm: 50.118316
Error norm: 2980.635862
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11556, 12797, 12101) (0.9030, 0.9550, 0.9283)
    repeat: (1112, 1348, 1447) (0.8249, 0.7685, 0.7957)
    filler: (1301, 1513, 1423) (0.8599, 0.9143, 0.8862)
    false_start: (961, 1577, 2244) (0.6094, 0.4283, 0.5030)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 25, 26) (0.5600, 0.5385, 0.5490)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.104367, 0.100123, 0.101729)
Item accuracy: 14944 / 17262 (0.8657)
Instance accuracy: 535 / 1316 (0.4065)

***** Iteration #102 *****
Loss: 36120.403615
Feature norm: 50.854672
Error norm: 2753.595742
Active features: 158563
Line search trials: 2
Line search step: 0.356281
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11559, 12784, 12101) (0.9042, 0.9552, 0.9290)
    repeat: (1131, 1391, 1447) (0.8131, 0.7816, 0.7970)
    filler: (1311, 1544, 1423) (0.8491, 0.9213, 0.8837)
    false_start: (938, 1515, 2244) (0.6191, 0.4180, 0.4991)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 26, 26) (0.5769, 0.5769, 0.5769)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.104512, 0.101474, 0.102382)
Item accuracy: 14954 / 17262 (0.8663)
Instance accuracy: 527 / 1316 (0.4005)

***** Iteration #103 *****
Loss: 35933.621424
Feature norm: 51.614042
Error norm: 1651.410230
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11595, 12850, 12101) (0.9023, 0.9582, 0.9294)
    repeat: (1131, 1386, 1447) (0.8160, 0.7816, 0.7984)
    filler: (1305, 1536, 1423) (0.8496, 0.9171, 0.8821)
    false_start: (920, 1462, 2244) (0.6293, 0.4100, 0.4965)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 26, 26) (0.5769, 0.5769, 0.5769)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.104838, 0.101216, 0.102315)
Item accuracy: 14966 / 17262 (0.8670)
Instance accuracy: 517 / 1316 (0.3929)

***** Iteration #104 *****
Loss: 35832.900536
Feature norm: 52.713269
Error norm: 4758.152846
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11497, 12694, 12101) (0.9057, 0.9501, 0.9274)
    repeat: (1122, 1368, 1447) (0.8202, 0.7754, 0.7972)
    filler: (1303, 1536, 1423) (0.8483, 0.9157, 0.8807)
    false_start: (977, 1637, 2244) (0.5968, 0.4354, 0.5035)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 25, 26) (0.6000, 0.5769, 0.5882)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.104750, 0.101485, 0.102693)
Item accuracy: 14914 / 17262 (0.8640)
Instance accuracy: 510 / 1316 (0.3875)

***** Iteration #105 *****
Loss: 35747.265074
Feature norm: 52.783753
Error norm: 2789.367995
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11616, 12918, 12101) (0.8992, 0.9599, 0.9286)
    repeat: (1118, 1360, 1447) (0.8221, 0.7726, 0.7966)
    filler: (1305, 1523, 1423) (0.8569, 0.9171, 0.8859)
    false_start: (890, 1434, 2244) (0.6206, 0.3966, 0.4840)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 25, 26) (0.6000, 0.5769, 0.5882)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.105521, 0.100644, 0.102314)
Item accuracy: 14944 / 17262 (0.8657)
Instance accuracy: 514 / 1316 (0.3906)

***** Iteration #106 *****
Loss: 35713.799959
Feature norm: 52.598512
Error norm: 1481.222687
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11591, 12848, 12101) (0.9022, 0.9579, 0.9292)
    repeat: (1121, 1369, 1447) (0.8188, 0.7747, 0.7962)
    filler: (1304, 1527, 1423) (0.8540, 0.9164, 0.8841)
    false_start: (925, 1491, 2244) (0.6204, 0.4122, 0.4953)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 25, 26) (0.6000, 0.5769, 0.5882)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.105427, 0.101057, 0.102582)
Item accuracy: 14956 / 17262 (0.8664)
Instance accuracy: 513 / 1316 (0.3898)

***** Iteration #107 *****
Loss: 35681.726166
Feature norm: 52.528107
Error norm: 1079.825870
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11562, 12799, 12101) (0.9034, 0.9555, 0.9287)
    repeat: (1119, 1367, 1447) (0.8186, 0.7733, 0.7953)
    filler: (1304, 1525, 1423) (0.8551, 0.9164, 0.8847)
    false_start: (948, 1544, 2244) (0.6140, 0.4225, 0.5005)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 25, 26) (0.6000, 0.5769, 0.5882)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.105306, 0.101237, 0.102706)
Item accuracy: 14948 / 17262 (0.8659)
Instance accuracy: 513 / 1316 (0.3898)

***** Iteration #108 *****
Loss: 35613.950118
Feature norm: 52.592367
Error norm: 1536.862889
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11547, 12762, 12101) (0.9048, 0.9542, 0.9289)
    repeat: (1119, 1370, 1447) (0.8168, 0.7733, 0.7945)
    filler: (1306, 1532, 1423) (0.8525, 0.9178, 0.8839)
    false_start: (963, 1571, 2244) (0.6130, 0.4291, 0.5048)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 25, 26) (0.6000, 0.5769, 0.5882)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.105196, 0.101427, 0.102787)
Item accuracy: 14950 / 17262 (0.8661)
Instance accuracy: 517 / 1316 (0.3929)

***** Iteration #109 *****
Loss: 35494.881803
Feature norm: 52.888191
Error norm: 2187.482244
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11533, 12745, 12101) (0.9049, 0.9531, 0.9284)
    repeat: (1113, 1363, 1447) (0.8166, 0.7692, 0.7922)
    filler: (1304, 1530, 1423) (0.8523, 0.9164, 0.8832)
    false_start: (965, 1597, 2244) (0.6043, 0.4300, 0.5025)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 25, 26) (0.6000, 0.5769, 0.5882)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.104945, 0.101266, 0.102622)
Item accuracy: 14930 / 17262 (0.8649)
Instance accuracy: 519 / 1316 (0.3944)

***** Iteration #110 *****
Loss: 35334.653677
Feature norm: 54.199346
Error norm: 2809.748986
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11549, 12765, 12101) (0.9047, 0.9544, 0.9289)
    repeat: (1121, 1379, 1447) (0.8129, 0.7747, 0.7933)
    filler: (1305, 1533, 1423) (0.8513, 0.9171, 0.8829)
    false_start: (954, 1559, 2244) (0.6119, 0.4251, 0.5017)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 24, 26) (0.6250, 0.5769, 0.6000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.105718, 0.101340, 0.102970)
Item accuracy: 14944 / 17262 (0.8657)
Instance accuracy: 519 / 1316 (0.3944)

***** Iteration #111 *****
Loss: 35246.075022
Feature norm: 55.023024
Error norm: 4190.090958
Active features: 158563
Line search trials: 2
Line search step: 0.426568
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11557, 12762, 12101) (0.9056, 0.9550, 0.9297)
    repeat: (1112, 1357, 1447) (0.8195, 0.7685, 0.7932)
    filler: (1304, 1525, 1423) (0.8551, 0.9164, 0.8847)
    false_start: (979, 1592, 2244) (0.6149, 0.4363, 0.5104)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 24, 26) (0.6250, 0.5769, 0.6000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.106113, 0.101475, 0.103275)
Item accuracy: 14967 / 17262 (0.8670)
Instance accuracy: 523 / 1316 (0.3974)

***** Iteration #112 *****
Loss: 35144.877694
Feature norm: 55.629733
Error norm: 1805.351283
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11593, 12873, 12101) (0.9006, 0.9580, 0.9284)
    repeat: (1114, 1353, 1447) (0.8234, 0.7699, 0.7957)
    filler: (1304, 1528, 1423) (0.8534, 0.9164, 0.8838)
    false_start: (932, 1484, 2244) (0.6280, 0.4153, 0.5000)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 22, 26) (0.6818, 0.5769, 0.6250)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107977, 0.101014, 0.103691)
Item accuracy: 14958 / 17262 (0.8665)
Instance accuracy: 527 / 1316 (0.4005)

***** Iteration #113 *****
Loss: 35096.689431
Feature norm: 55.956145
Error norm: 1892.712204
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11591, 12878, 12101) (0.9001, 0.9579, 0.9281)
    repeat: (1119, 1359, 1447) (0.8234, 0.7733, 0.7976)
    filler: (1304, 1522, 1423) (0.8568, 0.9164, 0.8856)
    false_start: (931, 1479, 2244) (0.6295, 0.4149, 0.5001)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 22, 26) (0.6818, 0.5769, 0.6250)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.108098, 0.101093, 0.103787)
Item accuracy: 14960 / 17262 (0.8666)
Instance accuracy: 522 / 1316 (0.3967)

***** Iteration #114 *****
Loss: 34991.769889
Feature norm: 56.826430
Error norm: 1971.745592
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11594, 12855, 12101) (0.9019, 0.9581, 0.9292)
    repeat: (1123, 1376, 1447) (0.8161, 0.7761, 0.7956)
    filler: (1309, 1532, 1423) (0.8544, 0.9199, 0.8860)
    false_start: (932, 1475, 2244) (0.6319, 0.4153, 0.5012)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 22, 26) (0.6818, 0.5769, 0.6250)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107949, 0.101287, 0.103804)
Item accuracy: 14973 / 17262 (0.8674)
Instance accuracy: 522 / 1316 (0.3967)

***** Iteration #115 *****
Loss: 34935.590489
Feature norm: 56.742919
Error norm: 1406.740917
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11599, 12866, 12101) (0.9015, 0.9585, 0.9291)
    repeat: (1127, 1375, 1447) (0.8196, 0.7789, 0.7987)
    filler: (1309, 1533, 1423) (0.8539, 0.9199, 0.8857)
    false_start: (929, 1464, 2244) (0.6346, 0.4140, 0.5011)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 22, 26) (0.6818, 0.5769, 0.6250)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.108095, 0.101338, 0.103878)
Item accuracy: 14979 / 17262 (0.8677)
Instance accuracy: 525 / 1316 (0.3989)

***** Iteration #116 *****
Loss: 34829.360564
Feature norm: 56.844896
Error norm: 1067.328705
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11605, 12895, 12101) (0.9000, 0.9590, 0.9285)
    repeat: (1124, 1371, 1447) (0.8198, 0.7768, 0.7977)
    filler: (1306, 1528, 1423) (0.8547, 0.9178, 0.8851)
    false_start: (908, 1444, 2244) (0.6288, 0.4046, 0.4924)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 22, 26) (0.6818, 0.5769, 0.6250)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107921, 0.100976, 0.103578)
Item accuracy: 14958 / 17262 (0.8665)
Instance accuracy: 523 / 1316 (0.3974)

***** Iteration #117 *****
Loss: 34646.624801
Feature norm: 57.364925
Error norm: 1297.019437
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11604, 12906, 12101) (0.8991, 0.9589, 0.9281)
    repeat: (1125, 1365, 1447) (0.8242, 0.7775, 0.8001)
    filler: (1308, 1524, 1423) (0.8583, 0.9192, 0.8877)
    false_start: (910, 1443, 2244) (0.6306, 0.4055, 0.4936)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 20, 26) (0.7500, 0.5769, 0.6522)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123950, 0.114945, 0.118380)
Item accuracy: 14964 / 17262 (0.8669)
Instance accuracy: 528 / 1316 (0.4012)

***** Iteration #118 *****
Loss: 34468.005152
Feature norm: 58.119537
Error norm: 1731.134120
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11595, 12881, 12101) (0.9002, 0.9582, 0.9283)
    repeat: (1125, 1363, 1447) (0.8254, 0.7775, 0.8007)
    filler: (1312, 1530, 1423) (0.8575, 0.9220, 0.8886)
    false_start: (920, 1464, 2244) (0.6284, 0.4100, 0.4962)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 20, 26) (0.7500, 0.5769, 0.6522)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123930, 0.115127, 0.118499)
Item accuracy: 14969 / 17262 (0.8672)
Instance accuracy: 531 / 1316 (0.4035)

***** Iteration #119 *****
Loss: 34432.256480
Feature norm: 58.248607
Error norm: 1812.989256
Active features: 158563
Line search trials: 2
Line search step: 0.143318
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11565, 12825, 12101) (0.9018, 0.9557, 0.9279)
    repeat: (1116, 1343, 1447) (0.8310, 0.7713, 0.8000)
    filler: (1312, 1524, 1423) (0.8609, 0.9220, 0.8904)
    false_start: (952, 1546, 2244) (0.6158, 0.4242, 0.5024)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 20, 26) (0.7500, 0.5769, 0.6522)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123872, 0.115281, 0.118691)
Item accuracy: 14962 / 17262 (0.8668)
Instance accuracy: 530 / 1316 (0.4027)

***** Iteration #120 *****
Loss: 34312.903518
Feature norm: 59.204432
Error norm: 1048.932108
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11553, 12816, 12101) (0.9015, 0.9547, 0.9273)
    repeat: (1113, 1343, 1447) (0.8287, 0.7692, 0.7978)
    filler: (1311, 1526, 1423) (0.8591, 0.9213, 0.8891)
    false_start: (949, 1553, 2244) (0.6111, 0.4229, 0.4999)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 20, 26) (0.7500, 0.5769, 0.6522)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123622, 0.115139, 0.118509)
Item accuracy: 14943 / 17262 (0.8657)
Instance accuracy: 522 / 1316 (0.3967)

***** Iteration #121 *****
Loss: 34273.865662
Feature norm: 59.665626
Error norm: 3111.722973
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11600, 12926, 12101) (0.8974, 0.9586, 0.9270)
    repeat: (1099, 1316, 1447) (0.8351, 0.7595, 0.7955)
    filler: (1309, 1514, 1423) (0.8646, 0.9199, 0.8914)
    false_start: (906, 1482, 2244) (0.6113, 0.4037, 0.4863)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 20, 26) (0.7500, 0.5769, 0.6522)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123846, 0.114407, 0.118122)
Item accuracy: 14931 / 17262 (0.8650)
Instance accuracy: 524 / 1316 (0.3982)

***** Iteration #122 *****
Loss: 34208.515126
Feature norm: 59.913567
Error norm: 1246.473257
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11563, 12847, 12101) (0.9001, 0.9555, 0.9270)
    repeat: (1114, 1351, 1447) (0.8246, 0.7699, 0.7963)
    filler: (1311, 1520, 1423) (0.8625, 0.9213, 0.8909)
    false_start: (934, 1520, 2244) (0.6145, 0.4162, 0.4963)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 20, 26) (0.7500, 0.5769, 0.6522)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123656, 0.114996, 0.118406)
Item accuracy: 14939 / 17262 (0.8654)
Instance accuracy: 523 / 1316 (0.3974)

***** Iteration #123 *****
Loss: 34169.716009
Feature norm: 59.949387
Error norm: 1035.741404
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11565, 12827, 12101) (0.9016, 0.9557, 0.9279)
    repeat: (1115, 1358, 1447) (0.8211, 0.7706, 0.7950)
    filler: (1312, 1523, 1423) (0.8615, 0.9220, 0.8907)
    false_start: (949, 1530, 2244) (0.6203, 0.4229, 0.5029)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 20, 26) (0.7500, 0.5769, 0.6522)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123733, 0.115225, 0.118574)
Item accuracy: 14958 / 17262 (0.8665)
Instance accuracy: 525 / 1316 (0.3989)

***** Iteration #124 *****
Loss: 34122.548969
Feature norm: 59.997918
Error norm: 1730.527974
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11581, 12851, 12101) (0.9012, 0.9570, 0.9283)
    repeat: (1120, 1367, 1447) (0.8193, 0.7740, 0.7960)
    filler: (1311, 1526, 1423) (0.8591, 0.9213, 0.8891)
    false_start: (936, 1494, 2244) (0.6265, 0.4171, 0.5008)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 20, 26) (0.7500, 0.5769, 0.6522)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123781, 0.115177, 0.118510)
Item accuracy: 14965 / 17262 (0.8669)
Instance accuracy: 530 / 1316 (0.4027)

***** Iteration #125 *****
Loss: 34048.693784
Feature norm: 60.149716
Error norm: 2304.257298
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11559, 12840, 12101) (0.9002, 0.9552, 0.9269)
    repeat: (1118, 1364, 1447) (0.8196, 0.7726, 0.7954)
    filler: (1315, 1527, 1423) (0.8612, 0.9241, 0.8915)
    false_start: (930, 1507, 2244) (0.6171, 0.4144, 0.4959)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 20, 26) (0.7500, 0.5769, 0.6522)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123560, 0.115092, 0.118387)
Item accuracy: 14939 / 17262 (0.8654)
Instance accuracy: 529 / 1316 (0.4020)

***** Iteration #126 *****
Loss: 33963.768129
Feature norm: 60.468192
Error norm: 2324.160840
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11611, 12936, 12101) (0.8976, 0.9595, 0.9275)
    repeat: (1133, 1387, 1447) (0.8169, 0.7830, 0.7996)
    filler: (1314, 1534, 1423) (0.8566, 0.9234, 0.8887)
    false_start: (882, 1381, 2244) (0.6387, 0.3930, 0.4866)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 20, 26) (0.7500, 0.5769, 0.6522)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123880, 0.114886, 0.118184)
Item accuracy: 14957 / 17262 (0.8665)
Instance accuracy: 528 / 1316 (0.4012)

***** Iteration #127 *****
Loss: 33858.998033
Feature norm: 61.028725
Error norm: 1686.609005
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11609, 12942, 12101) (0.8970, 0.9593, 0.9271)
    repeat: (1114, 1346, 1447) (0.8276, 0.7699, 0.7977)
    filler: (1305, 1509, 1423) (0.8648, 0.9171, 0.8902)
    false_start: (911, 1442, 2244) (0.6318, 0.4060, 0.4943)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123835, 0.113631, 0.117543)
Item accuracy: 14955 / 17262 (0.8664)
Instance accuracy: 529 / 1316 (0.4020)

***** Iteration #128 *****
Loss: 33781.006965
Feature norm: 61.197753
Error norm: 1510.202677
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11624, 12968, 12101) (0.8964, 0.9606, 0.9274)
    repeat: (1113, 1346, 1447) (0.8269, 0.7692, 0.7970)
    filler: (1305, 1510, 1423) (0.8642, 0.9171, 0.8899)
    false_start: (898, 1415, 2244) (0.6346, 0.4002, 0.4908)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123860, 0.113485, 0.117425)
Item accuracy: 14956 / 17262 (0.8664)
Instance accuracy: 528 / 1316 (0.4012)

***** Iteration #129 *****
Loss: 33659.185938
Feature norm: 62.052906
Error norm: 3366.736301
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11572, 12849, 12101) (0.9006, 0.9563, 0.9276)
    repeat: (1118, 1362, 1447) (0.8209, 0.7726, 0.7960)
    filler: (1317, 1531, 1423) (0.8602, 0.9255, 0.8917)
    false_start: (945, 1498, 2244) (0.6308, 0.4211, 0.5051)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 18, 26) (0.7222, 0.5000, 0.5909)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123188, 0.113210, 0.116980)
Item accuracy: 14967 / 17262 (0.8670)
Instance accuracy: 520 / 1316 (0.3951)

***** Iteration #130 *****
Loss: 33599.510258
Feature norm: 62.272838
Error norm: 2761.643150
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11643, 13007, 12101) (0.8951, 0.9622, 0.9274)
    repeat: (1116, 1339, 1447) (0.8335, 0.7713, 0.8011)
    filler: (1313, 1517, 1423) (0.8655, 0.9227, 0.8932)
    false_start: (880, 1376, 2244) (0.6395, 0.3922, 0.4862)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124180, 0.113520, 0.117505)
Item accuracy: 14968 / 17262 (0.8671)
Instance accuracy: 525 / 1316 (0.3989)

***** Iteration #131 *****
Loss: 33568.648379
Feature norm: 62.172863
Error norm: 1576.833845
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11625, 12973, 12101) (0.8961, 0.9607, 0.9273)
    repeat: (1118, 1348, 1447) (0.8294, 0.7726, 0.8000)
    filler: (1315, 1521, 1423) (0.8646, 0.9241, 0.8933)
    false_start: (889, 1398, 2244) (0.6359, 0.3962, 0.4882)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 18, 26) (0.7222, 0.5000, 0.5909)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123560, 0.112599, 0.116658)
Item accuracy: 14962 / 17262 (0.8668)
Instance accuracy: 526 / 1316 (0.3997)

***** Iteration #132 *****
Loss: 33528.019664
Feature norm: 62.195349
Error norm: 749.011994
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11622, 12956, 12101) (0.8970, 0.9604, 0.9276)
    repeat: (1117, 1351, 1447) (0.8268, 0.7719, 0.7984)
    filler: (1314, 1522, 1423) (0.8633, 0.9234, 0.8924)
    false_start: (901, 1410, 2244) (0.6390, 0.4015, 0.4932)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123973, 0.113770, 0.117606)
Item accuracy: 14970 / 17262 (0.8672)
Instance accuracy: 526 / 1316 (0.3997)

***** Iteration #133 *****
Loss: 33479.916836
Feature norm: 62.378540
Error norm: 1460.922206
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11590, 12909, 12101) (0.8978, 0.9578, 0.9268)
    repeat: (1118, 1358, 1447) (0.8233, 0.7726, 0.7971)
    filler: (1314, 1521, 1423) (0.8639, 0.9234, 0.8927)
    false_start: (913, 1451, 2244) (0.6292, 0.4069, 0.4942)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123641, 0.113865, 0.117585)
Item accuracy: 14951 / 17262 (0.8661)
Instance accuracy: 524 / 1316 (0.3982)

***** Iteration #134 *****
Loss: 33432.847425
Feature norm: 62.692127
Error norm: 1675.180739
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11594, 12902, 12101) (0.8986, 0.9581, 0.9274)
    repeat: (1122, 1361, 1447) (0.8244, 0.7754, 0.7991)
    filler: (1315, 1525, 1423) (0.8623, 0.9241, 0.8921)
    false_start: (914, 1451, 2244) (0.6299, 0.4073, 0.4947)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123668, 0.113983, 0.117656)
Item accuracy: 14961 / 17262 (0.8667)
Instance accuracy: 525 / 1316 (0.3989)

***** Iteration #135 *****
Loss: 33381.104440
Feature norm: 63.000693
Error norm: 3508.548030
Active features: 158563
Line search trials: 2
Line search step: 0.412559
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11581, 12846, 12101) (0.9015, 0.9570, 0.9284)
    repeat: (1103, 1327, 1447) (0.8312, 0.7623, 0.7952)
    filler: (1308, 1507, 1423) (0.8679, 0.9192, 0.8928)
    false_start: (975, 1559, 2244) (0.6254, 0.4345, 0.5128)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123970, 0.114206, 0.118097)
Item accuracy: 14983 / 17262 (0.8680)
Instance accuracy: 526 / 1316 (0.3997)

***** Iteration #136 *****
Loss: 33294.401589
Feature norm: 63.459089
Error norm: 1649.186761
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11617, 12904, 12101) (0.9003, 0.9600, 0.9292)
    repeat: (1114, 1336, 1447) (0.8338, 0.7699, 0.8006)
    filler: (1308, 1508, 1423) (0.8674, 0.9192, 0.8925)
    false_start: (952, 1491, 2244) (0.6385, 0.4242, 0.5098)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124356, 0.114216, 0.118174)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 532 / 1316 (0.4043)

***** Iteration #137 *****
Loss: 33243.403172
Feature norm: 63.723037
Error norm: 818.618126
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11626, 12933, 12101) (0.8989, 0.9607, 0.9288)
    repeat: (1112, 1331, 1447) (0.8355, 0.7685, 0.8006)
    filler: (1301, 1505, 1423) (0.8645, 0.9143, 0.8887)
    false_start: (941, 1470, 2244) (0.6401, 0.4193, 0.5067)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124329, 0.113925, 0.117972)
Item accuracy: 14996 / 17262 (0.8687)
Instance accuracy: 532 / 1316 (0.4043)

***** Iteration #138 *****
Loss: 33211.969583
Feature norm: 63.833144
Error norm: 897.425429
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11613, 12923, 12101) (0.8986, 0.9597, 0.9281)
    repeat: (1113, 1342, 1447) (0.8294, 0.7692, 0.7981)
    filler: (1301, 1506, 1423) (0.8639, 0.9143, 0.8884)
    false_start: (933, 1468, 2244) (0.6356, 0.4158, 0.5027)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124007, 0.113815, 0.117766)
Item accuracy: 14976 / 17262 (0.8676)
Instance accuracy: 528 / 1316 (0.4012)

***** Iteration #139 *****
Loss: 33172.976283
Feature norm: 63.894950
Error norm: 3361.851871
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11658, 13007, 12101) (0.8963, 0.9634, 0.9286)
    repeat: (1108, 1328, 1447) (0.8343, 0.7657, 0.7986)
    filler: (1292, 1490, 1423) (0.8671, 0.9079, 0.8871)
    false_start: (917, 1414, 2244) (0.6485, 0.4086, 0.5014)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124530, 0.113449, 0.117718)
Item accuracy: 14991 / 17262 (0.8684)
Instance accuracy: 531 / 1316 (0.4035)

***** Iteration #140 *****
Loss: 33113.521433
Feature norm: 64.070357
Error norm: 2025.631876
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12961, 12101) (0.8978, 0.9617, 0.9287)
    repeat: (1116, 1342, 1447) (0.8316, 0.7713, 0.8003)
    filler: (1294, 1491, 1423) (0.8679, 0.9093, 0.8881)
    false_start: (932, 1445, 2244) (0.6450, 0.4153, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124421, 0.113779, 0.117905)
Item accuracy: 14995 / 17262 (0.8687)
Instance accuracy: 531 / 1316 (0.4035)

***** Iteration #141 *****
Loss: 33042.717475
Feature norm: 64.164128
Error norm: 1178.473753
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12920, 12101) (0.9001, 0.9610, 0.9295)
    repeat: (1119, 1361, 1447) (0.8222, 0.7733, 0.7970)
    filler: (1288, 1485, 1423) (0.8673, 0.9051, 0.8858)
    false_start: (954, 1473, 2244) (0.6477, 0.4251, 0.5133)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 6, 4) (0.3333, 0.5000, 0.4000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.118791, 0.111837, 0.113440)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 531 / 1316 (0.4035)

***** Iteration #142 *****
Loss: 32978.469737
Feature norm: 64.200721
Error norm: 1628.842228
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 12914, 12101) (0.9003, 0.9608, 0.9296)
    repeat: (1121, 1370, 1447) (0.8182, 0.7747, 0.7959)
    filler: (1287, 1484, 1423) (0.8673, 0.9044, 0.8854)
    false_start: (953, 1471, 2244) (0.6479, 0.4247, 0.5131)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124182, 0.113975, 0.117950)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 531 / 1316 (0.4035)

***** Iteration #143 *****
Loss: 32928.458871
Feature norm: 64.233613
Error norm: 1288.462341
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11617, 12899, 12101) (0.9006, 0.9600, 0.9294)
    repeat: (1122, 1368, 1447) (0.8202, 0.7754, 0.7972)
    filler: (1293, 1494, 1423) (0.8655, 0.9086, 0.8865)
    false_start: (947, 1478, 2244) (0.6407, 0.4220, 0.5089)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123995, 0.114014, 0.117893)
Item accuracy: 14995 / 17262 (0.8687)
Instance accuracy: 528 / 1316 (0.4012)

***** Iteration #144 *****
Loss: 32872.513745
Feature norm: 64.260987
Error norm: 2926.731336
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11606, 12900, 12101) (0.8997, 0.9591, 0.9284)
    repeat: (1100, 1303, 1447) (0.8442, 0.7602, 0.8000)
    filler: (1297, 1491, 1423) (0.8699, 0.9115, 0.8902)
    false_start: (971, 1545, 2244) (0.6285, 0.4327, 0.5125)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124420, 0.113942, 0.118150)
Item accuracy: 14990 / 17262 (0.8684)
Instance accuracy: 528 / 1316 (0.4012)

***** Iteration #145 *****
Loss: 32806.479472
Feature norm: 64.440378
Error norm: 1488.627099
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11662, 13001, 12101) (0.8970, 0.9637, 0.9292)
    repeat: (1118, 1336, 1447) (0.8368, 0.7726, 0.8034)
    filler: (1306, 1523, 1423) (0.8575, 0.9178, 0.8866)
    false_start: (912, 1378, 2244) (0.6618, 0.4064, 0.5036)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 20, 26) (0.7500, 0.5769, 0.6522)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.125088, 0.114930, 0.118750)
Item accuracy: 15015 / 17262 (0.8698)
Instance accuracy: 533 / 1316 (0.4050)

***** Iteration #146 *****
Loss: 32777.266198
Feature norm: 64.405911
Error norm: 1012.934081
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11651, 12970, 12101) (0.8983, 0.9628, 0.9294)
    repeat: (1117, 1338, 1447) (0.8348, 0.7719, 0.8022)
    filler: (1306, 1519, 1423) (0.8598, 0.9178, 0.8878)
    false_start: (928, 1411, 2244) (0.6577, 0.4135, 0.5078)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 20, 26) (0.7500, 0.5769, 0.6522)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.125017, 0.115083, 0.118872)
Item accuracy: 15019 / 17262 (0.8701)
Instance accuracy: 531 / 1316 (0.4035)

***** Iteration #147 *****
Loss: 32723.280243
Feature norm: 64.412824
Error norm: 1120.031699
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11644, 12959, 12101) (0.8985, 0.9622, 0.9293)
    repeat: (1120, 1341, 1447) (0.8352, 0.7740, 0.8034)
    filler: (1301, 1504, 1423) (0.8650, 0.9143, 0.8890)
    false_start: (937, 1435, 2244) (0.6530, 0.4176, 0.5094)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124682, 0.114070, 0.118147)
Item accuracy: 15018 / 17262 (0.8700)
Instance accuracy: 536 / 1316 (0.4073)

***** Iteration #148 *****
Loss: 32698.618846
Feature norm: 64.467141
Error norm: 1892.959773
Active features: 158563
Line search trials: 2
Line search step: 0.305290
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11604, 12874, 12101) (0.9014, 0.9589, 0.9292)
    repeat: (1129, 1360, 1447) (0.8301, 0.7802, 0.8044)
    filler: (1300, 1501, 1423) (0.8661, 0.9136, 0.8892)
    false_start: (957, 1503, 2244) (0.6367, 0.4265, 0.5108)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 20, 26) (0.7500, 0.5769, 0.6522)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124564, 0.115448, 0.119051)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 536 / 1316 (0.4073)

***** Iteration #149 *****
Loss: 32665.588758
Feature norm: 64.537980
Error norm: 1447.739456
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11613, 12873, 12101) (0.9021, 0.9597, 0.9300)
    repeat: (1126, 1360, 1447) (0.8279, 0.7782, 0.8023)
    filler: (1293, 1489, 1423) (0.8684, 0.9086, 0.8880)
    false_start: (978, 1516, 2244) (0.6451, 0.4358, 0.5202)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 20, 26) (0.7500, 0.5769, 0.6522)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124821, 0.115534, 0.119242)
Item accuracy: 15027 / 17262 (0.8705)
Instance accuracy: 537 / 1316 (0.4081)

***** Iteration #150 *****
Loss: 32591.828678
Feature norm: 64.712429
Error norm: 1055.994089
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11618, 12906, 12101) (0.9002, 0.9601, 0.9292)
    repeat: (1121, 1346, 1447) (0.8328, 0.7747, 0.8027)
    filler: (1296, 1492, 1423) (0.8686, 0.9108, 0.8892)
    false_start: (959, 1493, 2244) (0.6423, 0.4274, 0.5132)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.125164, 0.116341, 0.119866)
Item accuracy: 15012 / 17262 (0.8697)
Instance accuracy: 536 / 1316 (0.4073)

***** Iteration #151 *****
Loss: 32527.433633
Feature norm: 64.893548
Error norm: 1088.893427
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11624, 12926, 12101) (0.8993, 0.9606, 0.9289)
    repeat: (1120, 1339, 1447) (0.8364, 0.7740, 0.8040)
    filler: (1304, 1520, 1423) (0.8579, 0.9164, 0.8862)
    false_start: (941, 1452, 2244) (0.6481, 0.4193, 0.5092)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.125100, 0.116269, 0.119699)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 533 / 1316 (0.4050)

***** Iteration #152 *****
Loss: 32465.446062
Feature norm: 65.101294
Error norm: 894.791820
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11609, 12907, 12101) (0.8994, 0.9593, 0.9284)
    repeat: (1113, 1325, 1447) (0.8400, 0.7692, 0.8030)
    filler: (1298, 1508, 1423) (0.8607, 0.9122, 0.8857)
    false_start: (952, 1497, 2244) (0.6359, 0.4242, 0.5090)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124945, 0.116120, 0.119638)
Item accuracy: 14990 / 17262 (0.8684)
Instance accuracy: 534 / 1316 (0.4058)

***** Iteration #153 *****
Loss: 32436.383324
Feature norm: 65.211875
Error norm: 1410.759922
Active features: 158563
Line search trials: 2
Line search step: 0.441458
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12952, 12101) (0.8978, 0.9609, 0.9283)
    repeat: (1125, 1346, 1447) (0.8358, 0.7775, 0.8056)
    filler: (1306, 1533, 1423) (0.8519, 0.9178, 0.8836)
    false_start: (913, 1406, 2244) (0.6494, 0.4069, 0.5003)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124910, 0.116067, 0.119406)
Item accuracy: 14990 / 17262 (0.8684)
Instance accuracy: 531 / 1316 (0.4035)

***** Iteration #154 *****
Loss: 32403.477786
Feature norm: 65.246371
Error norm: 992.650397
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11604, 12912, 12101) (0.8987, 0.9589, 0.9278)
    repeat: (1124, 1345, 1447) (0.8357, 0.7768, 0.8052)
    filler: (1306, 1533, 1423) (0.8519, 0.9178, 0.8836)
    false_start: (929, 1447, 2244) (0.6420, 0.4140, 0.5034)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124729, 0.116191, 0.119468)
Item accuracy: 14981 / 17262 (0.8679)
Instance accuracy: 530 / 1316 (0.4027)

***** Iteration #155 *****
Loss: 32341.909422
Feature norm: 65.318206
Error norm: 1082.230203
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11621, 12921, 12101) (0.8994, 0.9603, 0.9289)
    repeat: (1113, 1325, 1447) (0.8400, 0.7692, 0.8030)
    filler: (1306, 1524, 1423) (0.8570, 0.9178, 0.8863)
    false_start: (947, 1467, 2244) (0.6455, 0.4220, 0.5104)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.125105, 0.116241, 0.119707)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 530 / 1316 (0.4027)

***** Iteration #156 *****
Loss: 32298.575994
Feature norm: 65.548335
Error norm: 3187.576150
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11588, 12842, 12101) (0.9024, 0.9576, 0.9292)
    repeat: (1120, 1342, 1447) (0.8346, 0.7740, 0.8032)
    filler: (1298, 1511, 1423) (0.8590, 0.9122, 0.8848)
    false_start: (969, 1542, 2244) (0.6284, 0.4318, 0.5119)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124619, 0.116416, 0.119718)
Item accuracy: 14993 / 17262 (0.8686)
Instance accuracy: 522 / 1316 (0.3967)

***** Iteration #157 *****
Loss: 32249.491519
Feature norm: 65.764010
Error norm: 1096.892404
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11620, 12902, 12101) (0.9006, 0.9603, 0.9295)
    repeat: (1114, 1327, 1447) (0.8395, 0.7699, 0.8032)
    filler: (1297, 1504, 1423) (0.8624, 0.9115, 0.8862)
    false_start: (960, 1504, 2244) (0.6383, 0.4278, 0.5123)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.125075, 0.116244, 0.119778)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 527 / 1316 (0.4005)

***** Iteration #158 *****
Loss: 32230.985814
Feature norm: 65.796057
Error norm: 804.494350
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11619, 12907, 12101) (0.9002, 0.9602, 0.9292)
    repeat: (1113, 1330, 1447) (0.8368, 0.7692, 0.8016)
    filler: (1297, 1506, 1423) (0.8612, 0.9115, 0.8856)
    false_start: (951, 1494, 2244) (0.6365, 0.4238, 0.5088)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124909, 0.116111, 0.119614)
Item accuracy: 14998 / 17262 (0.8688)
Instance accuracy: 524 / 1316 (0.3982)

***** Iteration #159 *****
Loss: 32207.216172
Feature norm: 65.842994
Error norm: 859.555016
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12939, 12101) (0.8993, 0.9616, 0.9294)
    repeat: (1113, 1332, 1447) (0.8356, 0.7692, 0.8010)
    filler: (1298, 1509, 1423) (0.8602, 0.9122, 0.8854)
    false_start: (934, 1457, 2244) (0.6410, 0.4162, 0.5047)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124945, 0.115959, 0.119483)
Item accuracy: 14999 / 17262 (0.8689)
Instance accuracy: 527 / 1316 (0.4005)

***** Iteration #160 *****
Loss: 32164.537773
Feature norm: 65.958266
Error norm: 1295.285558
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11649, 12975, 12101) (0.8978, 0.9626, 0.9291)
    repeat: (1110, 1324, 1447) (0.8384, 0.7671, 0.8012)
    filler: (1298, 1510, 1423) (0.8596, 0.9122, 0.8851)
    false_start: (928, 1428, 2244) (0.6499, 0.4135, 0.5054)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.125209, 0.115857, 0.119490)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 528 / 1316 (0.4012)

***** Iteration #161 *****
Loss: 32105.238225
Feature norm: 66.245442
Error norm: 1416.207707
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11652, 12974, 12101) (0.8981, 0.9629, 0.9294)
    repeat: (1101, 1302, 1447) (0.8456, 0.7609, 0.8010)
    filler: (1298, 1499, 1423) (0.8659, 0.9122, 0.8884)
    false_start: (950, 1462, 2244) (0.6498, 0.4234, 0.5127)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.125593, 0.115963, 0.119788)
Item accuracy: 15019 / 17262 (0.8701)
Instance accuracy: 533 / 1316 (0.4050)

***** Iteration #162 *****
Loss: 32046.315809
Feature norm: 66.465127
Error norm: 1611.448054
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11674, 12983, 12101) (0.8992, 0.9647, 0.9308)
    repeat: (1110, 1328, 1447) (0.8358, 0.7671, 0.8000)
    filler: (1308, 1523, 1423) (0.8588, 0.9192, 0.8880)
    false_start: (934, 1403, 2244) (0.6657, 0.4162, 0.5122)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.125596, 0.116184, 0.119773)
Item accuracy: 15044 / 17262 (0.8715)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #163 *****
Loss: 32006.802021
Feature norm: 66.612988
Error norm: 1062.658741
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11652, 12945, 12101) (0.9001, 0.9629, 0.9304)
    repeat: (1115, 1341, 1447) (0.8315, 0.7706, 0.7999)
    filler: (1303, 1508, 1423) (0.8641, 0.9157, 0.8891)
    false_start: (946, 1443, 2244) (0.6556, 0.4216, 0.5132)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.125365, 0.116280, 0.119817)
Item accuracy: 15034 / 17262 (0.8709)
Instance accuracy: 539 / 1316 (0.4096)

***** Iteration #164 *****
Loss: 31983.470840
Feature norm: 66.825526
Error norm: 1074.157495
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11660, 12978, 12101) (0.8984, 0.9636, 0.9299)
    repeat: (1106, 1325, 1447) (0.8347, 0.7643, 0.7980)
    filler: (1296, 1494, 1423) (0.8675, 0.9108, 0.8886)
    false_start: (936, 1440, 2244) (0.6500, 0.4171, 0.5081)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.125348, 0.115865, 0.119595)
Item accuracy: 15016 / 17262 (0.8699)
Instance accuracy: 539 / 1316 (0.4096)

***** Iteration #165 *****
Loss: 31961.833129
Feature norm: 66.941464
Error norm: 1285.028501
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11647, 12952, 12101) (0.8992, 0.9625, 0.9298)
    repeat: (1109, 1325, 1447) (0.8370, 0.7664, 0.8001)
    filler: (1298, 1498, 1423) (0.8665, 0.9122, 0.8887)
    false_start: (944, 1462, 2244) (0.6457, 0.4207, 0.5094)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.125286, 0.116031, 0.119693)
Item accuracy: 15016 / 17262 (0.8699)
Instance accuracy: 536 / 1316 (0.4073)

***** Iteration #166 *****
Loss: 31931.296313
Feature norm: 67.041052
Error norm: 1651.487945
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12918, 12101) (0.9002, 0.9610, 0.9296)
    repeat: (1109, 1328, 1447) (0.8351, 0.7664, 0.7993)
    filler: (1302, 1503, 1423) (0.8663, 0.9150, 0.8900)
    false_start: (954, 1488, 2244) (0.6411, 0.4251, 0.5113)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.125128, 0.116192, 0.119749)
Item accuracy: 15012 / 17262 (0.8697)
Instance accuracy: 533 / 1316 (0.4050)

***** Iteration #167 *****
Loss: 31867.559107
Feature norm: 67.300341
Error norm: 1361.432034
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11619, 12900, 12101) (0.9007, 0.9602, 0.9295)
    repeat: (1107, 1331, 1447) (0.8317, 0.7650, 0.7970)
    filler: (1302, 1506, 1423) (0.8645, 0.9150, 0.8890)
    false_start: (957, 1500, 2244) (0.6380, 0.4265, 0.5112)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (16, 21, 26) (0.7619, 0.6154, 0.6809)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124912, 0.116167, 0.119655)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 531 / 1316 (0.4035)

***** Iteration #168 *****
Loss: 31811.657042
Feature norm: 67.556960
Error norm: 2084.391480
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11608, 12872, 12101) (0.9018, 0.9593, 0.9296)
    repeat: (1106, 1328, 1447) (0.8328, 0.7643, 0.7971)
    filler: (1303, 1505, 1423) (0.8658, 0.9157, 0.8900)
    false_start: (978, 1533, 2244) (0.6380, 0.4358, 0.5179)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (15, 18, 26) (0.8333, 0.5769, 0.6818)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.131622, 0.129223, 0.128235)
Item accuracy: 15014 / 17262 (0.8698)
Instance accuracy: 533 / 1316 (0.4050)

***** Iteration #169 *****
Loss: 31781.465109
Feature norm: 67.972068
Error norm: 2125.688648
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11657, 12947, 12101) (0.9004, 0.9633, 0.9308)
    repeat: (1122, 1369, 1447) (0.8196, 0.7754, 0.7969)
    filler: (1307, 1521, 1423) (0.8593, 0.9185, 0.8879)
    false_start: (930, 1402, 2244) (0.6633, 0.4144, 0.5101)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 17, 26) (0.8235, 0.5385, 0.6512)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 6, 4) (0.6667, 1.0000, 0.8000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.131466, 0.128058, 0.127135)
Item accuracy: 15034 / 17262 (0.8709)
Instance accuracy: 537 / 1316 (0.4081)

***** Iteration #170 *****
Loss: 31747.033419
Feature norm: 67.856037
Error norm: 880.145687
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12926, 12101) (0.9002, 0.9616, 0.9299)
    repeat: (1119, 1350, 1447) (0.8289, 0.7733, 0.8001)
    filler: (1302, 1509, 1423) (0.8628, 0.9150, 0.8881)
    false_start: (944, 1454, 2244) (0.6492, 0.4207, 0.5105)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 18, 26) (0.7778, 0.5385, 0.6364)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128304, 0.121083, 0.123104)
Item accuracy: 15018 / 17262 (0.8700)
Instance accuracy: 537 / 1316 (0.4081)

***** Iteration #171 *****
Loss: 31728.413602
Feature norm: 67.825905
Error norm: 694.391737
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12942, 12101) (0.8993, 0.9618, 0.9295)
    repeat: (1114, 1341, 1447) (0.8307, 0.7699, 0.7991)
    filler: (1302, 1508, 1423) (0.8634, 0.9150, 0.8884)
    false_start: (935, 1448, 2244) (0.6457, 0.4167, 0.5065)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 18, 26) (0.7778, 0.5385, 0.6364)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128248, 0.120883, 0.122962)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 534 / 1316 (0.4058)

***** Iteration #172 *****
Loss: 31687.202243
Feature norm: 67.916320
Error norm: 2202.624386
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11621, 12893, 12101) (0.9013, 0.9603, 0.9299)
    repeat: (1106, 1325, 1447) (0.8347, 0.7643, 0.7980)
    filler: (1299, 1500, 1423) (0.8660, 0.9129, 0.8888)
    false_start: (972, 1521, 2244) (0.6391, 0.4332, 0.5163)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (14, 19, 26) (0.7368, 0.5385, 0.6222)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124388, 0.114143, 0.118201)
Item accuracy: 15014 / 17262 (0.8698)
Instance accuracy: 536 / 1316 (0.4073)

***** Iteration #173 *****
Loss: 31647.640890
Feature norm: 67.986532
Error norm: 1207.298443
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12929, 12101) (0.9002, 0.9618, 0.9300)
    repeat: (1100, 1307, 1447) (0.8416, 0.7602, 0.7988)
    filler: (1306, 1510, 1423) (0.8649, 0.9178, 0.8906)
    false_start: (964, 1494, 2244) (0.6452, 0.4296, 0.5158)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 18, 26) (0.7222, 0.5000, 0.5909)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.124284, 0.113038, 0.117391)
Item accuracy: 15024 / 17262 (0.8704)
Instance accuracy: 536 / 1316 (0.4073)

***** Iteration #174 *****
Loss: 31618.942536
Feature norm: 68.158921
Error norm: 830.986424
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12927, 12101) (0.9004, 0.9619, 0.9302)
    repeat: (1101, 1313, 1447) (0.8385, 0.7609, 0.7978)
    filler: (1306, 1511, 1423) (0.8643, 0.9178, 0.8903)
    false_start: (961, 1489, 2244) (0.6454, 0.4283, 0.5149)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 17, 26) (0.7647, 0.5000, 0.6047)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128150, 0.119967, 0.122345)
Item accuracy: 15024 / 17262 (0.8704)
Instance accuracy: 536 / 1316 (0.4073)

***** Iteration #175 *****
Loss: 31584.843808
Feature norm: 68.277897
Error norm: 767.848592
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11650, 12945, 12101) (0.9000, 0.9627, 0.9303)
    repeat: (1106, 1319, 1447) (0.8385, 0.7643, 0.7997)
    filler: (1306, 1517, 1423) (0.8609, 0.9178, 0.8884)
    false_start: (949, 1459, 2244) (0.6504, 0.4229, 0.5126)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 17, 26) (0.7647, 0.5000, 0.6047)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128182, 0.119938, 0.122286)
Item accuracy: 15027 / 17262 (0.8705)
Instance accuracy: 534 / 1316 (0.4058)

***** Iteration #176 *****
Loss: 31543.607943
Feature norm: 68.420833
Error norm: 971.150321
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12933, 12101) (0.9000, 0.9619, 0.9299)
    repeat: (1110, 1328, 1447) (0.8358, 0.7671, 0.8000)
    filler: (1307, 1522, 1423) (0.8587, 0.9185, 0.8876)
    false_start: (945, 1457, 2244) (0.6486, 0.4211, 0.5107)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 17, 26) (0.7647, 0.5000, 0.6047)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127997, 0.119961, 0.122209)
Item accuracy: 15018 / 17262 (0.8700)
Instance accuracy: 536 / 1316 (0.4073)

***** Iteration #177 *****
Loss: 31497.738723
Feature norm: 68.616024
Error norm: 1472.137631
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11657, 12966, 12101) (0.8990, 0.9633, 0.9301)
    repeat: (1110, 1324, 1447) (0.8384, 0.7671, 0.8012)
    filler: (1307, 1522, 1423) (0.8587, 0.9185, 0.8876)
    false_start: (935, 1428, 2244) (0.6548, 0.4167, 0.5093)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (13, 17, 26) (0.7647, 0.5000, 0.6047)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128212, 0.119877, 0.122206)
Item accuracy: 15025 / 17262 (0.8704)
Instance accuracy: 536 / 1316 (0.4073)

***** Iteration #178 *****
Loss: 31439.620356
Feature norm: 68.923405
Error norm: 848.743615
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12930, 12101) (0.8995, 0.9612, 0.9293)
    repeat: (1105, 1318, 1447) (0.8384, 0.7636, 0.7993)
    filler: (1307, 1516, 1423) (0.8621, 0.9185, 0.8894)
    false_start: (952, 1477, 2244) (0.6445, 0.4242, 0.5117)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127628, 0.118863, 0.121328)
Item accuracy: 15010 / 17262 (0.8695)
Instance accuracy: 537 / 1316 (0.4081)

***** Iteration #179 *****
Loss: 31419.823247
Feature norm: 69.081994
Error norm: 1918.069563
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11656, 12970, 12101) (0.8987, 0.9632, 0.9298)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1311, 1513, 1423) (0.8665, 0.9213, 0.8931)
    false_start: (939, 1427, 2244) (0.6580, 0.4184, 0.5116)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128060, 0.119010, 0.121516)
Item accuracy: 15035 / 17262 (0.8710)
Instance accuracy: 538 / 1316 (0.4088)

***** Iteration #180 *****
Loss: 31386.065037
Feature norm: 69.220401
Error norm: 865.731154
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12933, 12101) (0.8998, 0.9617, 0.9297)
    repeat: (1112, 1325, 1447) (0.8392, 0.7685, 0.8023)
    filler: (1309, 1515, 1423) (0.8640, 0.9199, 0.8911)
    false_start: (952, 1468, 2244) (0.6485, 0.4242, 0.5129)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127821, 0.119050, 0.121503)
Item accuracy: 15025 / 17262 (0.8704)
Instance accuracy: 540 / 1316 (0.4103)

***** Iteration #181 *****
Loss: 31366.256442
Feature norm: 69.354284
Error norm: 1309.284114
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11610, 12880, 12101) (0.9014, 0.9594, 0.9295)
    repeat: (1111, 1321, 1447) (0.8410, 0.7678, 0.8027)
    filler: (1309, 1513, 1423) (0.8652, 0.9199, 0.8917)
    false_start: (972, 1527, 2244) (0.6365, 0.4332, 0.5155)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127615, 0.119217, 0.121599)
Item accuracy: 15017 / 17262 (0.8699)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #182 *****
Loss: 31341.038112
Feature norm: 69.610777
Error norm: 902.775086
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11607, 12875, 12101) (0.9015, 0.9592, 0.9295)
    repeat: (1108, 1311, 1447) (0.8452, 0.7657, 0.8035)
    filler: (1309, 1513, 1423) (0.8652, 0.9199, 0.8917)
    false_start: (982, 1542, 2244) (0.6368, 0.4376, 0.5188)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127741, 0.119276, 0.121708)
Item accuracy: 15021 / 17262 (0.8702)
Instance accuracy: 540 / 1316 (0.4103)

***** Iteration #183 *****
Loss: 31311.394748
Feature norm: 70.039609
Error norm: 805.422118
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11605, 12877, 12101) (0.9012, 0.9590, 0.9292)
    repeat: (1116, 1332, 1447) (0.8378, 0.7713, 0.8032)
    filler: (1314, 1522, 1423) (0.8633, 0.9234, 0.8924)
    false_start: (962, 1510, 2244) (0.6371, 0.4287, 0.5125)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127486, 0.119275, 0.121538)
Item accuracy: 15012 / 17262 (0.8697)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #184 *****
Loss: 31273.758065
Feature norm: 70.455316
Error norm: 1147.771047
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11645, 12948, 12101) (0.8994, 0.9623, 0.9298)
    repeat: (1109, 1316, 1447) (0.8427, 0.7664, 0.8028)
    filler: (1305, 1495, 1423) (0.8729, 0.9171, 0.8944)
    false_start: (960, 1482, 2244) (0.6478, 0.4278, 0.5153)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128132, 0.119032, 0.121677)
Item accuracy: 15034 / 17262 (0.8709)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #185 *****
Loss: 31236.592436
Feature norm: 70.639004
Error norm: 1644.302788
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11658, 12972, 12101) (0.8987, 0.9634, 0.9299)
    repeat: (1108, 1319, 1447) (0.8400, 0.7657, 0.8012)
    filler: (1305, 1490, 1423) (0.8758, 0.9171, 0.8960)
    false_start: (953, 1460, 2244) (0.6527, 0.4247, 0.5146)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128259, 0.118956, 0.121659)
Item accuracy: 15039 / 17262 (0.8712)
Instance accuracy: 553 / 1316 (0.4202)

***** Iteration #186 *****
Loss: 31182.776666
Feature norm: 70.975773
Error norm: 668.350160
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11645, 12943, 12101) (0.8997, 0.9623, 0.9300)
    repeat: (1110, 1322, 1447) (0.8396, 0.7671, 0.8017)
    filler: (1305, 1491, 1423) (0.8753, 0.9171, 0.8957)
    false_start: (962, 1485, 2244) (0.6478, 0.4287, 0.5160)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128123, 0.119076, 0.121706)
Item accuracy: 15037 / 17262 (0.8711)
Instance accuracy: 556 / 1316 (0.4225)

***** Iteration #187 *****
Loss: 31174.789946
Feature norm: 70.735148
Error norm: 1839.645682
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11665, 12982, 12101) (0.8986, 0.9640, 0.9301)
    repeat: (1110, 1326, 1447) (0.8371, 0.7671, 0.8006)
    filler: (1306, 1503, 1423) (0.8689, 0.9178, 0.8927)
    false_start: (942, 1430, 2244) (0.6587, 0.4198, 0.5128)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128148, 0.118894, 0.121507)
Item accuracy: 15038 / 17262 (0.8712)
Instance accuracy: 551 / 1316 (0.4187)

***** Iteration #188 *****
Loss: 31156.834905
Feature norm: 70.782130
Error norm: 632.180852
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11642, 12937, 12101) (0.8999, 0.9621, 0.9299)
    repeat: (1112, 1323, 1447) (0.8405, 0.7685, 0.8029)
    filler: (1308, 1500, 1423) (0.8720, 0.9192, 0.8950)
    false_start: (966, 1481, 2244) (0.6523, 0.4305, 0.5187)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128185, 0.119216, 0.121793)
Item accuracy: 15043 / 17262 (0.8715)
Instance accuracy: 556 / 1316 (0.4225)

***** Iteration #189 *****
Loss: 31145.320067
Feature norm: 70.803547
Error norm: 806.234320
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12924, 12101) (0.9002, 0.9614, 0.9298)
    repeat: (1112, 1323, 1447) (0.8405, 0.7685, 0.8029)
    filler: (1305, 1497, 1423) (0.8717, 0.9171, 0.8938)
    false_start: (972, 1497, 2244) (0.6493, 0.4332, 0.5196)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128104, 0.119213, 0.121785)
Item accuracy: 15038 / 17262 (0.8712)
Instance accuracy: 551 / 1316 (0.4187)

***** Iteration #190 *****
Loss: 31137.696638
Feature norm: 70.834065
Error norm: 811.807600
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12925, 12101) (0.9003, 0.9617, 0.9300)
    repeat: (1111, 1322, 1447) (0.8404, 0.7678, 0.8025)
    filler: (1305, 1497, 1423) (0.8717, 0.9171, 0.8938)
    false_start: (974, 1497, 2244) (0.6506, 0.4340, 0.5207)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128142, 0.119225, 0.121808)
Item accuracy: 15042 / 17262 (0.8714)
Instance accuracy: 553 / 1316 (0.4202)

***** Iteration #191 *****
Loss: 31111.448705
Feature norm: 71.056685
Error norm: 679.941885
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12923, 12101) (0.9002, 0.9613, 0.9297)
    repeat: (1111, 1320, 1447) (0.8417, 0.7678, 0.8030)
    filler: (1306, 1500, 1423) (0.8707, 0.9178, 0.8936)
    false_start: (968, 1498, 2244) (0.6462, 0.4314, 0.5174)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.128020, 0.119161, 0.121718)
Item accuracy: 15033 / 17262 (0.8709)
Instance accuracy: 553 / 1316 (0.4202)

***** Iteration #192 *****
Loss: 31101.499792
Feature norm: 70.756058
Error norm: 803.349922
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11618, 12907, 12101) (0.9001, 0.9601, 0.9291)
    repeat: (1107, 1320, 1447) (0.8386, 0.7650, 0.8001)
    filler: (1305, 1505, 1423) (0.8671, 0.9171, 0.8914)
    false_start: (961, 1509, 2244) (0.6368, 0.4283, 0.5121)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127576, 0.118944, 0.121414)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #193 *****
Loss: 31090.607142
Feature norm: 70.857895
Error norm: 1260.305176
Active features: 158563
Line search trials: 2
Line search step: 0.074740
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11652, 12973, 12101) (0.8982, 0.9629, 0.9294)
    repeat: (1101, 1306, 1447) (0.8430, 0.7609, 0.7999)
    filler: (1301, 1495, 1423) (0.8702, 0.9143, 0.8917)
    false_start: (942, 1467, 2244) (0.6421, 0.4198, 0.5077)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127877, 0.118594, 0.121298)
Item accuracy: 15011 / 17262 (0.8696)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #194 *****
Loss: 31060.486664
Feature norm: 71.049287
Error norm: 778.178439
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12954, 12101) (0.8986, 0.9620, 0.9292)
    repeat: (1105, 1309, 1447) (0.8442, 0.7636, 0.8019)
    filler: (1308, 1503, 1423) (0.8703, 0.9192, 0.8941)
    false_start: (947, 1475, 2244) (0.6420, 0.4220, 0.5093)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127919, 0.118844, 0.121460)
Item accuracy: 15016 / 17262 (0.8699)
Instance accuracy: 549 / 1316 (0.4172)

***** Iteration #195 *****
Loss: 31044.366848
Feature norm: 71.328914
Error norm: 1838.051615
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11612, 12885, 12101) (0.9012, 0.9596, 0.9295)
    repeat: (1105, 1309, 1447) (0.8442, 0.7636, 0.8019)
    filler: (1310, 1507, 1423) (0.8693, 0.9206, 0.8942)
    false_start: (979, 1540, 2244) (0.6357, 0.4363, 0.5174)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127787, 0.119212, 0.121697)
Item accuracy: 15021 / 17262 (0.8702)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #196 *****
Loss: 31023.202340
Feature norm: 71.323380
Error norm: 958.088362
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11620, 12897, 12101) (0.9010, 0.9603, 0.9297)
    repeat: (1105, 1309, 1447) (0.8442, 0.7636, 0.8019)
    filler: (1310, 1509, 1423) (0.8681, 0.9206, 0.8936)
    false_start: (975, 1526, 2244) (0.6389, 0.4345, 0.5172)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127839, 0.119181, 0.121680)
Item accuracy: 15025 / 17262 (0.8704)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #197 *****
Loss: 31005.450956
Feature norm: 71.363881
Error norm: 658.864370
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12921, 12101) (0.9000, 0.9610, 0.9295)
    repeat: (1110, 1319, 1447) (0.8415, 0.7671, 0.8026)
    filler: (1311, 1517, 1423) (0.8642, 0.9213, 0.8918)
    false_start: (952, 1484, 2244) (0.6415, 0.4242, 0.5107)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 5, 4) (0.6000, 0.7500, 0.6667)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.127702, 0.119033, 0.121466)
Item accuracy: 15017 / 17262 (0.8699)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #198 *****
Loss: 30988.261704
Feature norm: 71.476035
Error norm: 635.323962
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12938, 12101) (0.8996, 0.9618, 0.9297)
    repeat: (1112, 1321, 1447) (0.8418, 0.7685, 0.8035)
    filler: (1311, 1513, 1423) (0.8665, 0.9213, 0.8931)
    false_start: (949, 1469, 2244) (0.6460, 0.4229, 0.5112)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123883, 0.112112, 0.116542)
Item accuracy: 15025 / 17262 (0.8704)
Instance accuracy: 550 / 1316 (0.4179)

***** Iteration #199 *****
Loss: 30947.554996
Feature norm: 72.001334
Error norm: 843.372441
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12929, 12101) (0.9002, 0.9618, 0.9300)
    repeat: (1112, 1328, 1447) (0.8373, 0.7685, 0.8014)
    filler: (1311, 1516, 1423) (0.8648, 0.9213, 0.8921)
    false_start: (949, 1468, 2244) (0.6465, 0.4229, 0.5113)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123741, 0.112112, 0.116473)
Item accuracy: 15025 / 17262 (0.8704)
Instance accuracy: 551 / 1316 (0.4187)

***** Iteration #200 *****
Loss: 30935.924143
Feature norm: 71.972409
Error norm: 881.277610
Active features: 158563
Line search trials: 2
Line search step: 0.205747
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12924, 12101) (0.9005, 0.9617, 0.9301)
    repeat: (1117, 1335, 1447) (0.8367, 0.7719, 0.8030)
    filler: (1311, 1512, 1423) (0.8671, 0.9213, 0.8934)
    false_start: (949, 1470, 2244) (0.6456, 0.4229, 0.5110)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123770, 0.112206, 0.116546)
Item accuracy: 15029 / 17262 (0.8706)
Instance accuracy: 549 / 1316 (0.4172)

***** Iteration #201 *****
Loss: 30912.028355
Feature norm: 72.358820
Error norm: 593.530855
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11651, 12958, 12101) (0.8991, 0.9628, 0.9299)
    repeat: (1103, 1314, 1447) (0.8394, 0.7623, 0.7990)
    filler: (1309, 1506, 1423) (0.8692, 0.9199, 0.8938)
    false_start: (948, 1463, 2244) (0.6480, 0.4225, 0.5115)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123934, 0.111916, 0.116453)
Item accuracy: 15025 / 17262 (0.8704)
Instance accuracy: 553 / 1316 (0.4202)

***** Iteration #202 *****
Loss: 30898.649033
Feature norm: 72.585980
Error norm: 823.495680
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12922, 12101) (0.9002, 0.9613, 0.9298)
    repeat: (1102, 1312, 1447) (0.8399, 0.7616, 0.7988)
    filler: (1308, 1511, 1423) (0.8657, 0.9192, 0.8916)
    false_start: (955, 1496, 2244) (0.6384, 0.4256, 0.5107)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123614, 0.111922, 0.116363)
Item accuracy: 15012 / 17262 (0.8697)
Instance accuracy: 550 / 1316 (0.4179)

***** Iteration #203 *****
Loss: 30882.830310
Feature norm: 72.697399
Error norm: 652.059869
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11647, 12964, 12101) (0.8984, 0.9625, 0.9293)
    repeat: (1105, 1318, 1447) (0.8384, 0.7636, 0.7993)
    filler: (1308, 1509, 1423) (0.8668, 0.9192, 0.8922)
    false_start: (936, 1450, 2244) (0.6455, 0.4171, 0.5068)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123750, 0.111777, 0.116271)
Item accuracy: 15010 / 17262 (0.8695)
Instance accuracy: 549 / 1316 (0.4172)

***** Iteration #204 *****
Loss: 30869.813949
Feature norm: 72.721516
Error norm: 732.454902
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12943, 12101) (0.8992, 0.9617, 0.9294)
    repeat: (1103, 1313, 1447) (0.8401, 0.7623, 0.7993)
    filler: (1307, 1508, 1423) (0.8667, 0.9185, 0.8918)
    false_start: (946, 1477, 2244) (0.6405, 0.4216, 0.5085)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123675, 0.111822, 0.116309)
Item accuracy: 15008 / 17262 (0.8694)
Instance accuracy: 549 / 1316 (0.4172)

***** Iteration #205 *****
Loss: 30842.794235
Feature norm: 72.783165
Error norm: 1041.632502
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12936, 12101) (0.8994, 0.9614, 0.9293)
    repeat: (1102, 1313, 1447) (0.8393, 0.7616, 0.7986)
    filler: (1306, 1506, 1423) (0.8672, 0.9178, 0.8918)
    false_start: (948, 1486, 2244) (0.6380, 0.4225, 0.5083)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123602, 0.111799, 0.116281)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 550 / 1316 (0.4179)

***** Iteration #206 *****
Loss: 30809.337968
Feature norm: 73.044189
Error norm: 616.442940
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12937, 12101) (0.8990, 0.9612, 0.9291)
    repeat: (1102, 1314, 1447) (0.8387, 0.7616, 0.7983)
    filler: (1305, 1508, 1423) (0.8654, 0.9171, 0.8905)
    false_start: (951, 1482, 2244) (0.6417, 0.4238, 0.5105)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107677, 0.097921, 0.101711)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 551 / 1316 (0.4187)

***** Iteration #207 *****
Loss: 30788.400671
Feature norm: 73.213626
Error norm: 577.933716
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12951, 12101) (0.8988, 0.9620, 0.9293)
    repeat: (1102, 1314, 1447) (0.8387, 0.7616, 0.7983)
    filler: (1305, 1507, 1423) (0.8660, 0.9171, 0.8908)
    false_start: (947, 1469, 2244) (0.6447, 0.4220, 0.5101)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107770, 0.097894, 0.101717)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 553 / 1316 (0.4202)

***** Iteration #208 *****
Loss: 30769.566218
Feature norm: 73.529033
Error norm: 1316.208062
Active features: 158563
Line search trials: 2
Line search step: 0.509025
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11650, 12970, 12101) (0.8982, 0.9627, 0.9294)
    repeat: (1099, 1313, 1447) (0.8370, 0.7595, 0.7964)
    filler: (1303, 1510, 1423) (0.8629, 0.9157, 0.8885)
    false_start: (945, 1448, 2244) (0.6526, 0.4211, 0.5119)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107843, 0.097793, 0.101653)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 552 / 1316 (0.4195)

***** Iteration #209 *****
Loss: 30748.718515
Feature norm: 73.768688
Error norm: 513.710967
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12932, 12101) (0.8992, 0.9610, 0.9291)
    repeat: (1103, 1323, 1447) (0.8337, 0.7623, 0.7964)
    filler: (1303, 1510, 1423) (0.8629, 0.9157, 0.8885)
    false_start: (949, 1476, 2244) (0.6430, 0.4229, 0.5102)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107511, 0.097872, 0.101598)
Item accuracy: 14996 / 17262 (0.8687)
Instance accuracy: 550 / 1316 (0.4179)

***** Iteration #210 *****
Loss: 30738.735475
Feature norm: 73.832019
Error norm: 467.355532
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12940, 12101) (0.8989, 0.9612, 0.9290)
    repeat: (1099, 1319, 1447) (0.8332, 0.7595, 0.7946)
    filler: (1299, 1506, 1423) (0.8625, 0.9129, 0.8870)
    false_start: (948, 1476, 2244) (0.6423, 0.4225, 0.5097)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107459, 0.097711, 0.101491)
Item accuracy: 14990 / 17262 (0.8684)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #211 *****
Loss: 30725.608120
Feature norm: 73.978868
Error norm: 997.776861
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11617, 12903, 12101) (0.9003, 0.9600, 0.9292)
    repeat: (1102, 1320, 1447) (0.8348, 0.7616, 0.7965)
    filler: (1299, 1507, 1423) (0.8620, 0.9129, 0.8867)
    false_start: (961, 1511, 2244) (0.6360, 0.4283, 0.5119)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107354, 0.097895, 0.101600)
Item accuracy: 14991 / 17262 (0.8684)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #212 *****
Loss: 30709.510845
Feature norm: 74.047435
Error norm: 601.513134
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12923, 12101) (0.9003, 0.9615, 0.9299)
    repeat: (1104, 1322, 1447) (0.8351, 0.7630, 0.7974)
    filler: (1303, 1511, 1423) (0.8623, 0.9157, 0.8882)
    false_start: (955, 1485, 2244) (0.6431, 0.4256, 0.5122)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107568, 0.097979, 0.101696)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #213 *****
Loss: 30691.920446
Feature norm: 74.168265
Error norm: 531.247492
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11659, 12982, 12101) (0.8981, 0.9635, 0.9296)
    repeat: (1095, 1307, 1447) (0.8378, 0.7567, 0.7952)
    filler: (1303, 1503, 1423) (0.8669, 0.9157, 0.8906)
    false_start: (932, 1449, 2244) (0.6432, 0.4153, 0.5047)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107711, 0.097576, 0.101487)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 548 / 1316 (0.4164)

***** Iteration #214 *****
Loss: 30680.984742
Feature norm: 74.415260
Error norm: 1430.351007
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11672, 12972, 12101) (0.8998, 0.9645, 0.9310)
    repeat: (1113, 1347, 1447) (0.8263, 0.7692, 0.7967)
    filler: (1306, 1509, 1423) (0.8655, 0.9178, 0.8909)
    false_start: (925, 1413, 2244) (0.6546, 0.4122, 0.5059)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107715, 0.097924, 0.101606)
Item accuracy: 15028 / 17262 (0.8706)
Instance accuracy: 551 / 1316 (0.4187)

***** Iteration #215 *****
Loss: 30663.575991
Feature norm: 74.323899
Error norm: 531.045578
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11660, 12965, 12101) (0.8993, 0.9636, 0.9303)
    repeat: (1106, 1318, 1447) (0.8392, 0.7643, 0.8000)
    filler: (1303, 1498, 1423) (0.8698, 0.9157, 0.8922)
    false_start: (944, 1460, 2244) (0.6466, 0.4207, 0.5097)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107958, 0.097938, 0.101821)
Item accuracy: 15025 / 17262 (0.8704)
Instance accuracy: 553 / 1316 (0.4202)

***** Iteration #216 *****
Loss: 30653.689948
Feature norm: 74.319690
Error norm: 497.392722
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11657, 12964, 12101) (0.8992, 0.9633, 0.9301)
    repeat: (1099, 1309, 1447) (0.8396, 0.7595, 0.7975)
    filler: (1299, 1494, 1423) (0.8695, 0.9129, 0.8906)
    false_start: (949, 1474, 2244) (0.6438, 0.4229, 0.5105)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107879, 0.097781, 0.101726)
Item accuracy: 15016 / 17262 (0.8699)
Instance accuracy: 554 / 1316 (0.4210)

***** Iteration #217 *****
Loss: 30635.283707
Feature norm: 74.402825
Error norm: 1055.908366
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12923, 12101) (0.9003, 0.9614, 0.9298)
    repeat: (1100, 1311, 1447) (0.8391, 0.7602, 0.7977)
    filler: (1299, 1498, 1423) (0.8672, 0.9129, 0.8894)
    false_start: (960, 1509, 2244) (0.6362, 0.4278, 0.5116)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107617, 0.097884, 0.101718)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 555 / 1316 (0.4217)

***** Iteration #218 *****
Loss: 30618.327665
Feature norm: 74.541461
Error norm: 752.765994
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11647, 12935, 12101) (0.9004, 0.9625, 0.9304)
    repeat: (1102, 1314, 1447) (0.8387, 0.7616, 0.7983)
    filler: (1299, 1498, 1423) (0.8672, 0.9129, 0.8894)
    false_start: (963, 1494, 2244) (0.6446, 0.4291, 0.5152)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107844, 0.097989, 0.101852)
Item accuracy: 15023 / 17262 (0.8703)
Instance accuracy: 557 / 1316 (0.4233)

***** Iteration #219 *****
Loss: 30604.063684
Feature norm: 74.711212
Error norm: 635.594630
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12916, 12101) (0.9007, 0.9614, 0.9301)
    repeat: (1108, 1326, 1447) (0.8356, 0.7657, 0.7991)
    filler: (1299, 1498, 1423) (0.8672, 0.9129, 0.8894)
    false_start: (962, 1501, 2244) (0.6409, 0.4287, 0.5138)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107666, 0.098062, 0.101826)
Item accuracy: 15015 / 17262 (0.8698)
Instance accuracy: 559 / 1316 (0.4248)

***** Iteration #220 *****
Loss: 30576.889395
Feature norm: 74.921148
Error norm: 696.528549
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12934, 12101) (0.9000, 0.9620, 0.9300)
    repeat: (1108, 1329, 1447) (0.8337, 0.7657, 0.7983)
    filler: (1300, 1500, 1423) (0.8667, 0.9136, 0.8895)
    false_start: (952, 1478, 2244) (0.6441, 0.4242, 0.5116)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107669, 0.097974, 0.101740)
Item accuracy: 15013 / 17262 (0.8697)
Instance accuracy: 557 / 1316 (0.4233)

***** Iteration #221 *****
Loss: 30550.680747
Feature norm: 75.058884
Error norm: 552.423730
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11647, 12936, 12101) (0.9004, 0.9625, 0.9304)
    repeat: (1114, 1341, 1447) (0.8307, 0.7699, 0.7991)
    filler: (1299, 1496, 1423) (0.8683, 0.9129, 0.8900)
    false_start: (947, 1468, 2244) (0.6451, 0.4220, 0.5102)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107669, 0.098021, 0.101753)
Item accuracy: 15019 / 17262 (0.8701)
Instance accuracy: 551 / 1316 (0.4187)

***** Iteration #222 *****
Loss: 30524.192958
Feature norm: 75.150951
Error norm: 600.071529
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11654, 12952, 12101) (0.8998, 0.9631, 0.9303)
    repeat: (1115, 1340, 1447) (0.8321, 0.7706, 0.8001)
    filler: (1303, 1500, 1423) (0.8687, 0.9157, 0.8915)
    false_start: (938, 1449, 2244) (0.6473, 0.4180, 0.5080)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107763, 0.098023, 0.101760)
Item accuracy: 15022 / 17262 (0.8702)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #223 *****
Loss: 30509.743279
Feature norm: 75.274369
Error norm: 1618.006593
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11630, 12927, 12101) (0.8997, 0.9611, 0.9294)
    repeat: (1098, 1302, 1447) (0.8433, 0.7588, 0.7988)
    filler: (1302, 1495, 1423) (0.8709, 0.9150, 0.8924)
    false_start: (963, 1517, 2244) (0.6348, 0.4291, 0.5121)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107785, 0.097932, 0.101834)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #224 *****
Loss: 30495.396703
Feature norm: 75.223373
Error norm: 577.122914
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12947, 12101) (0.8989, 0.9617, 0.9293)
    repeat: (1106, 1319, 1447) (0.8385, 0.7643, 0.7997)
    filler: (1302, 1495, 1423) (0.8709, 0.9150, 0.8924)
    false_start: (944, 1480, 2244) (0.6378, 0.4207, 0.5070)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107715, 0.097868, 0.101713)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #225 *****
Loss: 30487.019084
Feature norm: 75.214011
Error norm: 562.072344
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11652, 12970, 12101) (0.8984, 0.9629, 0.9295)
    repeat: (1105, 1315, 1447) (0.8403, 0.7636, 0.8001)
    filler: (1302, 1494, 1423) (0.8715, 0.9150, 0.8927)
    false_start: (935, 1462, 2244) (0.6395, 0.4167, 0.5046)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107813, 0.097770, 0.101675)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #226 *****
Loss: 30473.997931
Feature norm: 75.270014
Error norm: 614.816513
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11647, 12953, 12101) (0.8992, 0.9625, 0.9298)
    repeat: (1109, 1322, 1447) (0.8389, 0.7664, 0.8010)
    filler: (1302, 1494, 1423) (0.8715, 0.9150, 0.8927)
    false_start: (942, 1472, 2244) (0.6399, 0.4198, 0.5070)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107807, 0.097922, 0.101772)
Item accuracy: 15012 / 17262 (0.8697)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #227 *****
Loss: 30455.225611
Feature norm: 75.522094
Error norm: 1868.870219
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11669, 13006, 12101) (0.8972, 0.9643, 0.9295)
    repeat: (1099, 1307, 1447) (0.8409, 0.7595, 0.7981)
    filler: (1300, 1492, 1423) (0.8713, 0.9136, 0.8919)
    false_start: (924, 1436, 2244) (0.6435, 0.4118, 0.5022)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107900, 0.097519, 0.101531)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #228 *****
Loss: 30437.587837
Feature norm: 75.620631
Error norm: 740.837123
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11653, 12957, 12101) (0.8994, 0.9630, 0.9301)
    repeat: (1113, 1338, 1447) (0.8318, 0.7692, 0.7993)
    filler: (1300, 1495, 1423) (0.8696, 0.9136, 0.8910)
    false_start: (938, 1451, 2244) (0.6465, 0.4180, 0.5077)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107744, 0.097924, 0.101706)
Item accuracy: 15016 / 17262 (0.8699)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #229 *****
Loss: 30430.429883
Feature norm: 75.657878
Error norm: 475.832005
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11644, 12951, 12101) (0.8991, 0.9622, 0.9296)
    repeat: (1112, 1333, 1447) (0.8342, 0.7685, 0.8000)
    filler: (1300, 1495, 1423) (0.8696, 0.9136, 0.8910)
    false_start: (940, 1462, 2244) (0.6430, 0.4189, 0.5073)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107705, 0.097909, 0.101701)
Item accuracy: 15008 / 17262 (0.8694)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #230 *****
Loss: 30421.186816
Feature norm: 75.726232
Error norm: 547.353715
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11645, 12949, 12101) (0.8993, 0.9623, 0.9297)
    repeat: (1106, 1324, 1447) (0.8353, 0.7643, 0.7983)
    filler: (1302, 1497, 1423) (0.8697, 0.9150, 0.8918)
    false_start: (946, 1471, 2244) (0.6431, 0.4216, 0.5093)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107752, 0.097909, 0.101734)
Item accuracy: 15011 / 17262 (0.8696)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #231 *****
Loss: 30412.247039
Feature norm: 75.785716
Error norm: 526.352874
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11644, 12961, 12101) (0.8984, 0.9622, 0.9292)
    repeat: (1107, 1329, 1447) (0.8330, 0.7650, 0.7976)
    filler: (1303, 1500, 1423) (0.8687, 0.9157, 0.8915)
    false_start: (931, 1451, 2244) (0.6416, 0.4149, 0.5039)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107589, 0.097760, 0.101544)
Item accuracy: 14997 / 17262 (0.8688)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #232 *****
Loss: 30405.805560
Feature norm: 75.875298
Error norm: 1404.221057
Active features: 158563
Line search trials: 2
Line search step: 0.281430
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12918, 12101) (0.9001, 0.9609, 0.9295)
    repeat: (1100, 1310, 1447) (0.8397, 0.7602, 0.7980)
    filler: (1303, 1497, 1423) (0.8704, 0.9157, 0.8925)
    false_start: (962, 1516, 2244) (0.6346, 0.4287, 0.5117)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107677, 0.097973, 0.101806)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #233 *****
Loss: 30392.471889
Feature norm: 75.926683
Error norm: 920.099993
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11646, 12959, 12101) (0.8987, 0.9624, 0.9294)
    repeat: (1105, 1321, 1447) (0.8365, 0.7636, 0.7984)
    filler: (1301, 1496, 1423) (0.8697, 0.9143, 0.8914)
    false_start: (935, 1465, 2244) (0.6382, 0.4167, 0.5042)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107628, 0.097737, 0.101577)
Item accuracy: 14999 / 17262 (0.8689)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #234 *****
Loss: 30377.107969
Feature norm: 76.003038
Error norm: 515.328665
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11658, 12973, 12101) (0.8986, 0.9634, 0.9299)
    repeat: (1113, 1339, 1447) (0.8312, 0.7692, 0.7990)
    filler: (1301, 1498, 1423) (0.8685, 0.9143, 0.8908)
    false_start: (923, 1431, 2244) (0.6450, 0.4113, 0.5023)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107637, 0.097769, 0.101537)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #235 *****
Loss: 30368.772004
Feature norm: 76.048202
Error norm: 503.446115
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11658, 12970, 12101) (0.8988, 0.9634, 0.9300)
    repeat: (1113, 1341, 1447) (0.8300, 0.7692, 0.7984)
    filler: (1301, 1503, 1423) (0.8656, 0.9143, 0.8893)
    false_start: (923, 1427, 2244) (0.6468, 0.4113, 0.5029)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107578, 0.097769, 0.101497)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #236 *****
Loss: 30362.436226
Feature norm: 76.126927
Error norm: 1203.126557
Active features: 158563
Line search trials: 2
Line search step: 0.517746
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11677, 12999, 12101) (0.8983, 0.9650, 0.9304)
    repeat: (1111, 1334, 1447) (0.8328, 0.7678, 0.7990)
    filler: (1301, 1502, 1423) (0.8662, 0.9143, 0.8896)
    false_start: (917, 1406, 2244) (0.6522, 0.4086, 0.5025)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107808, 0.097700, 0.101522)
Item accuracy: 15018 / 17262 (0.8700)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #237 *****
Loss: 30351.839620
Feature norm: 76.178868
Error norm: 768.124329
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11656, 12952, 12101) (0.8999, 0.9632, 0.9305)
    repeat: (1113, 1343, 1447) (0.8287, 0.7692, 0.7978)
    filler: (1302, 1505, 1423) (0.8651, 0.9150, 0.8893)
    false_start: (938, 1441, 2244) (0.6509, 0.4180, 0.5091)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107675, 0.097970, 0.101670)
Item accuracy: 15021 / 17262 (0.8702)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #238 *****
Loss: 30339.282781
Feature norm: 76.247061
Error norm: 494.931253
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12925, 12101) (0.9004, 0.9617, 0.9301)
    repeat: (1118, 1351, 1447) (0.8275, 0.7726, 0.7991)
    filler: (1303, 1508, 1423) (0.8641, 0.9157, 0.8891)
    false_start: (940, 1457, 2244) (0.6452, 0.4189, 0.5080)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107466, 0.098069, 0.101657)
Item accuracy: 15011 / 17262 (0.8696)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #239 *****
Loss: 30329.321294
Feature norm: 76.320097
Error norm: 631.437196
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11626, 12902, 12101) (0.9011, 0.9607, 0.9300)
    repeat: (1115, 1343, 1447) (0.8302, 0.7706, 0.7993)
    filler: (1305, 1510, 1423) (0.8642, 0.9171, 0.8899)
    false_start: (956, 1486, 2244) (0.6433, 0.4260, 0.5126)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107514, 0.098221, 0.101807)
Item accuracy: 15014 / 17262 (0.8698)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #240 *****
Loss: 30318.933964
Feature norm: 76.387500
Error norm: 559.228002
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12925, 12101) (0.9003, 0.9616, 0.9299)
    repeat: (1118, 1349, 1447) (0.8288, 0.7726, 0.7997)
    filler: (1305, 1510, 1423) (0.8642, 0.9171, 0.8899)
    false_start: (944, 1457, 2244) (0.6479, 0.4207, 0.5101)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107577, 0.098153, 0.101749)
Item accuracy: 15015 / 17262 (0.8698)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #241 *****
Loss: 30316.169849
Feature norm: 76.551255
Error norm: 1791.262939
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11623, 12878, 12101) (0.9025, 0.9605, 0.9306)
    repeat: (1111, 1323, 1447) (0.8398, 0.7678, 0.8022)
    filler: (1305, 1508, 1423) (0.8654, 0.9171, 0.8905)
    false_start: (983, 1532, 2244) (0.6416, 0.4381, 0.5207)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107803, 0.098471, 0.102146)
Item accuracy: 15034 / 17262 (0.8709)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #242 *****
Loss: 30300.669853
Feature norm: 76.499842
Error norm: 540.314223
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12917, 12101) (0.9002, 0.9609, 0.9296)
    repeat: (1119, 1341, 1447) (0.8345, 0.7733, 0.8027)
    filler: (1305, 1508, 1423) (0.8654, 0.9171, 0.8905)
    false_start: (947, 1475, 2244) (0.6420, 0.4220, 0.5093)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107602, 0.098191, 0.101816)
Item accuracy: 15011 / 17262 (0.8696)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #243 *****
Loss: 30293.689220
Feature norm: 76.499510
Error norm: 499.744362
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12941, 12101) (0.8995, 0.9620, 0.9297)
    repeat: (1120, 1345, 1447) (0.8327, 0.7740, 0.8023)
    filler: (1305, 1510, 1423) (0.8642, 0.9171, 0.8899)
    false_start: (931, 1445, 2244) (0.6443, 0.4149, 0.5047)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107566, 0.098042, 0.101666)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #244 *****
Loss: 30287.750689
Feature norm: 76.524747
Error norm: 650.995118
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12949, 12101) (0.8990, 0.9620, 0.9294)
    repeat: (1119, 1346, 1447) (0.8314, 0.7733, 0.8013)
    filler: (1305, 1510, 1423) (0.8642, 0.9171, 0.8899)
    false_start: (923, 1436, 2244) (0.6428, 0.4113, 0.5016)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107470, 0.097923, 0.101543)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #245 *****
Loss: 30277.699719
Feature norm: 76.569452
Error norm: 546.610239
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12949, 12101) (0.8988, 0.9618, 0.9293)
    repeat: (1123, 1352, 1447) (0.8306, 0.7761, 0.8024)
    filler: (1305, 1506, 1423) (0.8665, 0.9171, 0.8911)
    false_start: (919, 1434, 2244) (0.6409, 0.4095, 0.4997)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107456, 0.097946, 0.101551)
Item accuracy: 14998 / 17262 (0.8688)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #246 *****
Loss: 30267.953746
Feature norm: 76.704377
Error norm: 1059.411588
Active features: 158563
Line search trials: 2
Line search step: 0.460542
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11650, 12982, 12101) (0.8974, 0.9627, 0.9289)
    repeat: (1120, 1344, 1447) (0.8333, 0.7740, 0.8026)
    filler: (1304, 1501, 1423) (0.8688, 0.9164, 0.8919)
    false_start: (908, 1414, 2244) (0.6421, 0.4046, 0.4964)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107589, 0.097758, 0.101478)
Item accuracy: 14994 / 17262 (0.8686)
Instance accuracy: 548 / 1316 (0.4164)

***** Iteration #247 *****
Loss: 30253.592607
Feature norm: 76.762284
Error norm: 632.359582
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 12940, 12101) (0.8985, 0.9608, 0.9286)
    repeat: (1118, 1346, 1447) (0.8306, 0.7726, 0.8006)
    filler: (1302, 1497, 1423) (0.8697, 0.9150, 0.8918)
    false_start: (923, 1458, 2244) (0.6331, 0.4113, 0.4986)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107320, 0.097814, 0.101471)
Item accuracy: 14982 / 17262 (0.8679)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #248 *****
Loss: 30246.757516
Feature norm: 76.782561
Error norm: 614.885657
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12935, 12101) (0.8990, 0.9610, 0.9290)
    repeat: (1118, 1346, 1447) (0.8306, 0.7726, 0.8006)
    filler: (1302, 1497, 1423) (0.8697, 0.9150, 0.8918)
    false_start: (930, 1463, 2244) (0.6357, 0.4144, 0.5018)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107407, 0.097905, 0.101567)
Item accuracy: 14991 / 17262 (0.8684)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #249 *****
Loss: 30231.110701
Feature norm: 76.893779
Error norm: 611.064685
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12941, 12101) (0.8991, 0.9615, 0.9292)
    repeat: (1119, 1346, 1447) (0.8314, 0.7733, 0.8013)
    filler: (1303, 1499, 1423) (0.8692, 0.9157, 0.8919)
    false_start: (927, 1455, 2244) (0.6371, 0.4131, 0.5012)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107455, 0.097920, 0.101581)
Item accuracy: 14996 / 17262 (0.8687)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #250 *****
Loss: 30228.514901
Feature norm: 77.016866
Error norm: 1386.571075
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11618, 12900, 12101) (0.9006, 0.9601, 0.9294)
    repeat: (1104, 1317, 1447) (0.8383, 0.7630, 0.7988)
    filler: (1306, 1504, 1423) (0.8684, 0.9178, 0.8924)
    false_start: (966, 1520, 2244) (0.6355, 0.4305, 0.5133)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107621, 0.098135, 0.101868)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 540 / 1316 (0.4103)

***** Iteration #251 *****
Loss: 30217.908687
Feature norm: 77.005192
Error norm: 549.544667
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12943, 12101) (0.8991, 0.9617, 0.9293)
    repeat: (1118, 1341, 1447) (0.8337, 0.7726, 0.8020)
    filler: (1304, 1500, 1423) (0.8693, 0.9164, 0.8922)
    false_start: (932, 1457, 2244) (0.6397, 0.4153, 0.5036)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107594, 0.097987, 0.101682)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #252 *****
Loss: 30211.130243
Feature norm: 77.020550
Error norm: 535.494176
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12943, 12101) (0.8992, 0.9617, 0.9294)
    repeat: (1119, 1342, 1447) (0.8338, 0.7733, 0.8024)
    filler: (1304, 1500, 1423) (0.8693, 0.9164, 0.8922)
    false_start: (933, 1456, 2244) (0.6408, 0.4158, 0.5043)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107631, 0.098021, 0.101715)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 548 / 1316 (0.4164)

***** Iteration #253 *****
Loss: 30202.759717
Feature norm: 77.090981
Error norm: 675.553547
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12953, 12101) (0.8986, 0.9618, 0.9291)
    repeat: (1119, 1342, 1447) (0.8338, 0.7733, 0.8024)
    filler: (1303, 1498, 1423) (0.8698, 0.9157, 0.8922)
    false_start: (926, 1448, 2244) (0.6395, 0.4127, 0.5016)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107592, 0.097917, 0.101630)
Item accuracy: 14999 / 17262 (0.8689)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #254 *****
Loss: 30196.074912
Feature norm: 77.177303
Error norm: 501.050819
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12935, 12101) (0.8993, 0.9612, 0.9292)
    repeat: (1120, 1345, 1447) (0.8327, 0.7740, 0.8023)
    filler: (1303, 1498, 1423) (0.8698, 0.9157, 0.8922)
    false_start: (933, 1463, 2244) (0.6377, 0.4158, 0.5034)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107531, 0.098007, 0.101677)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #255 *****
Loss: 30189.991797
Feature norm: 77.286976
Error norm: 437.130341
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12938, 12101) (0.8991, 0.9612, 0.9291)
    repeat: (1109, 1329, 1447) (0.8345, 0.7664, 0.7990)
    filler: (1303, 1497, 1423) (0.8704, 0.9157, 0.8925)
    false_start: (941, 1477, 2244) (0.6371, 0.4193, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107572, 0.097895, 0.101658)
Item accuracy: 14997 / 17262 (0.8688)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #256 *****
Loss: 30182.630649
Feature norm: 77.318755
Error norm: 526.186088
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12929, 12101) (0.8996, 0.9612, 0.9294)
    repeat: (1107, 1328, 1447) (0.8336, 0.7650, 0.7978)
    filler: (1303, 1497, 1423) (0.8704, 0.9157, 0.8925)
    false_start: (948, 1487, 2244) (0.6375, 0.4225, 0.5082)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107575, 0.097941, 0.101699)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #257 *****
Loss: 30165.038329
Feature norm: 77.404049
Error norm: 736.007663
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12915, 12101) (0.9003, 0.9609, 0.9296)
    repeat: (1111, 1333, 1447) (0.8335, 0.7678, 0.7993)
    filler: (1304, 1503, 1423) (0.8676, 0.9164, 0.8913)
    false_start: (951, 1490, 2244) (0.6383, 0.4238, 0.5094)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107534, 0.098067, 0.101749)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #258 *****
Loss: 30160.802456
Feature norm: 77.541727
Error norm: 1090.996500
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12941, 12101) (0.8989, 0.9613, 0.9291)
    repeat: (1113, 1343, 1447) (0.8287, 0.7692, 0.7978)
    filler: (1306, 1507, 1423) (0.8666, 0.9178, 0.8915)
    false_start: (926, 1450, 2244) (0.6386, 0.4127, 0.5014)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 18, 26) (0.6667, 0.4615, 0.5455)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 3, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.108322, 0.097847, 0.101811)
Item accuracy: 14990 / 17262 (0.8684)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #259 *****
Loss: 30154.623297
Feature norm: 77.484881
Error norm: 551.168785
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12938, 12101) (0.8988, 0.9610, 0.9289)
    repeat: (1113, 1339, 1447) (0.8312, 0.7692, 0.7990)
    filler: (1306, 1507, 1423) (0.8666, 0.9178, 0.8915)
    false_start: (927, 1457, 2244) (0.6362, 0.4131, 0.5009)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 18, 26) (0.6667, 0.4615, 0.5455)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 3, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.108321, 0.097850, 0.101826)
Item accuracy: 14987 / 17262 (0.8682)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #260 *****
Loss: 30148.636752
Feature norm: 77.470310
Error norm: 356.313287
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11626, 12925, 12101) (0.8995, 0.9607, 0.9291)
    repeat: (1110, 1335, 1447) (0.8315, 0.7671, 0.7980)
    filler: (1307, 1509, 1423) (0.8661, 0.9185, 0.8915)
    false_start: (937, 1472, 2244) (0.6365, 0.4176, 0.5043)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 18, 26) (0.6667, 0.4615, 0.5455)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 3, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.108342, 0.097929, 0.101900)
Item accuracy: 14992 / 17262 (0.8685)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #261 *****
Loss: 30139.662188
Feature norm: 77.523507
Error norm: 611.612847
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11620, 12908, 12101) (0.9002, 0.9603, 0.9293)
    repeat: (1108, 1330, 1447) (0.8331, 0.7657, 0.7980)
    filler: (1310, 1521, 1423) (0.8613, 0.9206, 0.8899)
    false_start: (945, 1482, 2244) (0.6377, 0.4211, 0.5072)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (1, 4, 4) (0.2500, 0.2500, 0.2500)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.116336, 0.104978, 0.109238)
Item accuracy: 14996 / 17262 (0.8687)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #262 *****
Loss: 30132.115966
Feature norm: 77.592739
Error norm: 575.374987
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11622, 12917, 12101) (0.8997, 0.9604, 0.9291)
    repeat: (1107, 1328, 1447) (0.8336, 0.7650, 0.7978)
    filler: (1309, 1519, 1423) (0.8618, 0.9199, 0.8899)
    false_start: (942, 1477, 2244) (0.6378, 0.4198, 0.5063)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (1, 4, 4) (0.2500, 0.2500, 0.2500)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.116354, 0.104907, 0.109202)
Item accuracy: 14993 / 17262 (0.8686)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #263 *****
Loss: 30118.387888
Feature norm: 77.745798
Error norm: 1472.705369
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11618, 12888, 12101) (0.9015, 0.9601, 0.9298)
    repeat: (1112, 1339, 1447) (0.8305, 0.7685, 0.7983)
    filler: (1309, 1515, 1423) (0.8640, 0.9199, 0.8911)
    false_start: (959, 1499, 2244) (0.6398, 0.4274, 0.5124)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (1, 4, 4) (0.2500, 0.2500, 0.2500)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.116433, 0.105204, 0.109438)
Item accuracy: 15011 / 17262 (0.8696)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #264 *****
Loss: 30110.601020
Feature norm: 77.735000
Error norm: 472.432964
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12952, 12101) (0.8983, 0.9615, 0.9288)
    repeat: (1106, 1326, 1447) (0.8341, 0.7643, 0.7977)
    filler: (1307, 1511, 1423) (0.8650, 0.9185, 0.8909)
    false_start: (929, 1452, 2244) (0.6398, 0.4140, 0.5027)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 18, 26) (0.6667, 0.4615, 0.5455)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 3, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.108441, 0.097773, 0.101823)
Item accuracy: 14989 / 17262 (0.8683)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #265 *****
Loss: 30106.909899
Feature norm: 77.740548
Error norm: 395.657749
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12949, 12101) (0.8984, 0.9614, 0.9289)
    repeat: (1106, 1328, 1447) (0.8328, 0.7643, 0.7971)
    filler: (1307, 1511, 1423) (0.8650, 0.9185, 0.8909)
    false_start: (929, 1453, 2244) (0.6394, 0.4140, 0.5026)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 18, 26) (0.6667, 0.4615, 0.5455)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 3, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.108397, 0.097771, 0.101804)
Item accuracy: 14988 / 17262 (0.8683)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #266 *****
Loss: 30098.002466
Feature norm: 77.809622
Error norm: 347.758350
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12944, 12101) (0.8989, 0.9616, 0.9292)
    repeat: (1108, 1332, 1447) (0.8318, 0.7657, 0.7974)
    filler: (1309, 1519, 1423) (0.8618, 0.9199, 0.8899)
    false_start: (931, 1446, 2244) (0.6438, 0.4149, 0.5046)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 5, 4) (0.4000, 0.5000, 0.4444)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.121844, 0.111767, 0.114916)
Item accuracy: 14998 / 17262 (0.8688)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #267 *****
Loss: 30093.000842
Feature norm: 77.918338
Error norm: 1368.459562
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11606, 12887, 12101) (0.9006, 0.9591, 0.9289)
    repeat: (1100, 1321, 1447) (0.8327, 0.7602, 0.7948)
    filler: (1305, 1513, 1423) (0.8625, 0.9171, 0.8890)
    false_start: (964, 1520, 2244) (0.6342, 0.4296, 0.5122)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 15, 26) (0.8000, 0.4615, 0.5854)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 6, 4) (0.5000, 0.7500, 0.6000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.125834, 0.118819, 0.119730)
Item accuracy: 14990 / 17262 (0.8684)
Instance accuracy: 541 / 1316 (0.4111)

***** Iteration #268 *****
Loss: 30084.557511
Feature norm: 77.972252
Error norm: 306.191396
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11623, 12932, 12101) (0.8988, 0.9605, 0.9286)
    repeat: (1105, 1330, 1447) (0.8308, 0.7636, 0.7958)
    filler: (1306, 1517, 1423) (0.8609, 0.9178, 0.8884)
    false_start: (935, 1462, 2244) (0.6395, 0.4167, 0.5046)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 14, 26) (0.8571, 0.4615, 0.6000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 7, 4) (0.5714, 1.0000, 0.7273)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.129406, 0.125559, 0.123465)
Item accuracy: 14985 / 17262 (0.8681)
Instance accuracy: 541 / 1316 (0.4111)

***** Iteration #269 *****
Loss: 30082.762241
Feature norm: 77.982477
Error norm: 349.702100
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11626, 12946, 12101) (0.8980, 0.9607, 0.9283)
    repeat: (1105, 1330, 1447) (0.8308, 0.7636, 0.7958)
    filler: (1307, 1516, 1423) (0.8621, 0.9185, 0.8894)
    false_start: (930, 1449, 2244) (0.6418, 0.4144, 0.5037)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 14, 26) (0.8571, 0.4615, 0.6000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 7, 4) (0.5714, 1.0000, 0.7273)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.129483, 0.125524, 0.123458)
Item accuracy: 14984 / 17262 (0.8680)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #270 *****
Loss: 30078.916706
Feature norm: 78.009779
Error norm: 422.612042
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11625, 12950, 12101) (0.8977, 0.9607, 0.9281)
    repeat: (1105, 1324, 1447) (0.8346, 0.7636, 0.7975)
    filler: (1304, 1513, 1423) (0.8619, 0.9164, 0.8883)
    false_start: (932, 1454, 2244) (0.6410, 0.4153, 0.5041)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 14, 26) (0.8571, 0.4615, 0.6000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 7, 4) (0.5714, 1.0000, 0.7273)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.129547, 0.125488, 0.123480)
Item accuracy: 14982 / 17262 (0.8679)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #271 *****
Loss: 30070.233941
Feature norm: 78.072384
Error norm: 400.435493
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11625, 12943, 12101) (0.8982, 0.9607, 0.9284)
    repeat: (1106, 1329, 1447) (0.8322, 0.7643, 0.7968)
    filler: (1303, 1508, 1423) (0.8641, 0.9157, 0.8891)
    false_start: (933, 1461, 2244) (0.6386, 0.4158, 0.5036)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 14, 26) (0.8571, 0.4615, 0.6000)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (4, 7, 4) (0.5714, 1.0000, 0.7273)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.129489, 0.125500, 0.123479)
Item accuracy: 14983 / 17262 (0.8680)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #272 *****
Loss: 30058.457680
Feature norm: 78.140110
Error norm: 812.268925
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11630, 12954, 12101) (0.8978, 0.9611, 0.9284)
    repeat: (1101, 1311, 1447) (0.8398, 0.7609, 0.7984)
    filler: (1303, 1508, 1423) (0.8641, 0.9157, 0.8891)
    false_start: (935, 1468, 2244) (0.6369, 0.4167, 0.5038)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 15, 26) (0.8000, 0.4615, 0.5854)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 6, 4) (0.5000, 0.7500, 0.6000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.126072, 0.118496, 0.119584)
Item accuracy: 14984 / 17262 (0.8680)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #273 *****
Loss: 30053.260257
Feature norm: 78.153548
Error norm: 385.432375
Active features: 158563
Line search trials: 2
Line search step: 0.214231
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12947, 12101) (0.8982, 0.9610, 0.9285)
    repeat: (1101, 1317, 1447) (0.8360, 0.7609, 0.7967)
    filler: (1303, 1508, 1423) (0.8641, 0.9157, 0.8891)
    false_start: (937, 1469, 2244) (0.6378, 0.4176, 0.5047)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 15, 26) (0.8000, 0.4615, 0.5854)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 6, 4) (0.5000, 0.7500, 0.6000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.126003, 0.118518, 0.119567)
Item accuracy: 14985 / 17262 (0.8681)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #274 *****
Loss: 30048.271336
Feature norm: 78.136617
Error norm: 317.032668
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12950, 12101) (0.8980, 0.9610, 0.9284)
    repeat: (1105, 1319, 1447) (0.8378, 0.7636, 0.7990)
    filler: (1303, 1508, 1423) (0.8641, 0.9157, 0.8891)
    false_start: (937, 1464, 2244) (0.6400, 0.4176, 0.5054)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 15, 26) (0.8000, 0.4615, 0.5854)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (3, 6, 4) (0.5000, 0.7500, 0.6000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.126106, 0.118595, 0.119647)
Item accuracy: 14989 / 17262 (0.8683)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #275 *****
Loss: 30038.601097
Feature norm: 78.128452
Error norm: 907.858977
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11626, 12938, 12101) (0.8986, 0.9607, 0.9286)
    repeat: (1108, 1322, 1447) (0.8381, 0.7657, 0.8003)
    filler: (1304, 1505, 1423) (0.8664, 0.9164, 0.8907)
    false_start: (940, 1476, 2244) (0.6369, 0.4189, 0.5054)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 5, 4) (0.4000, 0.5000, 0.4444)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.121945, 0.111758, 0.115024)
Item accuracy: 14992 / 17262 (0.8685)
Instance accuracy: 541 / 1316 (0.4111)

***** Iteration #276 *****
Loss: 30035.358269
Feature norm: 78.127183
Error norm: 993.092998
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12964, 12101) (0.8979, 0.9620, 0.9289)
    repeat: (1118, 1336, 1447) (0.8368, 0.7726, 0.8034)
    filler: (1304, 1497, 1423) (0.8711, 0.9164, 0.8932)
    false_start: (930, 1444, 2244) (0.6440, 0.4144, 0.5043)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 18, 26) (0.6667, 0.4615, 0.5455)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 3, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.108793, 0.097971, 0.102091)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 548 / 1316 (0.4164)

***** Iteration #277 *****
Loss: 30028.983989
Feature norm: 78.135791
Error norm: 264.926392
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12952, 12101) (0.8983, 0.9615, 0.9288)
    repeat: (1113, 1331, 1447) (0.8362, 0.7692, 0.8013)
    filler: (1304, 1499, 1423) (0.8699, 0.9164, 0.8925)
    false_start: (936, 1459, 2244) (0.6415, 0.4171, 0.5055)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 5, 4) (0.4000, 0.5000, 0.4444)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.122111, 0.111825, 0.115113)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #278 *****
Loss: 30026.981764
Feature norm: 78.150365
Error norm: 288.541854
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12948, 12101) (0.8987, 0.9616, 0.9291)
    repeat: (1111, 1329, 1447) (0.8360, 0.7678, 0.8004)
    filler: (1304, 1497, 1423) (0.8711, 0.9164, 0.8932)
    false_start: (941, 1467, 2244) (0.6414, 0.4193, 0.5071)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 16, 26) (0.7500, 0.4615, 0.5714)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 5, 4) (0.4000, 0.5000, 0.4444)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.122143, 0.111851, 0.115157)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #279 *****
Loss: 30023.628229
Feature norm: 78.171449
Error norm: 340.551574
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12940, 12101) (0.8990, 0.9613, 0.9291)
    repeat: (1111, 1329, 1447) (0.8360, 0.7678, 0.8004)
    filler: (1304, 1497, 1423) (0.8711, 0.9164, 0.8932)
    false_start: (944, 1475, 2244) (0.6400, 0.4207, 0.5077)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 18, 26) (0.6667, 0.4615, 0.5455)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 3, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.108686, 0.097992, 0.102106)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #280 *****
Loss: 30014.630511
Feature norm: 78.216616
Error norm: 407.067540
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12935, 12101) (0.8993, 0.9613, 0.9293)
    repeat: (1111, 1328, 1447) (0.8366, 0.7678, 0.8007)
    filler: (1308, 1503, 1423) (0.8703, 0.9192, 0.8941)
    false_start: (943, 1475, 2244) (0.6393, 0.4202, 0.5071)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107697, 0.098058, 0.101793)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #281 *****
Loss: 30006.304621
Feature norm: 78.271567
Error norm: 529.109472
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11644, 12954, 12101) (0.8989, 0.9622, 0.9295)
    repeat: (1109, 1319, 1447) (0.8408, 0.7664, 0.8019)
    filler: (1309, 1507, 1423) (0.8686, 0.9199, 0.8935)
    false_start: (939, 1461, 2244) (0.6427, 0.4184, 0.5069)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107849, 0.098015, 0.101808)
Item accuracy: 15013 / 17262 (0.8697)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #282 *****
Loss: 30003.196870
Feature norm: 78.287638
Error norm: 493.319597
Active features: 158563
Line search trials: 2
Line search step: 0.464898
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12919, 12101) (0.9001, 0.9609, 0.9295)
    repeat: (1110, 1323, 1447) (0.8390, 0.7671, 0.8014)
    filler: (1309, 1511, 1423) (0.8663, 0.9199, 0.8923)
    false_start: (956, 1488, 2244) (0.6425, 0.4260, 0.5123)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107762, 0.098207, 0.101914)
Item accuracy: 15015 / 17262 (0.8698)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #283 *****
Loss: 30000.421700
Feature norm: 78.280831
Error norm: 294.339701
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12939, 12101) (0.8996, 0.9619, 0.9297)
    repeat: (1111, 1324, 1447) (0.8391, 0.7678, 0.8019)
    filler: (1309, 1507, 1423) (0.8686, 0.9199, 0.8935)
    false_start: (952, 1471, 2244) (0.6472, 0.4242, 0.5125)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107947, 0.098205, 0.101971)
Item accuracy: 15024 / 17262 (0.8704)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #284 *****
Loss: 29997.085869
Feature norm: 78.275388
Error norm: 287.430609
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11642, 12951, 12101) (0.8989, 0.9621, 0.9294)
    repeat: (1111, 1324, 1447) (0.8391, 0.7678, 0.8019)
    filler: (1305, 1499, 1423) (0.8706, 0.9171, 0.8932)
    false_start: (943, 1467, 2244) (0.6428, 0.4202, 0.5082)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107862, 0.098020, 0.101836)
Item accuracy: 15013 / 17262 (0.8697)
Instance accuracy: 548 / 1316 (0.4164)

***** Iteration #285 *****
Loss: 29993.508671
Feature norm: 78.280246
Error norm: 328.759518
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12944, 12101) (0.8993, 0.9620, 0.9296)
    repeat: (1113, 1327, 1447) (0.8387, 0.7692, 0.8025)
    filler: (1305, 1499, 1423) (0.8706, 0.9171, 0.8932)
    false_start: (945, 1471, 2244) (0.6424, 0.4211, 0.5087)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107851, 0.098081, 0.101871)
Item accuracy: 15016 / 17262 (0.8699)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #286 *****
Loss: 29985.167399
Feature norm: 78.319329
Error norm: 639.580339
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11648, 12960, 12101) (0.8988, 0.9626, 0.9296)
    repeat: (1113, 1332, 1447) (0.8356, 0.7692, 0.8010)
    filler: (1303, 1497, 1423) (0.8704, 0.9157, 0.8925)
    false_start: (935, 1452, 2244) (0.6439, 0.4167, 0.5060)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107785, 0.097934, 0.101731)
Item accuracy: 15011 / 17262 (0.8696)
Instance accuracy: 548 / 1316 (0.4164)

***** Iteration #287 *****
Loss: 29982.018155
Feature norm: 78.337361
Error norm: 343.935680
Active features: 158563
Line search trials: 2
Line search step: 0.409110
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12931, 12101) (0.8996, 0.9613, 0.9295)
    repeat: (1112, 1329, 1447) (0.8367, 0.7685, 0.8012)
    filler: (1303, 1501, 1423) (0.8681, 0.9157, 0.8912)
    false_start: (949, 1480, 2244) (0.6412, 0.4229, 0.5097)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107701, 0.098054, 0.101801)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 549 / 1316 (0.4172)

***** Iteration #288 *****
Loss: 29979.378225
Feature norm: 78.359844
Error norm: 258.481090
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12928, 12101) (0.8997, 0.9612, 0.9294)
    repeat: (1111, 1327, 1447) (0.8372, 0.7678, 0.8010)
    filler: (1303, 1501, 1423) (0.8681, 0.9157, 0.8912)
    false_start: (951, 1485, 2244) (0.6404, 0.4238, 0.5101)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107694, 0.098055, 0.101807)
Item accuracy: 15008 / 17262 (0.8694)
Instance accuracy: 549 / 1316 (0.4172)

***** Iteration #289 *****
Loss: 29975.964119
Feature norm: 78.383787
Error norm: 514.358700
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12916, 12101) (0.9004, 0.9610, 0.9297)
    repeat: (1115, 1335, 1447) (0.8352, 0.7706, 0.8016)
    filler: (1305, 1505, 1423) (0.8671, 0.9171, 0.8914)
    false_start: (951, 1485, 2244) (0.6404, 0.4238, 0.5101)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107629, 0.098166, 0.101835)
Item accuracy: 15012 / 17262 (0.8697)
Instance accuracy: 549 / 1316 (0.4172)

***** Iteration #290 *****
Loss: 29972.166323
Feature norm: 78.413083
Error norm: 324.696234
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12932, 12101) (0.8995, 0.9612, 0.9293)
    repeat: (1111, 1329, 1447) (0.8360, 0.7678, 0.8004)
    filler: (1309, 1513, 1423) (0.8652, 0.9199, 0.8917)
    false_start: (945, 1467, 2244) (0.6442, 0.4211, 0.5093)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107677, 0.098100, 0.101780)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 549 / 1316 (0.4172)

***** Iteration #291 *****
Loss: 29969.191425
Feature norm: 78.419883
Error norm: 293.720612
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12926, 12101) (0.8996, 0.9609, 0.9292)
    repeat: (1110, 1328, 1447) (0.8358, 0.7671, 0.8000)
    filler: (1309, 1513, 1423) (0.8652, 0.9199, 0.8917)
    false_start: (945, 1474, 2244) (0.6411, 0.4211, 0.5083)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107591, 0.098071, 0.101739)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #292 *****
Loss: 29961.258036
Feature norm: 78.455659
Error norm: 217.710222
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11626, 12929, 12101) (0.8992, 0.9607, 0.9290)
    repeat: (1107, 1323, 1447) (0.8367, 0.7650, 0.7993)
    filler: (1307, 1509, 1423) (0.8661, 0.9185, 0.8915)
    false_start: (945, 1480, 2244) (0.6385, 0.4211, 0.5075)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107561, 0.097970, 0.101684)
Item accuracy: 14997 / 17262 (0.8688)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #293 *****
Loss: 29956.775804
Feature norm: 78.455195
Error norm: 287.802034
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 12937, 12101) (0.8987, 0.9608, 0.9287)
    repeat: (1107, 1321, 1447) (0.8380, 0.7650, 0.7999)
    filler: (1306, 1507, 1423) (0.8666, 0.9178, 0.8915)
    false_start: (941, 1476, 2244) (0.6375, 0.4193, 0.5059)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107569, 0.097903, 0.101648)
Item accuracy: 14993 / 17262 (0.8686)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #294 *****
Loss: 29953.986712
Feature norm: 78.461340
Error norm: 644.403130
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11645, 12973, 12101) (0.8976, 0.9623, 0.9289)
    repeat: (1110, 1329, 1447) (0.8352, 0.7671, 0.7997)
    filler: (1304, 1501, 1423) (0.8688, 0.9164, 0.8919)
    false_start: (925, 1438, 2244) (0.6433, 0.4122, 0.5024)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107679, 0.097765, 0.101563)
Item accuracy: 14996 / 17262 (0.8687)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #295 *****
Loss: 29950.253399
Feature norm: 78.463483
Error norm: 316.717397
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12964, 12101) (0.8979, 0.9619, 0.9288)
    repeat: (1110, 1329, 1447) (0.8352, 0.7671, 0.7997)
    filler: (1304, 1501, 1423) (0.8688, 0.9164, 0.8919)
    false_start: (927, 1447, 2244) (0.6406, 0.4131, 0.5023)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107613, 0.097778, 0.101557)
Item accuracy: 14993 / 17262 (0.8686)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #296 *****
Loss: 29945.765400
Feature norm: 78.479487
Error norm: 290.221633
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12936, 12101) (0.8990, 0.9610, 0.9289)
    repeat: (1115, 1336, 1447) (0.8346, 0.7706, 0.8013)
    filler: (1304, 1501, 1423) (0.8688, 0.9164, 0.8919)
    false_start: (938, 1468, 2244) (0.6390, 0.4180, 0.5054)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107579, 0.097985, 0.101691)
Item accuracy: 14998 / 17262 (0.8688)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #297 *****
Loss: 29942.725438
Feature norm: 78.489622
Error norm: 285.784250
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12943, 12101) (0.8986, 0.9612, 0.9288)
    repeat: (1113, 1334, 1447) (0.8343, 0.7692, 0.8004)
    filler: (1304, 1501, 1423) (0.8688, 0.9164, 0.8919)
    false_start: (936, 1463, 2244) (0.6398, 0.4171, 0.5050)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107586, 0.097927, 0.101654)
Item accuracy: 14996 / 17262 (0.8687)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #298 *****
Loss: 29940.610917
Feature norm: 78.505538
Error norm: 700.985773
Active features: 158563
Line search trials: 2
Line search step: 0.194603
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12933, 12101) (0.8991, 0.9609, 0.9290)
    repeat: (1116, 1337, 1447) (0.8347, 0.7713, 0.8017)
    filler: (1304, 1501, 1423) (0.8688, 0.9164, 0.8919)
    false_start: (938, 1470, 2244) (0.6381, 0.4180, 0.5051)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107562, 0.098002, 0.101697)
Item accuracy: 14998 / 17262 (0.8688)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #299 *****
Loss: 29935.645820
Feature norm: 78.524909
Error norm: 333.569654
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12960, 12101) (0.8978, 0.9616, 0.9286)
    repeat: (1111, 1332, 1447) (0.8341, 0.7678, 0.7996)
    filler: (1304, 1501, 1423) (0.8688, 0.9164, 0.8919)
    false_start: (926, 1448, 2244) (0.6395, 0.4127, 0.5016)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107549, 0.097776, 0.101530)
Item accuracy: 14989 / 17262 (0.8683)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #300 *****
Loss: 29933.436214
Feature norm: 78.531549
Error norm: 231.641410
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12960, 12101) (0.8978, 0.9616, 0.9286)
    repeat: (1111, 1332, 1447) (0.8341, 0.7678, 0.7996)
    filler: (1304, 1501, 1423) (0.8688, 0.9164, 0.8919)
    false_start: (926, 1448, 2244) (0.6395, 0.4127, 0.5016)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107549, 0.097776, 0.101530)
Item accuracy: 14989 / 17262 (0.8683)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #301 *****
Loss: 29929.016234
Feature norm: 78.546295
Error norm: 376.855334
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12963, 12101) (0.8977, 0.9617, 0.9286)
    repeat: (1110, 1331, 1447) (0.8340, 0.7671, 0.7991)
    filler: (1304, 1501, 1423) (0.8688, 0.9164, 0.8919)
    false_start: (926, 1446, 2244) (0.6404, 0.4127, 0.5019)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107566, 0.097759, 0.101524)
Item accuracy: 14989 / 17262 (0.8683)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #302 *****
Loss: 29925.826561
Feature norm: 78.557679
Error norm: 283.963150
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12957, 12101) (0.8978, 0.9613, 0.9285)
    repeat: (1112, 1325, 1447) (0.8392, 0.7685, 0.8023)
    filler: (1305, 1502, 1423) (0.8688, 0.9171, 0.8923)
    false_start: (934, 1457, 2244) (0.6410, 0.4162, 0.5047)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107737, 0.097907, 0.101699)
Item accuracy: 14996 / 17262 (0.8687)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #303 *****
Loss: 29923.919324
Feature norm: 78.568745
Error norm: 561.949402
Active features: 158563
Line search trials: 2
Line search step: 0.419927
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12966, 12101) (0.8976, 0.9617, 0.9286)
    repeat: (1112, 1329, 1447) (0.8367, 0.7685, 0.8012)
    filler: (1307, 1502, 1423) (0.8702, 0.9185, 0.8937)
    false_start: (923, 1444, 2244) (0.6392, 0.4113, 0.5005)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107646, 0.097821, 0.101590)
Item accuracy: 14992 / 17262 (0.8685)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #304 *****
Loss: 29921.533475
Feature norm: 78.572734
Error norm: 278.741920
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12957, 12101) (0.8977, 0.9612, 0.9284)
    repeat: (1112, 1325, 1447) (0.8392, 0.7685, 0.8023)
    filler: (1307, 1502, 1423) (0.8702, 0.9185, 0.8937)
    false_start: (929, 1457, 2244) (0.6376, 0.4140, 0.5020)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107676, 0.097882, 0.101660)
Item accuracy: 14992 / 17262 (0.8685)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #305 *****
Loss: 29919.276410
Feature norm: 78.578724
Error norm: 246.873276
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12953, 12101) (0.8982, 0.9615, 0.9288)
    repeat: (1112, 1325, 1447) (0.8392, 0.7685, 0.8023)
    filler: (1307, 1502, 1423) (0.8702, 0.9185, 0.8937)
    false_start: (937, 1461, 2244) (0.6413, 0.4176, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107794, 0.097988, 0.101775)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #306 *****
Loss: 29918.214369
Feature norm: 78.582538
Error norm: 215.219219
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12952, 12101) (0.8982, 0.9614, 0.9288)
    repeat: (1112, 1325, 1447) (0.8392, 0.7685, 0.8023)
    filler: (1307, 1502, 1423) (0.8702, 0.9185, 0.8937)
    false_start: (937, 1462, 2244) (0.6409, 0.4176, 0.5057)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107782, 0.097985, 0.101770)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #307 *****
Loss: 29916.712338
Feature norm: 78.599553
Error norm: 672.307231
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11623, 12930, 12101) (0.8989, 0.9605, 0.9287)
    repeat: (1118, 1336, 1447) (0.8368, 0.7726, 0.8034)
    filler: (1307, 1502, 1423) (0.8702, 0.9185, 0.8937)
    false_start: (939, 1473, 2244) (0.6375, 0.4184, 0.5052)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107638, 0.098100, 0.101789)
Item accuracy: 14999 / 17262 (0.8689)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #308 *****
Loss: 29913.766784
Feature norm: 78.611583
Error norm: 264.980806
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12953, 12101) (0.8986, 0.9619, 0.9292)
    repeat: (1116, 1332, 1447) (0.8378, 0.7713, 0.8032)
    filler: (1307, 1502, 1423) (0.8702, 0.9185, 0.8937)
    false_start: (937, 1454, 2244) (0.6444, 0.4176, 0.5068)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107851, 0.098076, 0.101837)
Item accuracy: 15012 / 17262 (0.8697)
Instance accuracy: 549 / 1316 (0.4172)

***** Iteration #309 *****
Loss: 29911.907341
Feature norm: 78.623513
Error norm: 213.752618
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12945, 12101) (0.8990, 0.9617, 0.9293)
    repeat: (1116, 1332, 1447) (0.8378, 0.7713, 0.8032)
    filler: (1307, 1502, 1423) (0.8702, 0.9185, 0.8937)
    false_start: (940, 1462, 2244) (0.6430, 0.4189, 0.5073)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107822, 0.098108, 0.101855)
Item accuracy: 15013 / 17262 (0.8697)
Instance accuracy: 549 / 1316 (0.4172)

***** Iteration #310 *****
Loss: 29910.415082
Feature norm: 78.636416
Error norm: 235.026138
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12945, 12101) (0.8990, 0.9617, 0.9293)
    repeat: (1116, 1332, 1447) (0.8378, 0.7713, 0.8032)
    filler: (1307, 1502, 1423) (0.8702, 0.9185, 0.8937)
    false_start: (940, 1462, 2244) (0.6430, 0.4189, 0.5073)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107822, 0.098108, 0.101855)
Item accuracy: 15013 / 17262 (0.8697)
Instance accuracy: 549 / 1316 (0.4172)

***** Iteration #311 *****
Loss: 29908.274480
Feature norm: 78.660624
Error norm: 443.947722
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12936, 12101) (0.8991, 0.9612, 0.9291)
    repeat: (1116, 1329, 1447) (0.8397, 0.7713, 0.8040)
    filler: (1307, 1502, 1423) (0.8702, 0.9185, 0.8937)
    false_start: (944, 1474, 2244) (0.6404, 0.4207, 0.5078)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107807, 0.098142, 0.101887)
Item accuracy: 15010 / 17262 (0.8695)
Instance accuracy: 549 / 1316 (0.4172)

***** Iteration #312 *****
Loss: 29905.082777
Feature norm: 78.684097
Error norm: 218.663403
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12942, 12101) (0.8992, 0.9617, 0.9294)
    repeat: (1117, 1333, 1447) (0.8380, 0.7719, 0.8036)
    filler: (1306, 1501, 1423) (0.8701, 0.9178, 0.8933)
    false_start: (942, 1465, 2244) (0.6430, 0.4198, 0.5080)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107828, 0.098131, 0.101876)
Item accuracy: 15014 / 17262 (0.8698)
Instance accuracy: 552 / 1316 (0.4195)

***** Iteration #313 *****
Loss: 29902.375144
Feature norm: 78.691693
Error norm: 220.048941
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12947, 12101) (0.8990, 0.9619, 0.9294)
    repeat: (1119, 1334, 1447) (0.8388, 0.7733, 0.8047)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (941, 1461, 2244) (0.6441, 0.4193, 0.5080)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107911, 0.098164, 0.101927)
Item accuracy: 15018 / 17262 (0.8700)
Instance accuracy: 552 / 1316 (0.4195)

***** Iteration #314 *****
Loss: 29896.996256
Feature norm: 78.715212
Error norm: 229.169284
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12943, 12101) (0.8989, 0.9614, 0.9291)
    repeat: (1118, 1339, 1447) (0.8350, 0.7726, 0.8026)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (935, 1460, 2244) (0.6404, 0.4167, 0.5049)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107696, 0.098056, 0.101771)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #315 *****
Loss: 29895.882152
Feature norm: 78.725305
Error norm: 486.664067
Active features: 158563
Line search trials: 2
Line search step: 0.182441
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11649, 12963, 12101) (0.8986, 0.9626, 0.9295)
    repeat: (1116, 1330, 1447) (0.8391, 0.7713, 0.8037)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (935, 1449, 2244) (0.6453, 0.4167, 0.5064)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107940, 0.098052, 0.101858)
Item accuracy: 15018 / 17262 (0.8700)
Instance accuracy: 549 / 1316 (0.4172)

***** Iteration #316 *****
Loss: 29892.802190
Feature norm: 78.743254
Error norm: 266.632651
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12959, 12101) (0.8982, 0.9619, 0.9290)
    repeat: (1118, 1337, 1447) (0.8362, 0.7726, 0.8032)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (927, 1446, 2244) (0.6411, 0.4131, 0.5024)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107731, 0.097971, 0.101717)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #317 *****
Loss: 29890.273491
Feature norm: 78.756342
Error norm: 196.822487
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12948, 12101) (0.8986, 0.9615, 0.9290)
    repeat: (1116, 1331, 1447) (0.8385, 0.7713, 0.8035)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (937, 1464, 2244) (0.6400, 0.4176, 0.5054)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107773, 0.098025, 0.101797)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #318 *****
Loss: 29885.560182
Feature norm: 78.797446
Error norm: 363.396716
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11625, 12928, 12101) (0.8992, 0.9607, 0.9289)
    repeat: (1114, 1329, 1447) (0.8382, 0.7699, 0.8026)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (946, 1486, 2244) (0.6366, 0.4216, 0.5072)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107688, 0.098075, 0.101823)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #319 *****
Loss: 29883.962034
Feature norm: 78.828898
Error norm: 394.203654
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12948, 12101) (0.8988, 0.9617, 0.9292)
    repeat: (1119, 1342, 1447) (0.8338, 0.7733, 0.8024)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (940, 1453, 2244) (0.6469, 0.4189, 0.5085)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107843, 0.098127, 0.101862)
Item accuracy: 15014 / 17262 (0.8698)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #320 *****
Loss: 29881.514334
Feature norm: 78.834927
Error norm: 243.873797
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12945, 12101) (0.8987, 0.9614, 0.9290)
    repeat: (1117, 1336, 1447) (0.8361, 0.7719, 0.8027)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (940, 1462, 2244) (0.6430, 0.4189, 0.5073)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107792, 0.098079, 0.101830)
Item accuracy: 15008 / 17262 (0.8694)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #321 *****
Loss: 29879.125810
Feature norm: 78.843254
Error norm: 226.424033
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12943, 12101) (0.8989, 0.9614, 0.9291)
    repeat: (1117, 1336, 1447) (0.8361, 0.7719, 0.8027)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (942, 1464, 2244) (0.6434, 0.4198, 0.5081)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107809, 0.098104, 0.101855)
Item accuracy: 15010 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #322 *****
Loss: 29874.288566
Feature norm: 78.880419
Error norm: 209.954490
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12948, 12101) (0.8985, 0.9614, 0.9289)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (940, 1462, 2244) (0.6430, 0.4189, 0.5073)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107796, 0.098041, 0.101811)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #323 *****
Loss: 29873.480111
Feature norm: 78.889385
Error norm: 480.005866
Active features: 158563
Line search trials: 2
Line search step: 0.134952
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11622, 12924, 12101) (0.8993, 0.9604, 0.9288)
    repeat: (1116, 1332, 1447) (0.8378, 0.7713, 0.8032)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (947, 1487, 2244) (0.6369, 0.4220, 0.5076)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107686, 0.098119, 0.101847)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #324 *****
Loss: 29870.949713
Feature norm: 78.919971
Error norm: 225.546382
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12945, 12101) (0.8987, 0.9614, 0.9290)
    repeat: (1116, 1335, 1447) (0.8360, 0.7713, 0.8023)
    filler: (1306, 1501, 1423) (0.8701, 0.9178, 0.8933)
    false_start: (937, 1460, 2244) (0.6418, 0.4176, 0.5059)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107726, 0.098043, 0.101774)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #325 *****
Loss: 29869.633897
Feature norm: 78.931482
Error norm: 184.996046
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12945, 12101) (0.8987, 0.9614, 0.9290)
    repeat: (1116, 1335, 1447) (0.8360, 0.7713, 0.8023)
    filler: (1306, 1501, 1423) (0.8701, 0.9178, 0.8933)
    false_start: (937, 1460, 2244) (0.6418, 0.4176, 0.5059)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107726, 0.098043, 0.101774)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #326 *****
Loss: 29866.828642
Feature norm: 78.958515
Error norm: 252.159980
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12934, 12101) (0.8993, 0.9612, 0.9292)
    repeat: (1118, 1336, 1447) (0.8368, 0.7726, 0.8034)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (943, 1473, 2244) (0.6402, 0.4202, 0.5074)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107750, 0.098129, 0.101858)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #327 *****
Loss: 29864.197862
Feature norm: 78.983325
Error norm: 208.488726
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 12926, 12101) (0.8995, 0.9608, 0.9292)
    repeat: (1118, 1334, 1447) (0.8381, 0.7726, 0.8040)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (948, 1483, 2244) (0.6392, 0.4225, 0.5087)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107766, 0.098182, 0.101910)
Item accuracy: 15010 / 17262 (0.8695)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #328 *****
Loss: 29862.370320
Feature norm: 78.998553
Error norm: 556.623652
Active features: 158563
Line search trials: 2
Line search step: 0.345976
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12934, 12101) (0.8993, 0.9612, 0.9293)
    repeat: (1120, 1340, 1447) (0.8358, 0.7740, 0.8037)
    filler: (1305, 1502, 1423) (0.8688, 0.9171, 0.8923)
    false_start: (943, 1465, 2244) (0.6437, 0.4202, 0.5085)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107757, 0.098170, 0.101865)
Item accuracy: 15012 / 17262 (0.8697)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #329 *****
Loss: 29858.400808
Feature norm: 79.037416
Error norm: 256.562024
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11625, 12924, 12101) (0.8995, 0.9607, 0.9291)
    repeat: (1119, 1336, 1447) (0.8376, 0.7733, 0.8042)
    filler: (1305, 1502, 1423) (0.8688, 0.9171, 0.8923)
    false_start: (947, 1479, 2244) (0.6403, 0.4220, 0.5087)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107716, 0.098184, 0.101878)
Item accuracy: 15008 / 17262 (0.8694)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #330 *****
Loss: 29856.078609
Feature norm: 79.056799
Error norm: 243.138346
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11626, 12921, 12101) (0.8998, 0.9607, 0.9293)
    repeat: (1119, 1336, 1447) (0.8376, 0.7733, 0.8042)
    filler: (1304, 1499, 1423) (0.8699, 0.9164, 0.8925)
    false_start: (953, 1485, 2244) (0.6418, 0.4247, 0.5111)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107794, 0.098241, 0.101956)
Item accuracy: 15014 / 17262 (0.8698)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #331 *****
Loss: 29854.036114
Feature norm: 79.075508
Error norm: 277.936322
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12938, 12101) (0.8992, 0.9614, 0.9293)
    repeat: (1114, 1328, 1447) (0.8389, 0.7699, 0.8029)
    filler: (1304, 1499, 1423) (0.8699, 0.9164, 0.8925)
    false_start: (950, 1476, 2244) (0.6436, 0.4234, 0.5108)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107866, 0.098126, 0.101911)
Item accuracy: 15014 / 17262 (0.8698)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #332 *****
Loss: 29853.700973
Feature norm: 79.082584
Error norm: 842.501131
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11619, 12904, 12101) (0.9004, 0.9602, 0.9293)
    repeat: (1121, 1338, 1447) (0.8378, 0.7747, 0.8050)
    filler: (1304, 1495, 1423) (0.8722, 0.9164, 0.8938)
    false_start: (964, 1504, 2244) (0.6410, 0.4296, 0.5144)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107861, 0.098399, 0.102107)
Item accuracy: 15020 / 17262 (0.8701)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #333 *****
Loss: 29851.616505
Feature norm: 79.077251
Error norm: 305.090137
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12928, 12101) (0.8995, 0.9610, 0.9292)
    repeat: (1119, 1334, 1447) (0.8388, 0.7733, 0.8047)
    filler: (1304, 1495, 1423) (0.8722, 0.9164, 0.8938)
    false_start: (952, 1484, 2244) (0.6415, 0.4242, 0.5107)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107880, 0.098235, 0.101995)
Item accuracy: 15016 / 17262 (0.8699)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #334 *****
Loss: 29850.519532
Feature norm: 79.074305
Error norm: 174.049630
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12932, 12101) (0.8992, 0.9610, 0.9291)
    repeat: (1118, 1334, 1447) (0.8381, 0.7726, 0.8040)
    filler: (1304, 1497, 1423) (0.8711, 0.9164, 0.8932)
    false_start: (947, 1478, 2244) (0.6407, 0.4220, 0.5089)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107797, 0.098154, 0.101902)
Item accuracy: 15010 / 17262 (0.8695)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #335 *****
Loss: 29849.006364
Feature norm: 79.077447
Error norm: 357.414473
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12937, 12101) (0.8993, 0.9614, 0.9293)
    repeat: (1120, 1336, 1447) (0.8383, 0.7740, 0.8049)
    filler: (1304, 1497, 1423) (0.8711, 0.9164, 0.8932)
    false_start: (945, 1471, 2244) (0.6424, 0.4211, 0.5087)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107852, 0.098179, 0.101929)
Item accuracy: 15015 / 17262 (0.8698)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #336 *****
Loss: 29847.241754
Feature norm: 79.085187
Error norm: 424.204051
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11630, 12932, 12101) (0.8993, 0.9611, 0.9292)
    repeat: (1119, 1334, 1447) (0.8388, 0.7733, 0.8047)
    filler: (1304, 1495, 1423) (0.8722, 0.9164, 0.8938)
    false_start: (948, 1480, 2244) (0.6405, 0.4225, 0.5091)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107848, 0.098188, 0.101949)
Item accuracy: 15013 / 17262 (0.8697)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #337 *****
Loss: 29843.471148
Feature norm: 79.103274
Error norm: 465.731399
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12931, 12101) (0.8993, 0.9610, 0.9291)
    repeat: (1118, 1333, 1447) (0.8387, 0.7726, 0.8043)
    filler: (1304, 1495, 1423) (0.8722, 0.9164, 0.8938)
    false_start: (949, 1482, 2244) (0.6404, 0.4229, 0.5094)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107839, 0.098179, 0.101943)
Item accuracy: 15012 / 17262 (0.8697)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #338 *****
Loss: 29841.661883
Feature norm: 79.128317
Error norm: 550.869779
Active features: 158563
Line search trials: 2
Line search step: 0.213261
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12942, 12101) (0.8989, 0.9613, 0.9290)
    repeat: (1119, 1338, 1447) (0.8363, 0.7733, 0.8036)
    filler: (1304, 1495, 1423) (0.8722, 0.9164, 0.8938)
    false_start: (944, 1466, 2244) (0.6439, 0.4207, 0.5089)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107859, 0.098146, 0.101906)
Item accuracy: 15012 / 17262 (0.8697)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #339 *****
Loss: 29838.304176
Feature norm: 79.145429
Error norm: 189.078063
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12927, 12101) (0.8995, 0.9609, 0.9292)
    repeat: (1120, 1335, 1447) (0.8390, 0.7740, 0.8052)
    filler: (1304, 1495, 1423) (0.8722, 0.9164, 0.8938)
    false_start: (957, 1484, 2244) (0.6449, 0.4265, 0.5134)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107977, 0.098314, 0.102080)
Item accuracy: 15021 / 17262 (0.8702)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #340 *****
Loss: 29837.334062
Feature norm: 79.148485
Error norm: 214.614781
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11630, 12925, 12101) (0.8998, 0.9611, 0.9294)
    repeat: (1120, 1335, 1447) (0.8390, 0.7740, 0.8052)
    filler: (1304, 1495, 1423) (0.8722, 0.9164, 0.8938)
    false_start: (960, 1486, 2244) (0.6460, 0.4278, 0.5147)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.108017, 0.098356, 0.102124)
Item accuracy: 15026 / 17262 (0.8705)
Instance accuracy: 548 / 1316 (0.4164)

***** Iteration #341 *****
Loss: 29835.211294
Feature norm: 79.158292
Error norm: 166.986950
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12929, 12101) (0.8998, 0.9614, 0.9296)
    repeat: (1120, 1337, 1447) (0.8377, 0.7740, 0.8046)
    filler: (1305, 1496, 1423) (0.8723, 0.9171, 0.8941)
    false_start: (958, 1479, 2244) (0.6477, 0.4269, 0.5146)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.108033, 0.098360, 0.102120)
Item accuracy: 15029 / 17262 (0.8706)
Instance accuracy: 549 / 1316 (0.4172)

***** Iteration #342 *****
Loss: 29834.903831
Feature norm: 79.172537
Error norm: 987.251677
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11621, 12910, 12101) (0.9002, 0.9603, 0.9293)
    repeat: (1115, 1330, 1447) (0.8383, 0.7706, 0.8030)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (962, 1503, 2244) (0.6401, 0.4287, 0.5135)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107814, 0.098284, 0.102018)
Item accuracy: 15015 / 17262 (0.8698)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #343 *****
Loss: 29831.596506
Feature norm: 79.180334
Error norm: 246.786458
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12942, 12101) (0.8993, 0.9618, 0.9295)
    repeat: (1115, 1328, 1447) (0.8396, 0.7706, 0.8036)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (951, 1473, 2244) (0.6456, 0.4238, 0.5117)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107980, 0.098189, 0.101991)
Item accuracy: 15022 / 17262 (0.8702)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #344 *****
Loss: 29830.517707
Feature norm: 79.185062
Error norm: 176.123138
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12942, 12101) (0.8993, 0.9618, 0.9295)
    repeat: (1115, 1328, 1447) (0.8396, 0.7706, 0.8036)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (951, 1473, 2244) (0.6456, 0.4238, 0.5117)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107980, 0.098189, 0.101991)
Item accuracy: 15022 / 17262 (0.8702)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #345 *****
Loss: 29829.439179
Feature norm: 79.194636
Error norm: 175.272940
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12943, 12101) (0.8993, 0.9619, 0.9296)
    repeat: (1115, 1327, 1447) (0.8402, 0.7706, 0.8039)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (951, 1473, 2244) (0.6456, 0.4238, 0.5117)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107998, 0.098191, 0.102001)
Item accuracy: 15023 / 17262 (0.8703)
Instance accuracy: 548 / 1316 (0.4164)

***** Iteration #346 *****
Loss: 29827.866776
Feature norm: 79.204651
Error norm: 234.636878
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12947, 12101) (0.8988, 0.9617, 0.9292)
    repeat: (1115, 1330, 1447) (0.8383, 0.7706, 0.8030)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (943, 1466, 2244) (0.6432, 0.4202, 0.5084)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107865, 0.098085, 0.101873)
Item accuracy: 15012 / 17262 (0.8697)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #347 *****
Loss: 29826.891056
Feature norm: 79.234730
Error norm: 467.435613
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12943, 12101) (0.8994, 0.9620, 0.9296)
    repeat: (1110, 1323, 1447) (0.8390, 0.7671, 0.8014)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (954, 1477, 2244) (0.6459, 0.4251, 0.5128)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107974, 0.098134, 0.101964)
Item accuracy: 15022 / 17262 (0.8702)
Instance accuracy: 550 / 1316 (0.4179)

***** Iteration #348 *****
Loss: 29823.770501
Feature norm: 79.239377
Error norm: 197.940657
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12944, 12101) (0.8990, 0.9617, 0.9293)
    repeat: (1112, 1327, 1447) (0.8380, 0.7685, 0.8017)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (947, 1472, 2244) (0.6433, 0.4220, 0.5097)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107864, 0.098077, 0.101877)
Item accuracy: 15013 / 17262 (0.8697)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #349 *****
Loss: 29822.450559
Feature norm: 79.241572
Error norm: 141.099343
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12944, 12101) (0.8990, 0.9617, 0.9293)
    repeat: (1112, 1327, 1447) (0.8380, 0.7685, 0.8017)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (947, 1472, 2244) (0.6433, 0.4220, 0.5097)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107864, 0.098077, 0.101877)
Item accuracy: 15013 / 17262 (0.8697)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #350 *****
Loss: 29820.851485
Feature norm: 79.250769
Error norm: 204.347080
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12946, 12101) (0.8990, 0.9618, 0.9294)
    repeat: (1112, 1329, 1447) (0.8367, 0.7685, 0.8012)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (946, 1468, 2244) (0.6444, 0.4216, 0.5097)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107859, 0.098069, 0.101864)
Item accuracy: 15014 / 17262 (0.8698)
Instance accuracy: 548 / 1316 (0.4164)

***** Iteration #351 *****
Loss: 29820.502504
Feature norm: 79.253315
Error norm: 260.459130
Active features: 158563
Line search trials: 2
Line search step: 0.153455
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11630, 12936, 12101) (0.8990, 0.9611, 0.9290)
    repeat: (1112, 1324, 1447) (0.8399, 0.7685, 0.8026)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (952, 1483, 2244) (0.6419, 0.4242, 0.5109)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107878, 0.098123, 0.101926)
Item accuracy: 15011 / 17262 (0.8696)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #352 *****
Loss: 29819.625610
Feature norm: 79.261956
Error norm: 213.172305
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11630, 12936, 12101) (0.8990, 0.9611, 0.9290)
    repeat: (1112, 1328, 1447) (0.8373, 0.7685, 0.8014)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (950, 1479, 2244) (0.6423, 0.4234, 0.5103)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107818, 0.098098, 0.101880)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #353 *****
Loss: 29817.364444
Feature norm: 79.274799
Error norm: 173.337878
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12949, 12101) (0.8984, 0.9614, 0.9289)
    repeat: (1108, 1322, 1447) (0.8381, 0.7657, 0.8003)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (947, 1472, 2244) (0.6433, 0.4220, 0.5097)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107852, 0.097993, 0.101825)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 548 / 1316 (0.4164)

***** Iteration #354 *****
Loss: 29814.563358
Feature norm: 79.292319
Error norm: 174.801741
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12946, 12101) (0.8991, 0.9619, 0.9295)
    repeat: (1113, 1327, 1447) (0.8387, 0.7692, 0.8025)
    filler: (1305, 1502, 1423) (0.8688, 0.9171, 0.8923)
    false_start: (948, 1466, 2244) (0.6467, 0.4225, 0.5111)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107915, 0.098115, 0.101905)
Item accuracy: 15018 / 17262 (0.8700)
Instance accuracy: 550 / 1316 (0.4179)

***** Iteration #355 *****
Loss: 29813.237785
Feature norm: 79.306321
Error norm: 347.137162
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12941, 12101) (0.8992, 0.9617, 0.9294)
    repeat: (1108, 1321, 1447) (0.8388, 0.7657, 0.8006)
    filler: (1305, 1502, 1423) (0.8688, 0.9171, 0.8923)
    false_start: (955, 1477, 2244) (0.6466, 0.4256, 0.5133)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107917, 0.098099, 0.101914)
Item accuracy: 15017 / 17262 (0.8699)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #356 *****
Loss: 29811.387038
Feature norm: 79.312210
Error norm: 153.994468
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12937, 12101) (0.8995, 0.9617, 0.9295)
    repeat: (1113, 1327, 1447) (0.8387, 0.7692, 0.8025)
    filler: (1305, 1502, 1423) (0.8688, 0.9171, 0.8923)
    false_start: (954, 1475, 2244) (0.6468, 0.4251, 0.5130)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107929, 0.098183, 0.101963)
Item accuracy: 15021 / 17262 (0.8702)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #357 *****
Loss: 29810.086383
Feature norm: 79.315777
Error norm: 117.493205
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12934, 12101) (0.8996, 0.9615, 0.9295)
    repeat: (1113, 1327, 1447) (0.8387, 0.7692, 0.8025)
    filler: (1305, 1502, 1423) (0.8688, 0.9171, 0.8923)
    false_start: (955, 1478, 2244) (0.6461, 0.4256, 0.5132)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107913, 0.098191, 0.101965)
Item accuracy: 15020 / 17262 (0.8701)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #358 *****
Loss: 29808.632238
Feature norm: 79.324546
Error norm: 159.430787
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12944, 12101) (0.8993, 0.9619, 0.9295)
    repeat: (1111, 1325, 1447) (0.8385, 0.7678, 0.8016)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (952, 1473, 2244) (0.6463, 0.4242, 0.5122)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107969, 0.098146, 0.101961)
Item accuracy: 15021 / 17262 (0.8702)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #359 *****
Loss: 29808.340089
Feature norm: 79.328513
Error norm: 287.664997
Active features: 158563
Line search trials: 2
Line search step: 0.114772
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 12923, 12101) (0.8997, 0.9608, 0.9293)
    repeat: (1113, 1325, 1447) (0.8400, 0.7692, 0.8030)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (959, 1494, 2244) (0.6419, 0.4274, 0.5131)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107901, 0.098241, 0.102018)
Item accuracy: 15017 / 17262 (0.8699)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #360 *****
Loss: 29807.207661
Feature norm: 79.339617
Error norm: 200.792913
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12936, 12101) (0.8993, 0.9613, 0.9293)
    repeat: (1113, 1323, 1447) (0.8413, 0.7692, 0.8036)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (956, 1483, 2244) (0.6446, 0.4260, 0.5130)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.108000, 0.098218, 0.102031)
Item accuracy: 15020 / 17262 (0.8701)
Instance accuracy: 548 / 1316 (0.4164)

***** Iteration #361 *****
Loss: 29805.531204
Feature norm: 79.356334
Error norm: 147.848718
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12949, 12101) (0.8990, 0.9620, 0.9294)
    repeat: (1113, 1325, 1447) (0.8400, 0.7692, 0.8030)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (949, 1468, 2244) (0.6465, 0.4229, 0.5113)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.108008, 0.098150, 0.101972)
Item accuracy: 15021 / 17262 (0.8702)
Instance accuracy: 548 / 1316 (0.4164)

***** Iteration #362 *****
Loss: 29802.880029
Feature norm: 79.389088
Error norm: 165.522992
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12950, 12101) (0.8989, 0.9620, 0.9294)
    repeat: (1112, 1324, 1447) (0.8399, 0.7685, 0.8026)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (947, 1468, 2244) (0.6451, 0.4220, 0.5102)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107964, 0.098106, 0.101929)
Item accuracy: 15018 / 17262 (0.8700)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #363 *****
Loss: 29800.600381
Feature norm: 79.418357
Error norm: 165.186924
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12961, 12101) (0.8978, 0.9617, 0.9287)
    repeat: (1111, 1321, 1447) (0.8410, 0.7678, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1460, 2244) (0.6425, 0.4180, 0.5065)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107894, 0.097966, 0.101809)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #364 *****
Loss: 29797.715418
Feature norm: 79.470583
Error norm: 252.568872
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11650, 12977, 12101) (0.8977, 0.9627, 0.9291)
    repeat: (1115, 1329, 1447) (0.8390, 0.7706, 0.8033)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (928, 1436, 2244) (0.6462, 0.4135, 0.5043)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123891, 0.111838, 0.116356)
Item accuracy: 15013 / 17262 (0.8697)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #365 *****
Loss: 29795.688073
Feature norm: 79.508047
Error norm: 246.983649
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11651, 12975, 12101) (0.8980, 0.9628, 0.9293)
    repeat: (1114, 1328, 1447) (0.8389, 0.7699, 0.8029)
    filler: (1306, 1501, 1423) (0.8701, 0.9178, 0.8933)
    false_start: (928, 1437, 2244) (0.6458, 0.4135, 0.5042)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123849, 0.111821, 0.116327)
Item accuracy: 15013 / 17262 (0.8697)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #366 *****
Loss: 29795.020616
Feature norm: 79.506583
Error norm: 327.577329
Active features: 158563
Line search trials: 2
Line search step: 0.501698
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12953, 12101) (0.8981, 0.9613, 0.9286)
    repeat: (1112, 1323, 1447) (0.8405, 0.7685, 0.8029)
    filler: (1306, 1501, 1423) (0.8701, 0.9178, 0.8933)
    false_start: (934, 1464, 2244) (0.6380, 0.4162, 0.5038)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123682, 0.111815, 0.116298)
Item accuracy: 14999 / 17262 (0.8689)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #367 *****
Loss: 29794.114374
Feature norm: 79.493328
Error norm: 176.205326
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12961, 12101) (0.8981, 0.9619, 0.9289)
    repeat: (1112, 1323, 1447) (0.8405, 0.7685, 0.8029)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (935, 1458, 2244) (0.6413, 0.4167, 0.5051)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123806, 0.111844, 0.116360)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #368 *****
Loss: 29793.434945
Feature norm: 79.492643
Error norm: 122.992569
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12958, 12101) (0.8982, 0.9618, 0.9289)
    repeat: (1113, 1324, 1447) (0.8406, 0.7692, 0.8033)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (935, 1460, 2244) (0.6404, 0.4167, 0.5049)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123788, 0.111861, 0.116365)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #369 *****
Loss: 29791.976004
Feature norm: 79.507908
Error norm: 178.306886
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12949, 12101) (0.8990, 0.9620, 0.9294)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (944, 1467, 2244) (0.6435, 0.4207, 0.5088)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123839, 0.111957, 0.116451)
Item accuracy: 15017 / 17262 (0.8699)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #370 *****
Loss: 29790.580233
Feature norm: 79.529398
Error norm: 188.215749
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11643, 12951, 12101) (0.8990, 0.9622, 0.9295)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (944, 1465, 2244) (0.6444, 0.4207, 0.5090)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123864, 0.111962, 0.116461)
Item accuracy: 15019 / 17262 (0.8701)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #371 *****
Loss: 29789.127148
Feature norm: 79.579152
Error norm: 374.241351
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11644, 12954, 12101) (0.8989, 0.9622, 0.9295)
    repeat: (1112, 1328, 1447) (0.8373, 0.7685, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (939, 1460, 2244) (0.6432, 0.4184, 0.5070)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123792, 0.111902, 0.116388)
Item accuracy: 15015 / 17262 (0.8698)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #372 *****
Loss: 29787.315774
Feature norm: 79.592511
Error norm: 176.520664
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11644, 12954, 12101) (0.8989, 0.9622, 0.9295)
    repeat: (1112, 1330, 1447) (0.8361, 0.7685, 0.8009)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (937, 1458, 2244) (0.6427, 0.4176, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123743, 0.111878, 0.116350)
Item accuracy: 15013 / 17262 (0.8697)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #373 *****
Loss: 29785.687095
Feature norm: 79.608784
Error norm: 171.756138
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12944, 12101) (0.8991, 0.9617, 0.9294)
    repeat: (1113, 1333, 1447) (0.8350, 0.7692, 0.8007)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1465, 2244) (0.6403, 0.4180, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123652, 0.111895, 0.116331)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #374 *****
Loss: 29785.049099
Feature norm: 79.616370
Error norm: 145.432001
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12953, 12101) (0.8986, 0.9618, 0.9291)
    repeat: (1113, 1332, 1447) (0.8356, 0.7692, 0.8010)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (930, 1457, 2244) (0.6383, 0.4144, 0.5026)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123599, 0.111799, 0.116243)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #375 *****
Loss: 29784.548176
Feature norm: 79.641065
Error norm: 463.704242
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12954, 12101) (0.8986, 0.9620, 0.9292)
    repeat: (1112, 1331, 1447) (0.8355, 0.7685, 0.8006)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (937, 1458, 2244) (0.6427, 0.4176, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123717, 0.111851, 0.116325)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #376 *****
Loss: 29783.493594
Feature norm: 79.639796
Error norm: 123.114370
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12960, 12101) (0.8982, 0.9620, 0.9290)
    repeat: (1113, 1332, 1447) (0.8356, 0.7692, 0.8010)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (930, 1451, 2244) (0.6409, 0.4144, 0.5034)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123661, 0.111784, 0.116252)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #377 *****
Loss: 29783.041966
Feature norm: 79.640248
Error norm: 160.542393
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12959, 12101) (0.8983, 0.9620, 0.9291)
    repeat: (1113, 1332, 1447) (0.8356, 0.7692, 0.8010)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (931, 1452, 2244) (0.6412, 0.4149, 0.5038)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123670, 0.111796, 0.116264)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #378 *****
Loss: 29782.625787
Feature norm: 79.644723
Error norm: 159.536066
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11642, 12954, 12101) (0.8987, 0.9621, 0.9293)
    repeat: (1113, 1333, 1447) (0.8350, 0.7692, 0.8007)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (936, 1456, 2244) (0.6429, 0.4171, 0.5059)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107758, 0.097972, 0.101746)
Item accuracy: 15008 / 17262 (0.8694)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #379 *****
Loss: 29781.026084
Feature norm: 79.660965
Error norm: 192.714238
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11645, 12961, 12101) (0.8985, 0.9623, 0.9293)
    repeat: (1113, 1333, 1447) (0.8350, 0.7692, 0.8007)
    filler: (1305, 1502, 1423) (0.8688, 0.9171, 0.8923)
    false_start: (932, 1445, 2244) (0.6450, 0.4153, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107745, 0.097929, 0.101693)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #380 *****
Loss: 29778.942202
Feature norm: 79.704210
Error norm: 289.729297
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11630, 12936, 12101) (0.8990, 0.9611, 0.9290)
    repeat: (1116, 1341, 1447) (0.8322, 0.7713, 0.8006)
    filler: (1305, 1502, 1423) (0.8688, 0.9171, 0.8923)
    false_start: (934, 1462, 2244) (0.6389, 0.4162, 0.5040)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107515, 0.097977, 0.101647)
Item accuracy: 14997 / 17262 (0.8688)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #381 *****
Loss: 29778.027778
Feature norm: 79.732533
Error norm: 152.964130
Active features: 158563
Line search trials: 2
Line search step: 0.508490
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12942, 12101) (0.8987, 0.9612, 0.9289)
    repeat: (1115, 1340, 1447) (0.8321, 0.7706, 0.8001)
    filler: (1305, 1502, 1423) (0.8688, 0.9171, 0.8923)
    false_start: (930, 1457, 2244) (0.6383, 0.4144, 0.5026)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107486, 0.097910, 0.101590)
Item accuracy: 14993 / 17262 (0.8686)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #382 *****
Loss: 29777.528188
Feature norm: 79.732276
Error norm: 96.965351
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12944, 12101) (0.8986, 0.9612, 0.9289)
    repeat: (1115, 1340, 1447) (0.8321, 0.7706, 0.8001)
    filler: (1305, 1502, 1423) (0.8688, 0.9171, 0.8923)
    false_start: (929, 1455, 2244) (0.6385, 0.4140, 0.5023)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107490, 0.097900, 0.101583)
Item accuracy: 14993 / 17262 (0.8686)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #383 *****
Loss: 29776.860547
Feature norm: 79.734916
Error norm: 103.599605
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12942, 12101) (0.8989, 0.9613, 0.9290)
    repeat: (1114, 1339, 1447) (0.8320, 0.7699, 0.7997)
    filler: (1305, 1502, 1423) (0.8688, 0.9171, 0.8923)
    false_start: (932, 1458, 2244) (0.6392, 0.4153, 0.5035)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107513, 0.097921, 0.101609)
Item accuracy: 14996 / 17262 (0.8687)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #384 *****
Loss: 29776.593547
Feature norm: 79.737617
Error norm: 300.560163
Active features: 158563
Line search trials: 2
Line search step: 0.267210
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12943, 12101) (0.8989, 0.9615, 0.9292)
    repeat: (1114, 1337, 1447) (0.8332, 0.7699, 0.8003)
    filler: (1305, 1502, 1423) (0.8688, 0.9171, 0.8923)
    false_start: (933, 1459, 2244) (0.6395, 0.4158, 0.5039)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107557, 0.097937, 0.101639)
Item accuracy: 14999 / 17262 (0.8689)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #385 *****
Loss: 29775.945543
Feature norm: 79.741572
Error norm: 255.919812
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12942, 12101) (0.8992, 0.9617, 0.9294)
    repeat: (1114, 1335, 1447) (0.8345, 0.7699, 0.8009)
    filler: (1306, 1503, 1423) (0.8689, 0.9178, 0.8927)
    false_start: (939, 1461, 2244) (0.6427, 0.4184, 0.5069)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107690, 0.098036, 0.101754)
Item accuracy: 15008 / 17262 (0.8694)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #386 *****
Loss: 29774.098201
Feature norm: 79.757693
Error norm: 154.174818
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12942, 12101) (0.8991, 0.9616, 0.9293)
    repeat: (1113, 1333, 1447) (0.8350, 0.7692, 0.8007)
    filler: (1306, 1503, 1423) (0.8689, 0.9178, 0.8927)
    false_start: (939, 1463, 2244) (0.6418, 0.4184, 0.5066)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107677, 0.098014, 0.101740)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #387 *****
Loss: 29772.480040
Feature norm: 79.784889
Error norm: 129.250943
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12939, 12101) (0.8990, 0.9612, 0.9291)
    repeat: (1113, 1331, 1447) (0.8362, 0.7692, 0.8013)
    filler: (1306, 1503, 1423) (0.8689, 0.9178, 0.8927)
    false_start: (941, 1468, 2244) (0.6410, 0.4193, 0.5070)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107687, 0.098030, 0.101761)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #388 *****
Loss: 29771.069070
Feature norm: 79.809900
Error norm: 118.018471
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12945, 12101) (0.8990, 0.9617, 0.9293)
    repeat: (1116, 1329, 1447) (0.8397, 0.7713, 0.8040)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (945, 1468, 2244) (0.6437, 0.4211, 0.5092)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107923, 0.098149, 0.101936)
Item accuracy: 15016 / 17262 (0.8699)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #389 *****
Loss: 29769.786710
Feature norm: 79.839126
Error norm: 224.807776
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11625, 12917, 12101) (0.9000, 0.9607, 0.9293)
    repeat: (1117, 1336, 1447) (0.8361, 0.7719, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (949, 1489, 2244) (0.6373, 0.4229, 0.5084)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107673, 0.098190, 0.101882)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #390 *****
Loss: 29768.733934
Feature norm: 79.862752
Error norm: 134.080418
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11630, 12936, 12101) (0.8990, 0.9611, 0.9290)
    repeat: (1113, 1327, 1447) (0.8387, 0.7692, 0.8025)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (948, 1479, 2244) (0.6410, 0.4225, 0.5093)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107822, 0.098112, 0.101888)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #391 *****
Loss: 29768.039957
Feature norm: 79.862433
Error norm: 194.780603
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11630, 12926, 12101) (0.8997, 0.9611, 0.9294)
    repeat: (1113, 1327, 1447) (0.8387, 0.7692, 0.8025)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (956, 1489, 2244) (0.6420, 0.4260, 0.5122)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107871, 0.098211, 0.101980)
Item accuracy: 15017 / 17262 (0.8699)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #392 *****
Loss: 29766.974978
Feature norm: 79.862617
Error norm: 149.349691
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11625, 12917, 12101) (0.9000, 0.9607, 0.9293)
    repeat: (1114, 1333, 1447) (0.8357, 0.7699, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (952, 1492, 2244) (0.6381, 0.4242, 0.5096)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107683, 0.098169, 0.101879)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #393 *****
Loss: 29765.919520
Feature norm: 79.885234
Error norm: 285.382052
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11624, 12915, 12101) (0.9000, 0.9606, 0.9293)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (955, 1496, 2244) (0.6384, 0.4256, 0.5107)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107728, 0.098204, 0.101924)
Item accuracy: 15011 / 17262 (0.8696)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #394 *****
Loss: 29764.756988
Feature norm: 79.927829
Error norm: 128.465580
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12927, 12101) (0.8996, 0.9610, 0.9293)
    repeat: (1113, 1327, 1447) (0.8387, 0.7692, 0.8025)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (954, 1488, 2244) (0.6411, 0.4251, 0.5113)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107841, 0.098184, 0.101951)
Item accuracy: 15014 / 17262 (0.8698)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #395 *****
Loss: 29764.408804
Feature norm: 79.936014
Error norm: 110.956785
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12931, 12101) (0.8992, 0.9609, 0.9291)
    repeat: (1113, 1327, 1447) (0.8387, 0.7692, 0.8025)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (952, 1484, 2244) (0.6415, 0.4242, 0.5107)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107842, 0.098157, 0.101930)
Item accuracy: 15011 / 17262 (0.8696)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #396 *****
Loss: 29763.587344
Feature norm: 79.958180
Error norm: 120.728019
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12940, 12101) (0.8992, 0.9616, 0.9294)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (948, 1472, 2244) (0.6440, 0.4225, 0.5102)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107880, 0.098145, 0.101920)
Item accuracy: 15016 / 17262 (0.8699)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #397 *****
Loss: 29762.909418
Feature norm: 79.971378
Error norm: 131.503587
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12941, 12101) (0.8992, 0.9616, 0.9293)
    repeat: (1113, 1329, 1447) (0.8375, 0.7692, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (948, 1472, 2244) (0.6440, 0.4225, 0.5102)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107874, 0.098126, 0.101907)
Item accuracy: 15015 / 17262 (0.8698)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #398 *****
Loss: 29762.197130
Feature norm: 80.026018
Error norm: 475.665723
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12932, 12101) (0.8994, 0.9612, 0.9293)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (948, 1477, 2244) (0.6418, 0.4225, 0.5095)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107792, 0.098153, 0.101894)
Item accuracy: 15012 / 17262 (0.8697)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #399 *****
Loss: 29760.899444
Feature norm: 80.017025
Error norm: 152.603562
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11642, 12965, 12101) (0.8980, 0.9621, 0.9289)
    repeat: (1114, 1332, 1447) (0.8363, 0.7699, 0.8017)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (929, 1445, 2244) (0.6429, 0.4140, 0.5037)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107778, 0.097924, 0.101709)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #400 *****
Loss: 29760.112066
Feature norm: 80.015431
Error norm: 155.867302
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12968, 12101) (0.8977, 0.9620, 0.9287)
    repeat: (1113, 1329, 1447) (0.8375, 0.7692, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (929, 1445, 2244) (0.6429, 0.4140, 0.5037)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107802, 0.097902, 0.101708)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #401 *****
Loss: 29759.525993
Feature norm: 80.022410
Error norm: 140.661927
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12968, 12101) (0.8977, 0.9620, 0.9287)
    repeat: (1113, 1329, 1447) (0.8375, 0.7692, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (929, 1445, 2244) (0.6429, 0.4140, 0.5037)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107802, 0.097902, 0.101708)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 542 / 1316 (0.4119)

***** Iteration #402 *****
Loss: 29759.059208
Feature norm: 80.072080
Error norm: 449.118511
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11643, 12967, 12101) (0.8979, 0.9622, 0.9289)
    repeat: (1116, 1335, 1447) (0.8360, 0.7713, 0.8023)
    filler: (1306, 1503, 1423) (0.8689, 0.9178, 0.8927)
    false_start: (929, 1436, 2244) (0.6469, 0.4140, 0.5049)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107814, 0.097964, 0.101726)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #403 *****
Loss: 29758.024759
Feature norm: 80.068334
Error norm: 120.897057
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12956, 12101) (0.8984, 0.9619, 0.9291)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (934, 1453, 2244) (0.6428, 0.4162, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107792, 0.098000, 0.101771)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #404 *****
Loss: 29757.740613
Feature norm: 80.073850
Error norm: 98.278259
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12956, 12101) (0.8984, 0.9619, 0.9291)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (934, 1453, 2244) (0.6428, 0.4162, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107792, 0.098000, 0.101771)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #405 *****
Loss: 29757.379021
Feature norm: 80.088030
Error norm: 139.978385
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12954, 12101) (0.8985, 0.9618, 0.9291)
    repeat: (1116, 1335, 1447) (0.8360, 0.7713, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (934, 1453, 2244) (0.6428, 0.4162, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107780, 0.098017, 0.101775)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #406 *****
Loss: 29756.692331
Feature norm: 80.109053
Error norm: 145.700190
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12954, 12101) (0.8985, 0.9618, 0.9291)
    repeat: (1116, 1335, 1447) (0.8360, 0.7713, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (934, 1453, 2244) (0.6428, 0.4162, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107780, 0.098017, 0.101775)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #407 *****
Loss: 29756.291945
Feature norm: 80.137500
Error norm: 335.940129
Active features: 158563
Line search trials: 2
Line search step: 0.186875
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12931, 12101) (0.9000, 0.9617, 0.9298)
    repeat: (1116, 1335, 1447) (0.8360, 0.7713, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (946, 1476, 2244) (0.6409, 0.4216, 0.5086)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107770, 0.098163, 0.101889)
Item accuracy: 15018 / 17262 (0.8700)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #408 *****
Loss: 29755.318926
Feature norm: 80.162220
Error norm: 213.635002
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11642, 12941, 12101) (0.8996, 0.9621, 0.9298)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (946, 1471, 2244) (0.6431, 0.4216, 0.5093)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107865, 0.098134, 0.101906)
Item accuracy: 15020 / 17262 (0.8701)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #409 *****
Loss: 29754.216592
Feature norm: 80.192830
Error norm: 119.774217
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11644, 12954, 12101) (0.8989, 0.9622, 0.9295)
    repeat: (1114, 1329, 1447) (0.8382, 0.7699, 0.8026)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (943, 1459, 2244) (0.6463, 0.4202, 0.5093)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107952, 0.098101, 0.101906)
Item accuracy: 15019 / 17262 (0.8701)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #410 *****
Loss: 29753.471073
Feature norm: 80.211825
Error norm: 140.913765
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11646, 12956, 12101) (0.8989, 0.9624, 0.9296)
    repeat: (1114, 1327, 1447) (0.8395, 0.7699, 0.8032)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (943, 1459, 2244) (0.6463, 0.4202, 0.5093)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107987, 0.098106, 0.101925)
Item accuracy: 15021 / 17262 (0.8702)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #411 *****
Loss: 29752.991905
Feature norm: 80.234416
Error norm: 322.999794
Active features: 158563
Line search trials: 2
Line search step: 0.503954
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11643, 12963, 12101) (0.8982, 0.9622, 0.9291)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (932, 1446, 2244) (0.6445, 0.4153, 0.5051)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107833, 0.097982, 0.101767)
Item accuracy: 15008 / 17262 (0.8694)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #412 *****
Loss: 29752.242649
Feature norm: 80.247655
Error norm: 177.546612
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11645, 12959, 12101) (0.8986, 0.9623, 0.9294)
    repeat: (1117, 1333, 1447) (0.8380, 0.7719, 0.8036)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (935, 1450, 2244) (0.6448, 0.4167, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107895, 0.098062, 0.101845)
Item accuracy: 15015 / 17262 (0.8698)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #413 *****
Loss: 29751.597257
Feature norm: 80.254225
Error norm: 116.515325
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12954, 12101) (0.8986, 0.9620, 0.9292)
    repeat: (1117, 1335, 1447) (0.8367, 0.7719, 0.8030)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (933, 1453, 2244) (0.6421, 0.4158, 0.5047)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107786, 0.098028, 0.101784)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #414 *****
Loss: 29750.842232
Feature norm: 80.264568
Error norm: 200.641279
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12952, 12101) (0.8987, 0.9619, 0.9292)
    repeat: (1116, 1335, 1447) (0.8360, 0.7713, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (933, 1455, 2244) (0.6412, 0.4158, 0.5045)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107742, 0.098007, 0.101756)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #415 *****
Loss: 29749.990434
Feature norm: 80.278056
Error norm: 182.648296
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12958, 12101) (0.8984, 0.9620, 0.9291)
    repeat: (1114, 1329, 1447) (0.8382, 0.7699, 0.8026)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (933, 1455, 2244) (0.6412, 0.4158, 0.5045)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107796, 0.097971, 0.101761)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #416 *****
Loss: 29749.709467
Feature norm: 80.291333
Error norm: 349.888536
Active features: 158563
Line search trials: 2
Line search step: 0.164297
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12933, 12101) (0.8999, 0.9617, 0.9298)
    repeat: (1116, 1337, 1447) (0.8347, 0.7713, 0.8017)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (950, 1472, 2244) (0.6454, 0.4234, 0.5113)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107855, 0.098213, 0.101946)
Item accuracy: 15022 / 17262 (0.8702)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #417 *****
Loss: 29748.922064
Feature norm: 80.307220
Error norm: 194.500164
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12962, 12101) (0.8980, 0.9619, 0.9289)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (930, 1449, 2244) (0.6418, 0.4144, 0.5037)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107788, 0.097951, 0.101736)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #418 *****
Loss: 29748.255365
Feature norm: 80.326788
Error norm: 136.470808
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12965, 12101) (0.8979, 0.9620, 0.9288)
    repeat: (1113, 1328, 1447) (0.8381, 0.7692, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (930, 1449, 2244) (0.6418, 0.4144, 0.5037)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107795, 0.097914, 0.101719)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #419 *****
Loss: 29747.478493
Feature norm: 80.354451
Error norm: 206.435414
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12969, 12101) (0.8976, 0.9620, 0.9287)
    repeat: (1113, 1328, 1447) (0.8381, 0.7692, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (928, 1445, 2244) (0.6422, 0.4135, 0.5031)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107798, 0.097890, 0.101700)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #420 *****
Loss: 29746.477398
Feature norm: 80.393268
Error norm: 234.822475
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11643, 12972, 12101) (0.8975, 0.9622, 0.9287)
    repeat: (1114, 1329, 1447) (0.8382, 0.7699, 0.8026)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (926, 1441, 2244) (0.6426, 0.4127, 0.5026)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107811, 0.097889, 0.101698)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #421 *****
Loss: 29745.698831
Feature norm: 80.457703
Error norm: 302.535389
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12955, 12101) (0.8978, 0.9612, 0.9284)
    repeat: (1112, 1325, 1447) (0.8392, 0.7685, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (933, 1462, 2244) (0.6382, 0.4158, 0.5035)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107723, 0.097909, 0.101707)
Item accuracy: 14994 / 17262 (0.8686)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #422 *****
Loss: 29744.553924
Feature norm: 80.486802
Error norm: 120.904674
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12968, 12101) (0.8977, 0.9620, 0.9287)
    repeat: (1113, 1330, 1447) (0.8368, 0.7692, 0.8016)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (925, 1444, 2244) (0.6406, 0.4122, 0.5016)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107720, 0.097853, 0.101644)
Item accuracy: 14997 / 17262 (0.8688)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #423 *****
Loss: 29744.048004
Feature norm: 80.487387
Error norm: 100.300361
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12967, 12101) (0.8977, 0.9620, 0.9288)
    repeat: (1114, 1333, 1447) (0.8357, 0.7699, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (925, 1442, 2244) (0.6415, 0.4122, 0.5019)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107715, 0.097872, 0.101648)
Item accuracy: 14998 / 17262 (0.8688)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #424 *****
Loss: 29743.156477
Feature norm: 80.508239
Error norm: 177.199096
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12963, 12101) (0.8978, 0.9617, 0.9287)
    repeat: (1114, 1333, 1447) (0.8357, 0.7699, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (926, 1446, 2244) (0.6404, 0.4127, 0.5019)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107686, 0.097877, 0.101646)
Item accuracy: 14996 / 17262 (0.8687)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #425 *****
Loss: 29742.799433
Feature norm: 80.520720
Error norm: 189.088333
Active features: 158563
Line search trials: 2
Line search step: 0.291354
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12933, 12101) (0.8991, 0.9609, 0.9290)
    repeat: (1116, 1336, 1447) (0.8353, 0.7713, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1473, 2244) (0.6368, 0.4180, 0.5047)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107612, 0.098041, 0.101748)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #426 *****
Loss: 29742.485220
Feature norm: 80.533005
Error norm: 135.368214
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12933, 12101) (0.8991, 0.9609, 0.9290)
    repeat: (1116, 1336, 1447) (0.8353, 0.7713, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1473, 2244) (0.6368, 0.4180, 0.5047)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107612, 0.098041, 0.101748)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #427 *****
Loss: 29741.947361
Feature norm: 80.563074
Error norm: 103.510856
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12935, 12101) (0.8990, 0.9609, 0.9289)
    repeat: (1114, 1334, 1447) (0.8351, 0.7699, 0.8012)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1473, 2244) (0.6368, 0.4180, 0.5047)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107602, 0.098003, 0.101722)
Item accuracy: 14998 / 17262 (0.8688)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #428 *****
Loss: 29741.482689
Feature norm: 80.590637
Error norm: 127.620209
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11630, 12943, 12101) (0.8986, 0.9611, 0.9288)
    repeat: (1112, 1332, 1447) (0.8348, 0.7685, 0.8003)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1467, 2244) (0.6380, 0.4171, 0.5044)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107618, 0.097944, 0.101687)
Item accuracy: 14996 / 17262 (0.8687)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #429 *****
Loss: 29740.496925
Feature norm: 80.655708
Error norm: 273.760055
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12947, 12101) (0.8985, 0.9613, 0.9289)
    repeat: (1114, 1334, 1447) (0.8351, 0.7699, 0.8012)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (933, 1461, 2244) (0.6386, 0.4158, 0.5036)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107639, 0.097952, 0.101691)
Item accuracy: 14998 / 17262 (0.8688)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #430 *****
Loss: 29739.769505
Feature norm: 80.733079
Error norm: 153.447436
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12947, 12101) (0.8987, 0.9615, 0.9290)
    repeat: (1113, 1333, 1447) (0.8350, 0.7692, 0.8007)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1462, 2244) (0.6402, 0.4171, 0.5051)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107685, 0.097975, 0.101725)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #431 *****
Loss: 29739.165302
Feature norm: 80.729184
Error norm: 101.953083
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12946, 12101) (0.8987, 0.9615, 0.9291)
    repeat: (1114, 1334, 1447) (0.8351, 0.7699, 0.8012)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1462, 2244) (0.6402, 0.4171, 0.5051)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107691, 0.097994, 0.101738)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #432 *****
Loss: 29738.514531
Feature norm: 80.728464
Error norm: 130.536407
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12942, 12101) (0.8989, 0.9614, 0.9291)
    repeat: (1114, 1334, 1447) (0.8351, 0.7699, 0.8012)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (939, 1466, 2244) (0.6405, 0.4184, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107704, 0.098029, 0.101770)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #433 *****
Loss: 29738.106105
Feature norm: 80.740221
Error norm: 293.993912
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12946, 12101) (0.8987, 0.9614, 0.9290)
    repeat: (1114, 1334, 1447) (0.8351, 0.7699, 0.8012)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (935, 1462, 2244) (0.6395, 0.4167, 0.5046)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107669, 0.097979, 0.101721)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #434 *****
Loss: 29737.527457
Feature norm: 80.750565
Error norm: 142.491645
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12936, 12101) (0.8994, 0.9614, 0.9293)
    repeat: (1115, 1335, 1447) (0.8352, 0.7706, 0.8016)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1471, 2244) (0.6377, 0.4180, 0.5050)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107640, 0.098036, 0.101754)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #435 *****
Loss: 29736.973841
Feature norm: 80.777029
Error norm: 140.175314
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12936, 12101) (0.8994, 0.9614, 0.9293)
    repeat: (1115, 1335, 1447) (0.8352, 0.7706, 0.8016)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1471, 2244) (0.6377, 0.4180, 0.5050)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107640, 0.098036, 0.101754)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #436 *****
Loss: 29736.575991
Feature norm: 80.799248
Error norm: 133.565321
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12939, 12101) (0.8991, 0.9614, 0.9292)
    repeat: (1114, 1332, 1447) (0.8363, 0.7699, 0.8017)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1471, 2244) (0.6377, 0.4180, 0.5050)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107666, 0.098017, 0.101755)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #437 *****
Loss: 29735.826348
Feature norm: 80.837316
Error norm: 166.816752
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12948, 12101) (0.8989, 0.9618, 0.9293)
    repeat: (1113, 1331, 1447) (0.8362, 0.7692, 0.8013)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1463, 2244) (0.6398, 0.4171, 0.5050)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107715, 0.097984, 0.101745)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #438 *****
Loss: 29735.384750
Feature norm: 80.864246
Error norm: 160.820010
Active features: 158563
Line search trials: 2
Line search step: 0.368735
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12948, 12101) (0.8990, 0.9619, 0.9294)
    repeat: (1114, 1332, 1447) (0.8363, 0.7699, 0.8017)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1462, 2244) (0.6402, 0.4171, 0.5051)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107732, 0.098006, 0.101763)
Item accuracy: 15008 / 17262 (0.8694)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #439 *****
Loss: 29734.719698
Feature norm: 80.893270
Error norm: 114.329952
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12950, 12101) (0.8985, 0.9616, 0.9290)
    repeat: (1114, 1332, 1447) (0.8363, 0.7699, 0.8017)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (933, 1460, 2244) (0.6390, 0.4158, 0.5038)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107687, 0.097959, 0.101715)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #440 *****
Loss: 29733.976873
Feature norm: 80.917263
Error norm: 122.753669
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12956, 12101) (0.8983, 0.9618, 0.9290)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (930, 1456, 2244) (0.6387, 0.4144, 0.5027)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107708, 0.097929, 0.101701)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #441 *****
Loss: 29733.680881
Feature norm: 80.958956
Error norm: 440.968613
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12976, 12101) (0.8971, 0.9620, 0.9284)
    repeat: (1113, 1329, 1447) (0.8375, 0.7692, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (919, 1437, 2244) (0.6395, 0.4095, 0.4993)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107693, 0.097778, 0.101579)
Item accuracy: 14991 / 17262 (0.8684)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #442 *****
Loss: 29732.930521
Feature norm: 80.964677
Error norm: 111.932516
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11641, 12953, 12101) (0.8987, 0.9620, 0.9293)
    repeat: (1113, 1329, 1447) (0.8375, 0.7692, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (933, 1460, 2244) (0.6390, 0.4158, 0.5038)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107724, 0.097952, 0.101727)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #443 *****
Loss: 29732.743438
Feature norm: 80.963335
Error norm: 90.313830
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12942, 12101) (0.8991, 0.9616, 0.9293)
    repeat: (1113, 1329, 1447) (0.8375, 0.7692, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1471, 2244) (0.6363, 0.4171, 0.5039)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107658, 0.097977, 0.101731)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #444 *****
Loss: 29732.255630
Feature norm: 80.988030
Error norm: 98.981176
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12936, 12101) (0.8992, 0.9612, 0.9292)
    repeat: (1115, 1332, 1447) (0.8371, 0.7706, 0.8024)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1474, 2244) (0.6350, 0.4171, 0.5035)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107614, 0.098006, 0.101732)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #445 *****
Loss: 29731.520529
Feature norm: 81.027677
Error norm: 119.582870
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12936, 12101) (0.8992, 0.9612, 0.9292)
    repeat: (1115, 1332, 1447) (0.8371, 0.7706, 0.8024)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1474, 2244) (0.6350, 0.4171, 0.5035)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107614, 0.098006, 0.101732)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #446 *****
Loss: 29730.572191
Feature norm: 81.124871
Error norm: 194.595651
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11623, 12927, 12101) (0.8991, 0.9605, 0.9288)
    repeat: (1116, 1335, 1447) (0.8360, 0.7713, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (937, 1480, 2244) (0.6331, 0.4176, 0.5032)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107528, 0.098017, 0.101710)
Item accuracy: 14994 / 17262 (0.8686)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #447 *****
Loss: 29730.162060
Feature norm: 81.178889
Error norm: 302.411925
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12958, 12101) (0.8982, 0.9618, 0.9289)
    repeat: (1115, 1334, 1447) (0.8358, 0.7706, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (931, 1450, 2244) (0.6421, 0.4149, 0.5041)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107748, 0.097961, 0.101725)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #448 *****
Loss: 29729.595840
Feature norm: 81.163946
Error norm: 87.847306
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12946, 12101) (0.8984, 0.9612, 0.9287)
    repeat: (1115, 1334, 1447) (0.8358, 0.7706, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (933, 1462, 2244) (0.6382, 0.4158, 0.5035)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107646, 0.097967, 0.101704)
Item accuracy: 14997 / 17262 (0.8688)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #449 *****
Loss: 29729.381140
Feature norm: 81.162061
Error norm: 75.766430
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12949, 12101) (0.8984, 0.9614, 0.9289)
    repeat: (1115, 1334, 1447) (0.8358, 0.7706, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (933, 1459, 2244) (0.6395, 0.4158, 0.5039)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107683, 0.097974, 0.101719)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #450 *****
Loss: 29729.086300
Feature norm: 81.185871
Error norm: 219.405310
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12939, 12101) (0.8989, 0.9612, 0.9290)
    repeat: (1115, 1334, 1447) (0.8358, 0.7706, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1469, 2244) (0.6372, 0.4171, 0.5042)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107632, 0.098004, 0.101730)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 543 / 1316 (0.4126)

***** Iteration #451 *****
Loss: 29728.669605
Feature norm: 81.207177
Error norm: 154.503795
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12948, 12101) (0.8986, 0.9615, 0.9290)
    repeat: (1115, 1334, 1447) (0.8358, 0.7706, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (933, 1460, 2244) (0.6390, 0.4158, 0.5038)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107675, 0.097976, 0.101719)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #452 *****
Loss: 29728.065457
Feature norm: 81.251345
Error norm: 113.557568
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12949, 12101) (0.8985, 0.9615, 0.9289)
    repeat: (1114, 1333, 1447) (0.8357, 0.7699, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (933, 1460, 2244) (0.6390, 0.4158, 0.5038)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107669, 0.097957, 0.101706)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #453 *****
Loss: 29727.531569
Feature norm: 81.295040
Error norm: 94.956526
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12947, 12101) (0.8987, 0.9615, 0.9290)
    repeat: (1114, 1333, 1447) (0.8357, 0.7699, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (935, 1462, 2244) (0.6395, 0.4167, 0.5046)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123640, 0.111871, 0.116308)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 544 / 1316 (0.4134)

***** Iteration #454 *****
Loss: 29726.997636
Feature norm: 81.334011
Error norm: 84.479315
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12945, 12101) (0.8988, 0.9615, 0.9291)
    repeat: (1114, 1333, 1447) (0.8357, 0.7699, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (937, 1464, 2244) (0.6400, 0.4176, 0.5054)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123657, 0.111895, 0.116333)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #455 *****
Loss: 29726.295201
Feature norm: 81.387580
Error norm: 203.735636
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12939, 12101) (0.8991, 0.9614, 0.9292)
    repeat: (1114, 1333, 1447) (0.8357, 0.7699, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1470, 2244) (0.6395, 0.4189, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123651, 0.111930, 0.116359)
Item accuracy: 15008 / 17262 (0.8694)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #456 *****
Loss: 29725.707221
Feature norm: 81.423046
Error norm: 136.586464
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12937, 12101) (0.8992, 0.9613, 0.9292)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (941, 1472, 2244) (0.6393, 0.4193, 0.5065)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123668, 0.111960, 0.116386)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #457 *****
Loss: 29725.341102
Feature norm: 81.406565
Error norm: 121.192225
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12941, 12101) (0.8992, 0.9616, 0.9293)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (941, 1468, 2244) (0.6410, 0.4193, 0.5070)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123715, 0.111966, 0.116404)
Item accuracy: 15012 / 17262 (0.8697)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #458 *****
Loss: 29725.019391
Feature norm: 81.391288
Error norm: 104.712437
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12936, 12101) (0.8992, 0.9612, 0.9292)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (941, 1473, 2244) (0.6388, 0.4193, 0.5063)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123656, 0.111957, 0.116381)
Item accuracy: 15008 / 17262 (0.8694)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #459 *****
Loss: 29724.775788
Feature norm: 81.401821
Error norm: 68.603869
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12941, 12101) (0.8991, 0.9615, 0.9292)
    repeat: (1114, 1332, 1447) (0.8363, 0.7699, 0.8017)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1469, 2244) (0.6399, 0.4189, 0.5063)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123679, 0.111933, 0.116371)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #460 *****
Loss: 29724.505470
Feature norm: 81.426130
Error norm: 76.403469
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12941, 12101) (0.8990, 0.9614, 0.9292)
    repeat: (1113, 1330, 1447) (0.8368, 0.7692, 0.8016)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1471, 2244) (0.6390, 0.4189, 0.5061)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123667, 0.111911, 0.116357)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 548 / 1316 (0.4164)

***** Iteration #461 *****
Loss: 29724.031111
Feature norm: 81.436944
Error norm: 66.718154
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12949, 12101) (0.8988, 0.9617, 0.9292)
    repeat: (1114, 1329, 1447) (0.8382, 0.7699, 0.8026)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (937, 1464, 2244) (0.6400, 0.4176, 0.5054)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123726, 0.111902, 0.116367)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #462 *****
Loss: 29723.617748
Feature norm: 81.452359
Error norm: 196.614790
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12947, 12101) (0.8987, 0.9615, 0.9290)
    repeat: (1111, 1326, 1447) (0.8379, 0.7678, 0.8013)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (939, 1469, 2244) (0.6392, 0.4184, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123691, 0.111863, 0.116338)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #463 *****
Loss: 29723.379738
Feature norm: 81.434818
Error norm: 238.362678
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12954, 12101) (0.8982, 0.9615, 0.9288)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (932, 1458, 2244) (0.6392, 0.4153, 0.5035)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123670, 0.111834, 0.116295)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #464 *****
Loss: 29723.139518
Feature norm: 81.430900
Error norm: 76.936284
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12944, 12101) (0.8989, 0.9615, 0.9291)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (939, 1468, 2244) (0.6396, 0.4184, 0.5059)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123701, 0.111920, 0.116372)
Item accuracy: 15008 / 17262 (0.8694)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #465 *****
Loss: 29723.065147
Feature norm: 81.429552
Error norm: 68.915818
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12941, 12101) (0.8988, 0.9612, 0.9290)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (939, 1471, 2244) (0.6383, 0.4184, 0.5055)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123664, 0.111913, 0.116357)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #466 *****
Loss: 29722.891056
Feature norm: 81.433167
Error norm: 91.321150
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12941, 12101) (0.8988, 0.9612, 0.9290)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (939, 1471, 2244) (0.6383, 0.4184, 0.5055)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123664, 0.111913, 0.116357)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #467 *****
Loss: 29722.663532
Feature norm: 81.446626
Error norm: 83.539183
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12939, 12101) (0.8989, 0.9612, 0.9290)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1473, 2244) (0.6382, 0.4189, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123661, 0.111923, 0.116365)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #468 *****
Loss: 29722.472768
Feature norm: 81.469470
Error norm: 178.967779
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 12932, 12101) (0.8991, 0.9608, 0.9289)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1479, 2244) (0.6356, 0.4189, 0.5050)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123597, 0.111933, 0.116352)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #469 *****
Loss: 29722.041489
Feature norm: 81.490464
Error norm: 97.063825
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12939, 12101) (0.8989, 0.9612, 0.9290)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1473, 2244) (0.6382, 0.4189, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123661, 0.111923, 0.116365)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #470 *****
Loss: 29721.602012
Feature norm: 81.522726
Error norm: 155.192678
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12945, 12101) (0.8985, 0.9612, 0.9288)
    repeat: (1113, 1326, 1447) (0.8394, 0.7692, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1471, 2244) (0.6377, 0.4180, 0.5050)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123685, 0.111879, 0.116348)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #471 *****
Loss: 29721.316691
Feature norm: 81.566639
Error norm: 89.939828
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 12941, 12101) (0.8985, 0.9608, 0.9286)
    repeat: (1111, 1324, 1447) (0.8391, 0.7678, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1477, 2244) (0.6351, 0.4180, 0.5042)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123605, 0.111832, 0.116297)
Item accuracy: 14996 / 17262 (0.8687)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #472 *****
Loss: 29721.189424
Feature norm: 81.586962
Error norm: 91.985407
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12949, 12101) (0.8983, 0.9612, 0.9287)
    repeat: (1111, 1324, 1447) (0.8391, 0.7678, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (937, 1469, 2244) (0.6378, 0.4176, 0.5047)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123678, 0.111831, 0.116315)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #473 *****
Loss: 29721.061856
Feature norm: 81.592102
Error norm: 57.217343
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 12935, 12101) (0.8989, 0.9608, 0.9288)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1477, 2244) (0.6351, 0.4180, 0.5042)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123574, 0.111889, 0.116315)
Item accuracy: 14999 / 17262 (0.8689)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #474 *****
Loss: 29720.852751
Feature norm: 81.605678
Error norm: 93.013565
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 12935, 12101) (0.8989, 0.9608, 0.9288)
    repeat: (1112, 1328, 1447) (0.8373, 0.7685, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1479, 2244) (0.6356, 0.4189, 0.5050)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123581, 0.111876, 0.116313)
Item accuracy: 14999 / 17262 (0.8689)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #475 *****
Loss: 29720.729635
Feature norm: 81.614461
Error norm: 81.597401
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12941, 12101) (0.8988, 0.9612, 0.9289)
    repeat: (1112, 1328, 1447) (0.8373, 0.7685, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1473, 2244) (0.6382, 0.4189, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123650, 0.111885, 0.116339)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #476 *****
Loss: 29720.425172
Feature norm: 81.630440
Error norm: 168.544190
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12941, 12101) (0.8988, 0.9612, 0.9289)
    repeat: (1112, 1328, 1447) (0.8373, 0.7685, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1473, 2244) (0.6382, 0.4189, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123650, 0.111885, 0.116339)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #477 *****
Loss: 29720.253278
Feature norm: 81.677657
Error norm: 165.512767
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12949, 12101) (0.8984, 0.9613, 0.9288)
    repeat: (1111, 1324, 1447) (0.8391, 0.7678, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1469, 2244) (0.6385, 0.4180, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123699, 0.111846, 0.116332)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #478 *****
Loss: 29720.079765
Feature norm: 81.664309
Error norm: 65.834133
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12947, 12101) (0.8985, 0.9613, 0.9289)
    repeat: (1111, 1324, 1447) (0.8391, 0.7678, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1471, 2244) (0.6390, 0.4189, 0.5061)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123716, 0.111870, 0.116357)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #479 *****
Loss: 29719.962632
Feature norm: 81.662616
Error norm: 55.416283
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12943, 12101) (0.8988, 0.9613, 0.9290)
    repeat: (1112, 1328, 1447) (0.8373, 0.7685, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1471, 2244) (0.6390, 0.4189, 0.5061)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123675, 0.111890, 0.116349)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #480 *****
Loss: 29719.824260
Feature norm: 81.670317
Error norm: 72.072715
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12939, 12101) (0.8989, 0.9612, 0.9290)
    repeat: (1114, 1332, 1447) (0.8363, 0.7699, 0.8017)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1471, 2244) (0.6390, 0.4189, 0.5061)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123650, 0.111923, 0.116356)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #481 *****
Loss: 29719.567191
Feature norm: 81.684395
Error norm: 83.842092
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12941, 12101) (0.8988, 0.9612, 0.9289)
    repeat: (1114, 1332, 1447) (0.8363, 0.7699, 0.8017)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1469, 2244) (0.6385, 0.4180, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123632, 0.111899, 0.116332)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #482 *****
Loss: 29719.177678
Feature norm: 81.692221
Error norm: 155.824945
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 12937, 12101) (0.8987, 0.9608, 0.9287)
    repeat: (1112, 1330, 1447) (0.8361, 0.7685, 0.8009)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1475, 2244) (0.6359, 0.4180, 0.5044)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123553, 0.111851, 0.116280)
Item accuracy: 14997 / 17262 (0.8688)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #483 *****
Loss: 29719.060403
Feature norm: 81.684025
Error norm: 70.261488
Active features: 158563
Line search trials: 2
Line search step: 0.354212
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12953, 12101) (0.8986, 0.9619, 0.9292)
    repeat: (1114, 1332, 1447) (0.8363, 0.7699, 0.8017)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1457, 2244) (0.6424, 0.4171, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123737, 0.111895, 0.116355)
Item accuracy: 15010 / 17262 (0.8695)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #484 *****
Loss: 29718.935191
Feature norm: 81.686975
Error norm: 48.505619
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12947, 12101) (0.8986, 0.9614, 0.9289)
    repeat: (1112, 1330, 1447) (0.8361, 0.7685, 0.8009)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1465, 2244) (0.6403, 0.4180, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123669, 0.111867, 0.116323)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #485 *****
Loss: 29718.824906
Feature norm: 81.694342
Error norm: 51.101939
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12949, 12101) (0.8986, 0.9616, 0.9290)
    repeat: (1112, 1328, 1447) (0.8373, 0.7685, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1465, 2244) (0.6403, 0.4180, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123704, 0.111872, 0.116342)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #486 *****
Loss: 29718.692276
Feature norm: 81.702420
Error norm: 70.690312
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12947, 12101) (0.8987, 0.9615, 0.9290)
    repeat: (1112, 1328, 1447) (0.8373, 0.7685, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (939, 1467, 2244) (0.6401, 0.4184, 0.5061)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123701, 0.111882, 0.116349)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #487 *****
Loss: 29718.545149
Feature norm: 81.724564
Error norm: 117.896075
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12951, 12101) (0.8985, 0.9616, 0.9289)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1466, 2244) (0.6405, 0.4184, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123740, 0.111865, 0.116357)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 548 / 1316 (0.4164)

***** Iteration #488 *****
Loss: 29718.395605
Feature norm: 81.733944
Error norm: 82.745694
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12952, 12101) (0.8984, 0.9616, 0.9289)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (938, 1465, 2244) (0.6403, 0.4180, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123731, 0.111852, 0.116344)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #489 *****
Loss: 29718.209606
Feature norm: 81.750220
Error norm: 41.182711
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11642, 12960, 12101) (0.8983, 0.9621, 0.9291)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (936, 1457, 2244) (0.6424, 0.4171, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123788, 0.111841, 0.116350)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #490 *****
Loss: 29718.135715
Feature norm: 81.755977
Error norm: 46.722091
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11643, 12962, 12101) (0.8982, 0.9622, 0.9291)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (935, 1455, 2244) (0.6426, 0.4167, 0.5055)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123792, 0.111831, 0.116342)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #491 *****
Loss: 29718.066567
Feature norm: 81.769850
Error norm: 104.419980
Active features: 158563
Line search trials: 2
Line search step: 0.302047
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11643, 12962, 12101) (0.8982, 0.9622, 0.9291)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (935, 1455, 2244) (0.6426, 0.4167, 0.5055)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123792, 0.111831, 0.116342)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #492 *****
Loss: 29717.941117
Feature norm: 81.776757
Error norm: 52.148844
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11643, 12962, 12101) (0.8982, 0.9622, 0.9291)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (935, 1455, 2244) (0.6426, 0.4167, 0.5055)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123792, 0.111831, 0.116342)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #493 *****
Loss: 29717.828524
Feature norm: 81.784244
Error norm: 46.954283
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11646, 12965, 12101) (0.8983, 0.9624, 0.9292)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (935, 1452, 2244) (0.6439, 0.4167, 0.5060)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 17, 26) (0.7059, 0.4615, 0.5581)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (2, 4, 4) (0.5000, 0.5000, 0.5000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.123829, 0.111838, 0.116357)
Item accuracy: 15012 / 17262 (0.8697)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #494 *****
Loss: 29717.654746
Feature norm: 81.799722
Error norm: 63.133033
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11646, 12963, 12101) (0.8984, 0.9624, 0.9293)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (936, 1454, 2244) (0.6437, 0.4171, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107875, 0.097961, 0.101789)
Item accuracy: 15011 / 17262 (0.8696)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #495 *****
Loss: 29717.357689
Feature norm: 81.833615
Error norm: 49.035077
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12952, 12101) (0.8985, 0.9617, 0.9291)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1465, 2244) (0.6410, 0.4184, 0.5063)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107802, 0.097980, 0.101786)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #496 *****
Loss: 29717.293197
Feature norm: 81.850334
Error norm: 133.324291
Active features: 158563
Line search trials: 2
Line search step: 0.109934
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12954, 12101) (0.8986, 0.9619, 0.9292)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1463, 2244) (0.6418, 0.4184, 0.5066)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107826, 0.097985, 0.101796)
Item accuracy: 15008 / 17262 (0.8694)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #497 *****
Loss: 29717.089981
Feature norm: 81.880339
Error norm: 69.057883
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12954, 12101) (0.8986, 0.9619, 0.9292)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1463, 2244) (0.6418, 0.4184, 0.5066)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107826, 0.097985, 0.101796)
Item accuracy: 15008 / 17262 (0.8694)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #498 *****
Loss: 29716.974495
Feature norm: 81.900938
Error norm: 53.048436
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12951, 12101) (0.8985, 0.9617, 0.9290)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1466, 2244) (0.6405, 0.4184, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107789, 0.097978, 0.101781)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #499 *****
Loss: 29716.888174
Feature norm: 81.917159
Error norm: 51.394584
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11637, 12951, 12101) (0.8985, 0.9617, 0.9290)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1466, 2244) (0.6405, 0.4184, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107789, 0.097978, 0.101781)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #500 *****
Loss: 29716.844476
Feature norm: 81.930299
Error norm: 134.022355
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12947, 12101) (0.8987, 0.9616, 0.9291)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (941, 1470, 2244) (0.6401, 0.4193, 0.5067)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107784, 0.098000, 0.101797)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #501 *****
Loss: 29716.766657
Feature norm: 81.928969
Error norm: 59.538162
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12953, 12101) (0.8986, 0.9618, 0.9291)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1464, 2244) (0.6414, 0.4184, 0.5065)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107814, 0.097983, 0.101791)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #502 *****
Loss: 29716.707203
Feature norm: 81.929216
Error norm: 39.345601
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11642, 12956, 12101) (0.8986, 0.9621, 0.9292)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1461, 2244) (0.6427, 0.4184, 0.5069)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107851, 0.097989, 0.101806)
Item accuracy: 15010 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #503 *****
Loss: 29716.678400
Feature norm: 81.934791
Error norm: 55.553289
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11642, 12956, 12101) (0.8986, 0.9621, 0.9292)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1461, 2244) (0.6427, 0.4184, 0.5069)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107851, 0.097989, 0.101806)
Item accuracy: 15010 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #504 *****
Loss: 29716.610196
Feature norm: 81.942393
Error norm: 56.392132
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12951, 12101) (0.8988, 0.9619, 0.9293)
    repeat: (1113, 1327, 1447) (0.8387, 0.7692, 0.8025)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1465, 2244) (0.6410, 0.4184, 0.5063)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107811, 0.098004, 0.101803)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #505 *****
Loss: 29716.549882
Feature norm: 81.956130
Error norm: 109.044093
Active features: 158563
Line search trials: 2
Line search step: 0.311702
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11642, 12956, 12101) (0.8986, 0.9621, 0.9292)
    repeat: (1112, 1326, 1447) (0.8386, 0.7685, 0.8020)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1461, 2244) (0.6427, 0.4184, 0.5069)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107851, 0.097989, 0.101806)
Item accuracy: 15010 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #506 *****
Loss: 29716.442225
Feature norm: 81.959314
Error norm: 74.492761
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11638, 12950, 12101) (0.8987, 0.9617, 0.9291)
    repeat: (1113, 1327, 1447) (0.8387, 0.7692, 0.8025)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (940, 1466, 2244) (0.6412, 0.4189, 0.5067)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107816, 0.098012, 0.101811)
Item accuracy: 15008 / 17262 (0.8694)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #507 *****
Loss: 29716.289594
Feature norm: 81.962419
Error norm: 39.552264
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12944, 12101) (0.8989, 0.9615, 0.9291)
    repeat: (1113, 1329, 1447) (0.8375, 0.7692, 0.8019)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (940, 1470, 2244) (0.6395, 0.4189, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107737, 0.098005, 0.101779)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #508 *****
Loss: 29716.219350
Feature norm: 81.962247
Error norm: 56.795280
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12944, 12101) (0.8989, 0.9615, 0.9291)
    repeat: (1113, 1329, 1447) (0.8375, 0.7692, 0.8019)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (940, 1470, 2244) (0.6395, 0.4189, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107737, 0.098005, 0.101779)
Item accuracy: 15005 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #509 *****
Loss: 29716.143653
Feature norm: 81.956855
Error norm: 86.832980
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.730
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12946, 12101) (0.8988, 0.9616, 0.9291)
    repeat: (1114, 1332, 1447) (0.8363, 0.7699, 0.8017)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1465, 2244) (0.6410, 0.4184, 0.5063)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107746, 0.098014, 0.101779)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #510 *****
Loss: 29716.055947
Feature norm: 81.955190
Error norm: 73.122235
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12942, 12101) (0.8989, 0.9613, 0.9290)
    repeat: (1114, 1332, 1447) (0.8363, 0.7699, 0.8017)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1469, 2244) (0.6392, 0.4184, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107698, 0.098007, 0.101762)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #511 *****
Loss: 29715.995529
Feature norm: 81.952271
Error norm: 51.093672
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12942, 12101) (0.8989, 0.9613, 0.9290)
    repeat: (1114, 1332, 1447) (0.8363, 0.7699, 0.8017)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1469, 2244) (0.6392, 0.4184, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107698, 0.098007, 0.101762)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #512 *****
Loss: 29715.863899
Feature norm: 81.943078
Error norm: 46.684163
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12948, 12101) (0.8987, 0.9616, 0.9291)
    repeat: (1112, 1330, 1447) (0.8361, 0.7685, 0.8009)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1465, 2244) (0.6410, 0.4184, 0.5063)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107735, 0.097976, 0.101753)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #513 *****
Loss: 29715.801075
Feature norm: 81.935798
Error norm: 39.109581
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12944, 12101) (0.8987, 0.9613, 0.9290)
    repeat: (1112, 1330, 1447) (0.8361, 0.7685, 0.8009)
    filler: (1305, 1498, 1423) (0.8712, 0.9171, 0.8935)
    false_start: (939, 1469, 2244) (0.6392, 0.4184, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107688, 0.097969, 0.101736)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #514 *****
Loss: 29715.751326
Feature norm: 81.931063
Error norm: 92.133460
Active features: 158563
Line search trials: 2
Line search step: 0.523178
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12947, 12101) (0.8987, 0.9615, 0.9290)
    repeat: (1112, 1328, 1447) (0.8373, 0.7685, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1467, 2244) (0.6394, 0.4180, 0.5055)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107729, 0.097981, 0.101756)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #515 *****
Loss: 29715.690296
Feature norm: 81.927986
Error norm: 42.917715
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12943, 12101) (0.8986, 0.9612, 0.9288)
    repeat: (1112, 1330, 1447) (0.8361, 0.7685, 0.8009)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1469, 2244) (0.6385, 0.4180, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107669, 0.097971, 0.101728)
Item accuracy: 14999 / 17262 (0.8689)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #516 *****
Loss: 29715.643087
Feature norm: 81.926937
Error norm: 38.446817
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12943, 12101) (0.8986, 0.9612, 0.9288)
    repeat: (1112, 1330, 1447) (0.8361, 0.7685, 0.8009)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1469, 2244) (0.6385, 0.4180, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107669, 0.097971, 0.101728)
Item accuracy: 14999 / 17262 (0.8689)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #517 *****
Loss: 29715.605544
Feature norm: 81.926314
Error norm: 45.539821
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12943, 12101) (0.8986, 0.9612, 0.9288)
    repeat: (1112, 1330, 1447) (0.8361, 0.7685, 0.8009)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1469, 2244) (0.6385, 0.4180, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107669, 0.097971, 0.101728)
Item accuracy: 14999 / 17262 (0.8689)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #518 *****
Loss: 29715.515101
Feature norm: 81.923213
Error norm: 116.956192
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12943, 12101) (0.8988, 0.9613, 0.9290)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1469, 2244) (0.6385, 0.4180, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107715, 0.098014, 0.101772)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #519 *****
Loss: 29715.435944
Feature norm: 81.917419
Error norm: 54.340415
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12946, 12101) (0.8988, 0.9616, 0.9291)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1466, 2244) (0.6398, 0.4180, 0.5057)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107752, 0.098021, 0.101787)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #520 *****
Loss: 29715.393021
Feature norm: 81.917094
Error norm: 37.666530
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12946, 12101) (0.8988, 0.9616, 0.9291)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1466, 2244) (0.6398, 0.4180, 0.5057)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107752, 0.098021, 0.101787)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #521 *****
Loss: 29715.342447
Feature norm: 81.914912
Error norm: 29.015212
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12946, 12101) (0.8988, 0.9616, 0.9291)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1466, 2244) (0.6398, 0.4180, 0.5057)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107752, 0.098021, 0.101787)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #522 *****
Loss: 29715.309980
Feature norm: 81.912309
Error norm: 32.617042
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12946, 12101) (0.8988, 0.9616, 0.9291)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1466, 2244) (0.6398, 0.4180, 0.5057)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107752, 0.098021, 0.101787)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #523 *****
Loss: 29715.268315
Feature norm: 81.910025
Error norm: 62.139423
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12952, 12101) (0.8986, 0.9618, 0.9292)
    repeat: (1112, 1328, 1447) (0.8373, 0.7685, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1462, 2244) (0.6416, 0.4180, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107789, 0.097990, 0.101779)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #524 *****
Loss: 29715.225870
Feature norm: 81.909410
Error norm: 37.703172
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12945, 12101) (0.8986, 0.9613, 0.9289)
    repeat: (1112, 1328, 1447) (0.8373, 0.7685, 0.8014)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1469, 2244) (0.6385, 0.4180, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107704, 0.097976, 0.101746)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #525 *****
Loss: 29715.169907
Feature norm: 81.910265
Error norm: 27.313769
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12944, 12101) (0.8987, 0.9613, 0.9290)
    repeat: (1113, 1329, 1447) (0.8375, 0.7692, 0.8019)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1469, 2244) (0.6385, 0.4180, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107710, 0.097995, 0.101759)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #526 *****
Loss: 29715.132840
Feature norm: 81.910840
Error norm: 30.399738
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12942, 12101) (0.8989, 0.9613, 0.9290)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1469, 2244) (0.6385, 0.4180, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107720, 0.098034, 0.101785)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #527 *****
Loss: 29715.046527
Feature norm: 81.912594
Error norm: 29.915277
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12946, 12101) (0.8988, 0.9616, 0.9291)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1465, 2244) (0.6403, 0.4180, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107767, 0.098040, 0.101803)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #528 *****
Loss: 29715.034673
Feature norm: 81.913290
Error norm: 56.211907
Active features: 158563
Line search trials: 2
Line search step: 0.122049
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12942, 12101) (0.8989, 0.9613, 0.9290)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1469, 2244) (0.6385, 0.4180, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107720, 0.098034, 0.101785)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #529 *****
Loss: 29714.995040
Feature norm: 81.914791
Error norm: 33.109826
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12944, 12101) (0.8987, 0.9613, 0.9290)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1467, 2244) (0.6380, 0.4171, 0.5044)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107703, 0.098009, 0.101761)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #530 *****
Loss: 29714.956517
Feature norm: 81.916327
Error norm: 27.649718
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12944, 12101) (0.8987, 0.9613, 0.9290)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1467, 2244) (0.6380, 0.4171, 0.5044)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107703, 0.098009, 0.101761)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #531 *****
Loss: 29714.898649
Feature norm: 81.919266
Error norm: 27.228999
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12944, 12101) (0.8987, 0.9613, 0.9290)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1467, 2244) (0.6380, 0.4171, 0.5044)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107703, 0.098009, 0.101761)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #532 *****
Loss: 29714.881978
Feature norm: 81.920563
Error norm: 66.716030
Active features: 158563
Line search trials: 2
Line search step: 0.145469
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12944, 12101) (0.8987, 0.9613, 0.9290)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1467, 2244) (0.6380, 0.4171, 0.5044)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107703, 0.098009, 0.101761)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #533 *****
Loss: 29714.846589
Feature norm: 81.922097
Error norm: 49.689201
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12944, 12101) (0.8987, 0.9613, 0.9290)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1467, 2244) (0.6380, 0.4171, 0.5044)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107703, 0.098009, 0.101761)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #534 *****
Loss: 29714.779094
Feature norm: 81.925482
Error norm: 30.092492
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12944, 12101) (0.8987, 0.9613, 0.9290)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (936, 1467, 2244) (0.6380, 0.4171, 0.5044)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107703, 0.098009, 0.101761)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #535 *****
Loss: 29714.716134
Feature norm: 81.929947
Error norm: 51.243640
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12942, 12101) (0.8989, 0.9613, 0.9290)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1469, 2244) (0.6385, 0.4180, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107720, 0.098034, 0.101785)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #536 *****
Loss: 29714.666997
Feature norm: 81.935041
Error norm: 57.076607
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12942, 12101) (0.8989, 0.9613, 0.9290)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1469, 2244) (0.6385, 0.4180, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107720, 0.098034, 0.101785)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #537 *****
Loss: 29714.614735
Feature norm: 81.937797
Error norm: 51.918267
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12942, 12101) (0.8989, 0.9613, 0.9290)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1469, 2244) (0.6385, 0.4180, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107720, 0.098034, 0.101785)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #538 *****
Loss: 29714.575781
Feature norm: 81.938277
Error norm: 37.350372
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12943, 12101) (0.8988, 0.9613, 0.9290)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1469, 2244) (0.6385, 0.4180, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107715, 0.098014, 0.101772)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #539 *****
Loss: 29714.516324
Feature norm: 81.940937
Error norm: 34.445031
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12943, 12101) (0.8988, 0.9613, 0.9290)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1469, 2244) (0.6385, 0.4180, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107715, 0.098014, 0.101772)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #540 *****
Loss: 29714.466674
Feature norm: 81.944518
Error norm: 33.975985
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12942, 12101) (0.8989, 0.9613, 0.9290)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (939, 1470, 2244) (0.6388, 0.4184, 0.5057)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107724, 0.098027, 0.101785)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #541 *****
Loss: 29714.431867
Feature norm: 81.949601
Error norm: 88.719318
Active features: 158563
Line search trials: 2
Line search step: 0.372287
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11636, 12946, 12101) (0.8988, 0.9616, 0.9291)
    repeat: (1114, 1330, 1447) (0.8376, 0.7699, 0.8023)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (939, 1466, 2244) (0.6405, 0.4184, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107771, 0.098034, 0.101802)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #542 *****
Loss: 29714.383170
Feature norm: 81.953377
Error norm: 54.958176
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12940, 12101) (0.8988, 0.9612, 0.9290)
    repeat: (1114, 1332, 1447) (0.8363, 0.7699, 0.8017)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (939, 1470, 2244) (0.6388, 0.4184, 0.5057)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107688, 0.098022, 0.101766)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #543 *****
Loss: 29714.329842
Feature norm: 81.959711
Error norm: 28.018301
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12940, 12101) (0.8988, 0.9612, 0.9290)
    repeat: (1114, 1332, 1447) (0.8363, 0.7699, 0.8017)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (939, 1470, 2244) (0.6388, 0.4184, 0.5057)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107688, 0.098022, 0.101766)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #544 *****
Loss: 29714.307401
Feature norm: 81.962040
Error norm: 30.278643
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12940, 12101) (0.8988, 0.9612, 0.9290)
    repeat: (1114, 1332, 1447) (0.8363, 0.7699, 0.8017)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (939, 1470, 2244) (0.6388, 0.4184, 0.5057)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107688, 0.098022, 0.101766)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #545 *****
Loss: 29714.223887
Feature norm: 81.970776
Error norm: 49.759152
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12940, 12101) (0.8988, 0.9612, 0.9290)
    repeat: (1114, 1332, 1447) (0.8363, 0.7699, 0.8017)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (939, 1470, 2244) (0.6388, 0.4184, 0.5057)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107688, 0.098022, 0.101766)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #546 *****
Loss: 29714.177438
Feature norm: 81.976897
Error norm: 58.958811
Active features: 158563
Line search trials: 2
Line search step: 0.499297
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12937, 12101) (0.8989, 0.9610, 0.9289)
    repeat: (1115, 1335, 1447) (0.8352, 0.7706, 0.8016)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (939, 1470, 2244) (0.6388, 0.4184, 0.5057)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107658, 0.098037, 0.101761)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #547 *****
Loss: 29714.102666
Feature norm: 81.983563
Error norm: 41.092342
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11626, 12934, 12101) (0.8989, 0.9607, 0.9288)
    repeat: (1115, 1335, 1447) (0.8352, 0.7706, 0.8016)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (939, 1473, 2244) (0.6375, 0.4184, 0.5052)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107622, 0.098030, 0.101746)
Item accuracy: 14998 / 17262 (0.8688)
Instance accuracy: 545 / 1316 (0.4141)

***** Iteration #548 *****
Loss: 29714.018144
Feature norm: 81.990262
Error norm: 34.960348
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12937, 12101) (0.8989, 0.9610, 0.9289)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (941, 1474, 2244) (0.6384, 0.4193, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107718, 0.098061, 0.101808)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #549 *****
Loss: 29713.997408
Feature norm: 81.996855
Error norm: 165.071482
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 12935, 12101) (0.8989, 0.9608, 0.9288)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (941, 1474, 2244) (0.6384, 0.4193, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107682, 0.098057, 0.101789)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #550 *****
Loss: 29713.895037
Feature norm: 81.997295
Error norm: 43.388640
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12941, 12101) (0.8988, 0.9612, 0.9290)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (941, 1470, 2244) (0.6401, 0.4193, 0.5067)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107765, 0.098068, 0.101825)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #551 *****
Loss: 29713.860677
Feature norm: 81.996561
Error norm: 45.106692
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12941, 12101) (0.8988, 0.9612, 0.9290)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (941, 1470, 2244) (0.6401, 0.4193, 0.5067)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107765, 0.098068, 0.101825)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #552 *****
Loss: 29713.794286
Feature norm: 81.997032
Error norm: 62.514763
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11632, 12941, 12101) (0.8988, 0.9612, 0.9290)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (941, 1470, 2244) (0.6401, 0.4193, 0.5067)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107765, 0.098068, 0.101825)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #553 *****
Loss: 29713.736282
Feature norm: 82.000258
Error norm: 38.974586
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 12936, 12101) (0.8988, 0.9608, 0.9288)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1473, 2244) (0.6382, 0.4189, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107674, 0.098045, 0.101777)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #554 *****
Loss: 29713.705131
Feature norm: 82.015447
Error norm: 54.578547
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 12937, 12101) (0.8987, 0.9608, 0.9287)
    repeat: (1116, 1334, 1447) (0.8366, 0.7713, 0.8026)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1471, 2244) (0.6377, 0.4180, 0.5050)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107661, 0.098039, 0.101766)
Item accuracy: 14999 / 17262 (0.8689)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #555 *****
Loss: 29713.613944
Feature norm: 82.017132
Error norm: 53.207180
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 12937, 12101) (0.8987, 0.9608, 0.9287)
    repeat: (1116, 1334, 1447) (0.8366, 0.7713, 0.8026)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1471, 2244) (0.6377, 0.4180, 0.5050)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107661, 0.098039, 0.101766)
Item accuracy: 14999 / 17262 (0.8689)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #556 *****
Loss: 29713.572576
Feature norm: 82.017244
Error norm: 38.755307
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11627, 12935, 12101) (0.8989, 0.9608, 0.9288)
    repeat: (1116, 1334, 1447) (0.8366, 0.7713, 0.8026)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1473, 2244) (0.6382, 0.4189, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107679, 0.098064, 0.101790)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #557 *****
Loss: 29713.485936
Feature norm: 82.023551
Error norm: 28.640597
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12938, 12101) (0.8988, 0.9610, 0.9289)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1471, 2244) (0.6390, 0.4189, 0.5061)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107698, 0.098049, 0.101787)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #558 *****
Loss: 29713.405629
Feature norm: 82.032796
Error norm: 28.678838
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12938, 12101) (0.8988, 0.9610, 0.9289)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1471, 2244) (0.6390, 0.4189, 0.5061)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107698, 0.098049, 0.101787)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #559 *****
Loss: 29713.331493
Feature norm: 82.051370
Error norm: 90.842176
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12946, 12101) (0.8984, 0.9612, 0.9287)
    repeat: (1115, 1331, 1447) (0.8377, 0.7706, 0.8027)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (937, 1465, 2244) (0.6396, 0.4176, 0.5053)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107738, 0.098017, 0.101777)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #560 *****
Loss: 29713.291061
Feature norm: 82.059120
Error norm: 40.489804
Active features: 158563
Line search trials: 2
Line search step: 0.488284
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12938, 12101) (0.8988, 0.9610, 0.9289)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1471, 2244) (0.6390, 0.4189, 0.5061)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107698, 0.098049, 0.101787)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #561 *****
Loss: 29713.253190
Feature norm: 82.060919
Error norm: 32.431955
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12938, 12101) (0.8988, 0.9610, 0.9289)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1471, 2244) (0.6390, 0.4189, 0.5061)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107698, 0.098049, 0.101787)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #562 *****
Loss: 29713.164423
Feature norm: 82.068252
Error norm: 30.957316
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12936, 12101) (0.8990, 0.9610, 0.9289)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (942, 1473, 2244) (0.6395, 0.4198, 0.5069)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107716, 0.098074, 0.101811)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #563 *****
Loss: 29713.112129
Feature norm: 82.075094
Error norm: 64.115928
Active features: 158563
Line search trials: 2
Line search step: 0.501794
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12936, 12101) (0.8990, 0.9610, 0.9289)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (942, 1473, 2244) (0.6395, 0.4198, 0.5069)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107716, 0.098074, 0.101811)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #564 *****
Loss: 29713.038640
Feature norm: 82.082363
Error norm: 39.026969
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11630, 12941, 12101) (0.8987, 0.9611, 0.9288)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1468, 2244) (0.6403, 0.4189, 0.5065)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107731, 0.098051, 0.101797)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #565 *****
Loss: 29712.970937
Feature norm: 82.090381
Error norm: 24.945929
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11630, 12941, 12101) (0.8987, 0.9611, 0.9288)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1468, 2244) (0.6403, 0.4189, 0.5065)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107731, 0.098051, 0.101797)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #566 *****
Loss: 29712.912233
Feature norm: 82.095861
Error norm: 28.505645
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12942, 12101) (0.8985, 0.9610, 0.9287)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1467, 2244) (0.6394, 0.4180, 0.5055)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107701, 0.098024, 0.101768)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #567 *****
Loss: 29712.894187
Feature norm: 82.097800
Error norm: 62.720584
Active features: 158563
Line search trials: 2
Line search step: 0.328772
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12945, 12101) (0.8985, 0.9612, 0.9288)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1466, 2244) (0.6398, 0.4180, 0.5057)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107726, 0.098010, 0.101769)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #568 *****
Loss: 29712.850648
Feature norm: 82.100643
Error norm: 35.306837
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12945, 12101) (0.8985, 0.9612, 0.9288)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1466, 2244) (0.6398, 0.4180, 0.5057)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107726, 0.098010, 0.101769)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #569 *****
Loss: 29712.812866
Feature norm: 82.102179
Error norm: 24.719473
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11631, 12945, 12101) (0.8985, 0.9612, 0.9288)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1466, 2244) (0.6398, 0.4180, 0.5057)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107726, 0.098010, 0.101769)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #570 *****
Loss: 29712.748034
Feature norm: 82.104835
Error norm: 32.385235
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12943, 12101) (0.8985, 0.9610, 0.9287)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1468, 2244) (0.6390, 0.4180, 0.5054)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107701, 0.098005, 0.101759)
Item accuracy: 14999 / 17262 (0.8689)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #571 *****
Loss: 29712.698602
Feature norm: 82.112588
Error norm: 61.967774
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12943, 12101) (0.8985, 0.9610, 0.9287)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1468, 2244) (0.6390, 0.4180, 0.5054)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107701, 0.098005, 0.101759)
Item accuracy: 14999 / 17262 (0.8689)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #572 *****
Loss: 29712.628677
Feature norm: 82.117495
Error norm: 36.687683
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12938, 12101) (0.8987, 0.9609, 0.9288)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1473, 2244) (0.6382, 0.4189, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107686, 0.098028, 0.101773)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #573 *****
Loss: 29712.562301
Feature norm: 82.124545
Error norm: 26.009465
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12938, 12101) (0.8987, 0.9609, 0.9288)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1473, 2244) (0.6382, 0.4189, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107686, 0.098028, 0.101773)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #574 *****
Loss: 29712.511650
Feature norm: 82.132386
Error norm: 22.341397
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12938, 12101) (0.8987, 0.9609, 0.9288)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1473, 2244) (0.6382, 0.4189, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107686, 0.098028, 0.101773)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #575 *****
Loss: 29712.497548
Feature norm: 82.135860
Error norm: 58.844660
Active features: 158563
Line search trials: 2
Line search step: 0.292737
Seconds required for this iteration: 1.390
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12936, 12101) (0.8989, 0.9609, 0.9289)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1475, 2244) (0.6373, 0.4189, 0.5055)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107666, 0.098028, 0.101768)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #576 *****
Loss: 29712.466596
Feature norm: 82.141263
Error norm: 30.608080
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.710
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11628, 12936, 12101) (0.8989, 0.9609, 0.9289)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1475, 2244) (0.6373, 0.4189, 0.5055)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107666, 0.098028, 0.101768)
Item accuracy: 15000 / 17262 (0.8690)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #577 *****
Loss: 29712.440326
Feature norm: 82.144374
Error norm: 29.071274
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11630, 12938, 12101) (0.8989, 0.9611, 0.9290)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1473, 2244) (0.6382, 0.4189, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107690, 0.098032, 0.101778)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #578 *****
Loss: 29712.364697
Feature norm: 82.154489
Error norm: 52.234845
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12947, 12101) (0.8986, 0.9614, 0.9289)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1464, 2244) (0.6407, 0.4180, 0.5059)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107752, 0.098017, 0.101781)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #579 *****
Loss: 29712.289834
Feature norm: 82.166679
Error norm: 45.323312
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12945, 12101) (0.8987, 0.9614, 0.9290)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1466, 2244) (0.6412, 0.4189, 0.5067)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107770, 0.098041, 0.101806)
Item accuracy: 15006 / 17262 (0.8693)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #580 *****
Loss: 29712.260355
Feature norm: 82.172775
Error norm: 75.048866
Active features: 158563
Line search trials: 2
Line search step: 0.220527
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11633, 12942, 12101) (0.8989, 0.9613, 0.9290)
    repeat: (1116, 1334, 1447) (0.8366, 0.7713, 0.8026)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1466, 2244) (0.6412, 0.4189, 0.5067)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107763, 0.098077, 0.101823)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #581 *****
Loss: 29712.207497
Feature norm: 82.178823
Error norm: 36.706586
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11630, 12939, 12101) (0.8988, 0.9611, 0.9289)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1470, 2244) (0.6395, 0.4189, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107710, 0.098051, 0.101792)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #582 *****
Loss: 29712.169103
Feature norm: 82.183077
Error norm: 31.797655
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11630, 12939, 12101) (0.8988, 0.9611, 0.9289)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1470, 2244) (0.6395, 0.4189, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107710, 0.098051, 0.101792)
Item accuracy: 15003 / 17262 (0.8691)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #583 *****
Loss: 29712.143181
Feature norm: 82.185683
Error norm: 34.228344
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12939, 12101) (0.8988, 0.9610, 0.9288)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1472, 2244) (0.6386, 0.4189, 0.5059)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107698, 0.098030, 0.101778)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #584 *****
Loss: 29712.122746
Feature norm: 82.189003
Error norm: 89.182147
Active features: 158563
Line search trials: 2
Line search step: 0.360787
Seconds required for this iteration: 1.380
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12939, 12101) (0.8988, 0.9610, 0.9288)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1472, 2244) (0.6386, 0.4189, 0.5059)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107698, 0.098030, 0.101778)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #585 *****
Loss: 29712.082063
Feature norm: 82.193163
Error norm: 63.586650
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11629, 12941, 12101) (0.8986, 0.9610, 0.9288)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (940, 1470, 2244) (0.6395, 0.4189, 0.5062)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107718, 0.098030, 0.101784)
Item accuracy: 15001 / 17262 (0.8690)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #586 *****
Loss: 29712.013216
Feature norm: 82.203522
Error norm: 23.574177
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12952, 12101) (0.8983, 0.9615, 0.9288)
    repeat: (1112, 1329, 1447) (0.8367, 0.7685, 0.8012)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (937, 1461, 2244) (0.6413, 0.4176, 0.5058)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107756, 0.097968, 0.101751)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #587 *****
Loss: 29711.990824
Feature norm: 82.209011
Error norm: 25.281929
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12948, 12101) (0.8986, 0.9615, 0.9290)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (937, 1463, 2244) (0.6405, 0.4176, 0.5055)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107746, 0.098007, 0.101771)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #588 *****
Loss: 29711.965326
Feature norm: 82.214916
Error norm: 20.839243
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12950, 12101) (0.8985, 0.9615, 0.9289)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (935, 1461, 2244) (0.6400, 0.4167, 0.5047)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107728, 0.097982, 0.101747)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #589 *****
Loss: 29711.958981
Feature norm: 82.223978
Error norm: 65.536509
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11639, 12954, 12101) (0.8985, 0.9618, 0.9291)
    repeat: (1115, 1333, 1447) (0.8365, 0.7706, 0.8022)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (935, 1455, 2244) (0.6426, 0.4167, 0.5055)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107788, 0.098010, 0.101778)
Item accuracy: 15007 / 17262 (0.8694)
Instance accuracy: 546 / 1316 (0.4149)

***** Iteration #590 *****
Loss: 29711.921250
Feature norm: 82.224603
Error norm: 21.367880
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11640, 12954, 12101) (0.8986, 0.9619, 0.9292)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (937, 1457, 2244) (0.6431, 0.4176, 0.5063)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107818, 0.098018, 0.101799)
Item accuracy: 15009 / 17262 (0.8695)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #591 *****
Loss: 29711.906379
Feature norm: 82.225399
Error norm: 19.383923
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11635, 12949, 12101) (0.8985, 0.9615, 0.9289)
    repeat: (1114, 1331, 1447) (0.8370, 0.7699, 0.8020)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (937, 1462, 2244) (0.6409, 0.4176, 0.5057)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107756, 0.098007, 0.101774)
Item accuracy: 15004 / 17262 (0.8692)
Instance accuracy: 547 / 1316 (0.4157)

***** Iteration #592 *****
Loss: 29711.892416
Feature norm: 82.227210
Error norm: 23.840074
Active features: 158563
Line search trials: 1
Line search step: 1.000000
Seconds required for this iteration: 0.720
Performance by label (#match, #model, #ref) (precision, recall, F1):
    OK: (11634, 12949, 12101) (0.8984, 0.9614, 0.9289)
    repeat: (1112, 1329, 1447) (0.8367, 0.7685, 0.8012)
    filler: (1306, 1499, 1423) (0.8712, 0.9178, 0.8939)
    false_start: (938, 1464, 2244) (0.6407, 0.4180, 0.5059)
    arg1: (0, 0, 3) (0.0000, 0.0000, 0.0000)
    w[-2]=kind: (0, 0, 0) (******, ******, ******)
    ^: (12, 19, 26) (0.6316, 0.4615, 0.5333)
    argM_tmp: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    argM_tm: (0, 0, 0) (******, ******, ******)
    predicate: (0, 0, 0) (******, ******, ******)
    arg0: (0, 2, 4) (0.0000, 0.0000, 0.0000)
    w[0]=twenty-seventh: (0, 0, 0) (******, ******, ******)
    argM_loc: (0, 0, 0) (******, ******, ******)
    w[-2]=watch: (0, 0, 0) (******, ******, ******)
    arg2: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    w[-2]=uh: (0, 0, 0) (******, ******, ******)
    w[-2]=has: (0, 0, 0) (******, ******, ******)
    w[-2]=reversing: (0, 0, 0) (******, ******, ******)
    w[-2]=have: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=not: (0, 0, 0) (******, ******, ******)
    w[-2]=granddaughters: (0, 0, 0) (******, ******, ******)
    w[-2]=of: (0, 0, 0) (******, ******, ******)
    w[-2]=you: (0, 0, 0) (******, ******, ******)
    w[-2]=before: (0, 0, 0) (******, ******, ******)
    w[-2]='s: (0, 0, 0) (******, ******, ******)
    argM_cause: (0, 0, 0) (******, ******, ******)
    ties: (0, 0, 0) (******, ******, ******)
    argM_adverb: (0, 0, 0) (******, ******, ******)
    w[-2]=girls: (0, 0, 0) (******, ******, ******)
    w[-2]=like: (0, 0, 0) (******, ******, ******)
    arg_particl: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    arg4: (0, 0, 0) (******, ******, ******)
    w[-2]=and: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=always: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=a: (0, 0, 2) (0.0000, 0.0000, 0.0000)
    w[-2]=are: (0, 0, 2) (0.0000, 0.0000, 0.0000)
Macro-average precision, recall, F1: (0.107742, 0.097978, 0.101755)
Item accuracy: 15002 / 17262 (0.8691)
Instance accuracy: 547 / 1316 (0.4157)

L-BFGS terminated with the stopping criteria
Total seconds required for training: 469.570

End time of the training: 2015-01-13T04:59:24Z

